{"./":{"url":"./","title":"首页","keywords":"","body":"深度学习预测水稻基因组组蛋白修饰 本项目 作者： "},"实验流程/":{"url":"实验流程/","title":"实验流程","keywords":"","body":"研究内容 ​ 组蛋白修饰的相关研究一直是表观遗传领域的热点，近年来，组蛋白修饰的定量检测已经成为研究染色体包装、转录激活和DNA损伤等生物过程的主要手段，目前定量检测组蛋白修饰的技术仍是以染色质免疫共沉淀和二代测序技术相结合的ChIP-seq为主，各课题组都在以更小的样本量，更高的分辨率，降低成本，缩短时间为目标，对ChIP-seq进行改进，但是高通量技术昂贵而耗时的特点仍然非常突出。 ​ 鉴于此，我们通过训练深度学习模型来拟合基因型序列数据与组蛋白修饰位点数据，以实现准确预测不同组蛋白标记的修饰位点的目的，并且使用不同的算法来解析序列信息中起到关键作用的位点，对序列的保守性特征实现可视化，以提取组蛋白修饰区域的motif，研究组蛋白修饰在基因表达调控中的作用，最终将训练好的模型用于组蛋白修饰定性图谱的绘制。 "},"实验流程/实验流程概述.html":{"url":"实验流程/实验流程概述.html","title":"实验流程概述","keywords":"","body":"实验流程概述 1.利用变异信息（vcf）里的变异信息（SNP)来替换水稻参考基因组中原本序列，生成品种基因型； 2.参考deepsea中定义组蛋白修饰标签的方式，将基因组切分成每500bp一个bin，根据narrowPeak文件里的信号区域范围，使用slide window的方式，在每个peak的最高点中心取一定长度的区域，与slide window重合超过10%就标记为有组蛋白修饰（标签为1），否则为无修饰（标签为0），注意每个品种的组蛋白修饰情况不同，最终形成训练集。20个水稻品种序列信息 ：组蛋白修饰标签（五个二分类）； 3.将训练集投入深度学习模型，进行调参，选择最优模型参数； 4.利用神经网络的提取特征的特性将PWM矩阵从卷积层中提取出来，获取高保守性的序列motif，与JASPAR数据库中的TFBS进行对比； 5.利用训练好的模型进行预测，绘制组蛋白修饰定性图谱。 整体架构 /public/home/xwli/xwzhang/deeplearningDATA/rice ├── data/ ├── mapto_MSU7/ ├── MHZS_mapto_MHRS1_ZSRS1/ │ ├── pytorch_deepsea/ ├── DeepHistone/ ├── Nt_Transformer/ └── scripts/ │ ├── py_scripts/ │ └── sh_scripts/ 技术路线 "},"实验流程/数据获取与预处理.html":{"url":"实验流程/数据获取与预处理.html","title":"数据获取与预处理","keywords":"","body":"数据获取与预处理 数据命名规则和存放位置 /public/home/xwli/xwzhang/deeplearningDATA/rice/data/ name location 序列文件 C^^^_C^^^.fasta /sequence 注释文件 C^^^_C^^^.fasta.fai /faidx 信号区域处理后 sort_C^^^.bed /signal_area 单品种标签 target_C^^^.txt /target 单品种数据集 data_C^^^.xlsx /dataset 数据集（data(数据量)（随机）） data_10w_sh.xlsx /dataset onehot编码 one_hot_10w_sh.npy /onehot 数据集对应标签 labels_10w_sh.txt /label DeepSEA dataset_rice1.npz /DeepSEA DeepHistone dataset_rice2.npz /DeepHistone Transformer dataset_rice3.npz /Transformer 数据格式 fasta 在生物信息学中，FASTA格式（又称为Pearson格式）是一种基于文本的、用于表示核苷酸序列或氨基酸序列的格式。在这种格式中碱基对或氨基酸用单个字母来表示，且允许在序列前添加序列名及注释。 FASTA文件以序列表示和序列作为一个基本单元，各行记录信息如下： 第一行是由大于号\">\"开头的任意文字说明，用于序列标记，为了保证后续分析软件能够区分每条序列，单个序列的标识必须具有唯一性。； 从第二行开始为序列本身，只允许使用既定的核苷酸或氨基酸编码符号。通常核苷酸符号大小写均可，而氨基酸常用大写字母。使用时应注意有些程序对大小写有明确要求。文件每行的字母一般不应超过80个字符。 IRGSP-1.0_genome.fasta vcf VCF格式：Variant Call Format，用于记录variants (SNP / InDel)的文件格式 水稻12条染色体的变异信息 SNP汇总： nip_total.vcf 注释部分 # vcf版本 日期 水稻12条染色体的长度 主体部分 CHROM ： 参考序列名称 POS ： variant所在的left-most位置(1-base position)（发生变异的位置的第一个碱基所在的位置） ID ： variant的ID。同时对应着dbSNP数据库中的ID，若没有，则默认使用‘.’ REF ： 参考序列的Allele，（等位碱基，即参考序列该位置的碱基类型及碱基数量） ALT ： variant的Allele，若有多个，则使用逗号分隔，（变异所支持的碱基类型及碱基数量）这里的碱基类型和碱基数量，对于SNP来说是单个碱基类型的编号，而对于Indel来说是指碱基个数的添加或缺失，以及碱基类型的变化 QUAL ： variants的质量。Phred格式的数值，代表着此位点是纯合的概率，此值越大，则概率越低，代表着次位点是variants的可能性越大。（表示变异碱基的可能性） FILTER ： 次位点是否要被过滤掉。如果是PASS，则表示此位点可以考虑为variant。 INFO ： variant的相关信息 FORMAT ： variants的格式，例如GT:AD:DP:GQ:PL SAMPLES ： 各个Sample的值，由BAM文件中的@RG下的SM标签所决定，这些值对应着第9列的各个格式，不同格式的值用冒号分开，每一个sample对应着1列；多个samples则对应着多列，这种情况下列的数多余10列。 nip_total.vcf narrowPeak ChIP-seq产生的数据格式 *narrowPeak文件是BED6+4格式，可以上传到UCSC浏览。输出文件每列信息分别包含： 1；染色体号 2：peak起始位点 3：结束位点 4：peak name 5：int(-10*log10qvalue) 6 ：正负链 7：fold change 8：-log10pvalue 9：-log10qvalue 10：relative summit position to peak start（？） fai fasta是常用的序列存储格式，软件对序列进行快速查找的时候通常需要建立索引文件，例如在GATK、IGV等软件中导入序列的时候都需要建立索引。fasta格式文件的一种索引为fai结尾的文件，可以使用samtools faidx命令创建，具体用法如下： 用法： samtools faidx input.fa 该命令对输入的fasta序列有一定要求：对于每条序列，除了最后一行外， 其他行的长度必须相同 第一列 NAME : 序列的名称，只保留“>”后，第一个空白之前的内容； 第二列 LENGTH: 序列的长度， 单位为bp； 第三列 OFFSET : 第一个碱基的偏移量， 从0开始计数，换行符也统计进行； 第四列 LINEBASES : 除了最后一行外， 其他代表序列的行的碱基数， 单位为bp； 第五列 LINEWIDTH : 行宽， 除了最后一行外， 其他代表序列的行的长度， 包括换行符， 在windows系统中换行符为\\r\\n, 要在序列长度的基础上加2； bed BED (Browser Extensible Data)格式文件就是通过规定行的内容来展示注释信息 BED文件每行至少包括chrom，chromStart，chromEnd三列；另外还可以添加额外的9列，这些列的顺序是固定的。 在自定义BED文件时，前面可以有注释行，以“browser”或“track”开头，可以设置一些参数便于浏览器更好展示BED文件信息。但是，下游的一些分析工具，例如bedToBigBed，是不接受有注释的BED文件的。 # BED文件必须的3列: chrom - 染色体号; 例如，chr1，chrX。。。。。。。 chromStart - feature在染色体上起始位置. 从0开始算，染色体上第一个碱基位置标记为0。 chromEnd - feature在染色体上终止位置。染色体上前100个碱基片段的位置位置标记为：chromStart=0, chromEnd=100。 实际上，第100个碱基不属于当前片段中，当前片段的碱基应该是0-99。所以在BED文件中，起始位置从0开始，终止位置从1开始。 # BED文件可选的9列: name - BED行名，在基因组浏览器左边显示； score - 在基因组浏览器中显示的灰度设定，值介于0-1000； gray score strand - 正负链标记. Either \".\" (=no strand) or \"+\" or \"-\". thickStart - feature起始位置(for example, the start codon in gene displays)。 When there is no thick part, thickStart and thickEnd are usually set to the chromStart position. thickEnd - feature编码终止位置 (for example the stop codon in gene displays). itemRgb - R,G,B (e.g. 255,0,0)值，当itemRgb 设置为 \"On\"，BED的行会显示颜色. blockCount - blocks (exons)数目. blockSizes - blocks (exons)大小列表，逗号分隔，对应于blockCount. blockStarts -blocks (exons)起始位置列表，逗号分隔，对应于blockCount.；这个起始位置是与chromStart的一个相对位置。 sort_C019_peak.bed .npy/.npz npy文件是Numpy专用的二进制格式文件，可以用来保存numpy.array import numpy as np # 将数组以二进制格式保存到磁盘 arr=np.arange(5) np.save('test',arr) # 读取数组 print(np.load('test.npy')) npz文件是Numpy的压缩文件，可以将多个数组压缩保存到同一个文件中。 import numpy as np # 将多个数组保存到磁盘 a = np.arange(5) b = np.arange(6) c = np.arange(7) np.savez('test', a, b, c_array=c) # c_array是数组c的命名 # 读取数组 data = np.load('test.npz') #类似于字典{‘arr_0’:a,’arr_1’:b,’c_array’:c} print('arr_0 : ', data['arr_0']) print('arr_1 : ', data['arr_1']) print('c_array : ', data['c_array']) -------------------------------------------------------------------------------- arr_0 : [0 1 2 3 4] arr_1 : [0 1 2 3 4 5] c_array : [0 1 2 3 4 5 6] 生成数据集 本部分包含数据处理脚本的全部更新过程，想查看最新版本数据处理流程请跳转至生成数据集总流程（bash脚本） 参考基因组下载 水稻日本晴第七版 wget http://rapdb.dna.affrc.go.jp/download/archive/irgsp1/IRGSP-1.0_genome.fasta.gz gunzip IRGSP-1.0_genome.fasta.gz 查看基因组的大小和ID bioawk -c fastx '{print $1 \"\\t\" length($seq)}' IRGSP-1.0_genome.fasta 生成品种基因型 以NIP为示例，后续使用其他品种扩大数据集 python脚本 geno_sub.py 目前使用脚本geno_sub2.0.py, 解决兼并碱基的问题（2021.3.28） 使用bash脚本批量并行提交作业 注：bash脚本在windows上编辑后在Linux运行会报错 scripts/sh_scripts/geno_make.sh: line 4: syntax error near unexpected token `$'do\\r'' 'cripts/sh_scripts/geno_make.sh: line 4: `do 解决方法： https://www.jianshu.com/p/55597646fa84 sed 's/\\r//' input.sh > output.sh #!/bin/bash #生成品种基因型，参考基因组日本晴第七版 for i in $(cat id1) do bsub -q high -e ${i}.err -o ${i}.out \"python3 scripts/py_scripts/geno_sub.py -s data/vcf/sort.total.vcf -n ${i} -r data/ref/IRGSP-1.0_genome.fasta -l 500\" done python脚本使用方法 $ python3 geno_sub.py -h usage: geno_sub.py [-h] -s -n -r [-l] New sample genome sequence based on snp data optional arguments: -h, --help show this help message and exit -s , --snpfile snp file in vcf format -n , --samplename sample name, which mest be in snpfile -r , --reference reference file -l , --seqlen seq length per line in output file input Format Description location .fasta 日本晴第七版参考基因组（IRGSP-1.0_genome.fasta） data/ref .vcf 水稻变异信息(vcf) data/vcf output Format Description Location .fasta 水稻品种自定义基因组（C^^^.fasta) data/sequence .fasta 水稻基因组（无>,paste时使用) data/seq 示例 bsub 'python3 scripts/geno_sub.py -s data/vcf/*.vcf -n C^^^ -r data/ref/*fasta -l 500' #geno_sub.py import re import os import sys import argparse from collections import defaultdict def defaultdict_list(): return defaultdict(list) def snpInfo(snp): ''' 处理位点文件，记录样本发生变异的位点坐标信息 ''' snp_file = open(snp, 'r') snp_info = defaultdict(defaultdict_list) snp_geno = defaultdict(defaultdict_list) for line in snp_file: if line.startswith('##') or re.search('^$',line.strip()): continue elif line.startswith('#CHROM'): line_info = line.strip().split('\\t') sample_list = line_info[9:] else: line_info = line.strip().split('\\t') for i in range(len(sample_list)): if line_info[i+9]!='0|0': snp_info[sample_list[i]][line_info[0]].append(int(line_info[1])) snp_geno[sample_list[i]][line_info[0]].append([line_info[3], line_info[4]]) snp_file.close() return snp_info, snp_geno def genomePar(genome): ''' 解析基因组文件 ''' genome_file = open(genome, 'r') seq = '' seq_name = '' seq_info = {} for line in genome_file: if line.startswith('>') and seq == '': seq_name = re.sub('chr0|chr', '',line.strip()[1:]) elif line.startswith('>') and seq != '': seq_info[seq_name] = seq seq_name = re.sub('chr0|chr', '',line.strip()[1:]) seq = '' else: seq += line.strip() seq_info[seq_name] = seq genome_file.close() return seq_info def seqFormat(seq, lenset=60): ''' 按指定长度替换数据 ''' format_seq = '' for i in range(1, len(seq)+1): if i % lenset == 0: format_seq += seq[i-1]+\"\\n\" else: format_seq += seq[i-1] return format_seq def faOut(snppos, snpgeno, fasta, sample, lenset=60): ''' 根据snppos内储存的信息，对基因组中的碱基进行替换 ''' out_fasta = open(f'{sample}.fasta', 'w') for key in fasta: n = 1 seq = '' for i in fasta[key]: if len(snppos[sample][key])!=0 and n==snppos[sample][key][0]: try: ref_index = snpgeno[sample][key][0].index(i.upper()) #print (ref_index, snpgeno[sample][key][0]) if ref_index == 0: seq += snpgeno[sample][key][0][1] else: seq += snpgeno[sample][key][0][0] except: print (f'chr {key} in pos {n} for sample {sample} is wrong: the ref is {i}, but geno is {snpgeno[sample][key][0]}') seq += i finally: snppos[sample][key].pop(0) snpgeno[sample][key].pop(0) else: seq += i n += 1 chr_id = 'chr{:0>2d}'.format(int(key)) seq = seqFormat(seq, lenset) out_fasta.write(f'>{chr_id}\\n{seq}\\n') out_fasta.close() if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"New sample genome sequence based on snp data\") parser.add_argument(\"-s\", \"--snpfile\", metavar=\"\", required=True, help=\"snp file in vcf format\") parser.add_argument(\"-n\", \"--samplename\", metavar=\"\", required=True, help=\"sample name, which mest be in snpfile\") parser.add_argument(\"-r\", \"--reference\", metavar=\"\", required=True, help=\"reference file\") parser.add_argument(\"-l\", \"--seqlen\", metavar=\"\", default=60, type=int, help=\"seq length per line in output file\") args = parser.parse_args() # 解析变异信息文件 snppos, snpgeno = snpInfo(args.snpfile) # 解析基因组文件 fasta = genomePar(args.reference) # 输出替换的结果 faOut(snppos, snpgeno, fasta, args.samplename, args.seqlen) #删除含有N（n）的行 sed -i '/N/d' C^^^.fasta | sed -i '/n/d' #geno_sub2.0.py import re import os import sys import argparse from collections import defaultdict def defaultdict_list(): return defaultdict(list) def snpInfo(snp): ''' 处理位点文件，记录样本发生变异的位点坐标信息 ''' degeneration = {'AG':'R','GA':'R','CT':'Y','TC':'Y', 'AC':'M','CA':'M','GT':'K','TG':'K', 'GC':'S','CG':'S','AT':'W','TA':'W'} snp_file = open(snp, 'r') snp_info = defaultdict(defaultdict_list) snp_geno = defaultdict(defaultdict_list) for line in snp_file: if line.startswith('##') or re.search('^$',line.strip()): continue elif line.startswith('#CHROM'): line_info = line.strip().split('\\t') sample_list = line_info[9:] else: line_info = line.strip().split('\\t') for i in range(len(sample_list)): if line_info[i+9]!='' and line_info[i+9]!='0|0' and line_info!=\".|.\": sample_allele = list(set(line_info[i+9].split('|'))) ref = line_info[3] alts = [ref] alts.extend(line_info[4].split(',')) if len(ref) == 1: snp_info[sample_list[i]][line_info[0]].append(int(line_info[1])) if len(sample_allele) == 1: snp_geno[sample_list[i]][line_info[0]].append([alts[int(sample_allele[0])]]) else: biallele = ''.join([alts[int(sample_allele[0])],alts[int(sample_allele[1])]]) if len(biallele)!=2: snp_geno[sample_list[i]][line_info[0]].append(alts[int(sample_allele[1])]) else: snp_geno[sample_list[i]][line_info[0]].append(degeneration[biallele]) else: snp_info[sample_list[i]][line_info[0]].append([int(line_info[1]),int(line_info[1])+len(alts[0])-1]) if len(sample_allele) == 1: snp_geno[sample_list[i]][line_info[0]].append([alts[int(sample_allele[0])]]) else: biallele = ''.join([alts[int(sample_allele[0])],alts[int(sample_allele[1])]]) snp_geno[sample_list[i]][line_info[0]].append(alts[int(sample_allele[0])]) snp_file.close() return snp_info, snp_geno def genomePar(genome): ''' 解析基因组文件 ''' genome_file = open(genome, 'r') seq = '' seq_name = '' seq_info = {} for line in genome_file: if line.startswith('>') and seq == '': seq_name = re.sub('chr0|chr', '',line.strip()[1:]) elif line.startswith('>') and seq != '': seq_info[seq_name] = seq seq_name = re.sub('chr0|chr', '',line.strip()[1:]) seq = '' else: seq += line.strip() seq_info[seq_name] = seq genome_file.close() return seq_info def seqFormat(seq, lenset=500): ''' 按指定长度替换数据 ''' format_seq = '' for i in range(1, len(seq)+1): if i % lenset == 0: format_seq += seq[i-1]+\"\\n\" else: format_seq += seq[i-1] return format_seq def faOut(snppos, snpgeno, fasta, sample, lenset=60): ''' 根据snppos内储存的信息，对基因组中的碱基进行替换 ''' fasta_file = open(fasta, 'r') out_fasta = open(f'{sample}.fasta', 'w') for line in fasta_file: if line.startswith('>'): #print (line) seq_name = re.sub('chr0|chr', '',line.strip()[1:]) out_fasta.write(f'>{seq_name}\\n') start = 1 else: for i in range(len(line.strip())): if len(snppos[sample][seq_name]) == 0: out_fasta.write(line[i]) elif i == snppos[sample][seq_name][0]: out_fasta.write(snpgeno[sample][seq_name][0]) snppos[sample][seq_name].pop(0) snpgeno[sample][seq_name].pop(0) elif isinstance(snppos[sample][seq_name][0], list) and i in snppos[sample][seq_name][0]: out_fasta.write(snpgeno[sample][seq_name][0]) i = snppos[sample][seq_name][0] snppos[sample][seq_name].pop(0) snpgeno[sample][seq_name].pop(0) else: out_fasta.write(line[i]) out_fasta.write('\\n') ''' for key in fasta: n = 1 seq = '' for i in fasta[key]: if len(snppos[sample][key])!=0 and n==snppos[sample][key][0]: try: ref_index = snpgeno[sample][key][0].index(i.upper()) #print (ref_index, snpgeno[sample][key][0]) if ref_index == 0: seq += snpgeno[sample][key][0][1] else: seq += snpgeno[sample][key][0][0] except: print (f'chr {key} in pos {n} for sample {sample} is wrong: the ref is {i}, but geno is {snpgeno[sample][key][0]}') seq += i finally: snppos[sample][key].pop(0) snpgeno[sample][key].pop(0) else: seq += i n += 1 chr_id = 'chr{:0>2d}'.format(int(key)) seq = seqFormat(seq, lenset) out_fasta.write(f'>{chr_id}\\n{seq}\\n') out_fasta.close() ''' if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"New sample genome sequence based on snp data\") parser.add_argument(\"-s\", \"--snpfile\", metavar=\"\", required=True, help=\"snp file in vcf format\") parser.add_argument(\"-n\", \"--samplename\", metavar=\"\", required=True, help=\"sample name, which mest be in snpfile\") parser.add_argument(\"-r\", \"--reference\", metavar=\"\", required=True, help=\"reference file\") parser.add_argument(\"-l\", \"--seqlen\", metavar=\"\", default=60, type=int, help=\"seq length per line in output file\") args = parser.parse_args() # 解析变异信息文件 snppos, snpgeno = snpInfo(args.snpfile) # 输出替换的结果 faOut(snppos, snpgeno, args.reference, args.samplename, args.seqlen) 生成组蛋白修饰标签 目前使用bash脚本自动化并行处理标签生成任务(2021.3.28) 分别提取组蛋白修饰信号区域 input ：narrowPeak文件 output：bed文件 组蛋白修饰H3K4me3, H3K27ac, H3K4me1, H3K27me3， H3K9me2 awk '{print $1,$2,$3}' mapto*/*_seedlings/*C^^^_peaks.narrowPeak | sort -t ' ' -k1.4nr >> C^^^.bed `按照染色体顺序排列，并计数 sort -k1,1V -k2,2n -k3,3n C^^^.bed > data/signal_area/sort_C^^^.bed rm -f C^^^.bed cat data/signal_area/sort_C^^^.bed | awk '{print $1}' | uniq -c ls *fasta | while read id;do echo ${id%.*} >> id.txt;done #提取品种id #area_extract.sh #!/bin/bash for n in $(cat histone) do for i in $(cat id.txt) do awk '{print $1,$2,$3}' mapto*/${n}_seedlings/*${i}_peaks.*Peak | sort -t ' ' -k1,4nr | sort -k1,1V -k2,2n -k3,3n > data/signal_area/sort_${i}_${n}.bed done done 生成自定义基因组的fai文件 samtools faidx data/sequence/C^^^.fasta 生成标签 python脚本target_mark.py 使用方法 $ python3 target_mark.py -h usage: 20210302_bin_count.py [-h] -f -b -o [-w] [-l] bin data out optional arguments: -h, --help show this help message and exit -f , --fai reference index file in fai -b , --bed bed file -o , --output output file -w , --window window size -l , --overlap overlap size input Format Description Location .narrowPeak 20个水稻品种的ChIP-seq结果 mapto_MSU7/*seedlings .bed 组蛋白修饰信号区域 sort_C^^^_C^^^.bed data/signal_area .fai fasta文件的索引 C^^^_C^^^.fasta.fai data/faidx output Format Description Location .txt（1.0） 标签[0,1] data/target .txt (2.0) onehot标签1-5 da 示例 bsub 'python3 scripts/target_mark.py -f data/faidx/C019_C019.fasta.fai -b data/signal_area/sort_C^^^.bed -o target_C^^^.bed' bsub -e 11.err -o 11.out 'python3 target_mark3.0.py -f data/sequence/C019.fasta.fai -b data/signal_area/sort_C019_H3K4me3.bed -o target_C019_H3K4me3.bed -s C019 -m H3K4me3' #!/bin/bash for n in $(cat histone) do for i in $(cat id.txt) do python3 scripts/py_scripts/target_mark3.0.py -f data/seq/${i}.fasta.fai -b data/signal_area/sort_${i}_${n}.bed -o target_${i}_${n}.bed && awk '{print $3}' target_${i}_${n}.bed > data/target/target_${i}_${n}.txt && rm -f *bed done done bsub -e 11.err -o 11.out 'python3 target_mark3.0.py -f data/sequence/C019.fasta.fai -b data/signal_area/sort_C019_H3K4me3.bed -o target_C019_H3K4me3.bed -s C019 -m H3K4me3' import re import os import sys import argparse from collections import defaultdict def getRefLen(fai): ''' 读取fai文件，获取基因组长度 ''' fai_file = open(fai, 'r') ref_Length = {} for line in fai_file: chr_id, seq_len, *other = line.strip().split('\\t') ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len) return ref_Length def bedParse(bed): ''' 解析bed文件，分染色体返回预设区间信息 ''' region = defaultdict(list) bed_info = open(bed, 'r') for line in bed_info: chr_id, start, end = re.split('\\s', line.strip()) chr_id = re.sub('chr0|chr', '', chr_id) region[chr_id].append((int(start), int(end))) bed_info.close() return region def binCal(region, reflen, out, win=500, overlap=250): ''' 根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0 ''' out_file = open(out, 'w') bin = 0 for chr in reflen: for i in range(0, reflen[chr]-500, 500): start_tmp = i end_tmp = i+win region_chr = region[chr] for start, end in region_chr: if end_tmp overlap: bin = 1 else: bin = 0 break elif start_tmp>=end: region[chr].remove((start, end)) out_file.write(f'{chr}\\t{i}\\t{bin}\\t{start}\\t{end}\\n') out_file.close() if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"bin data out\") parser.add_argument(\"-f\", \"--fai\", metavar=\"\", required=True, help=\"reference index file in fai\") parser.add_argument(\"-b\", \"--bed\", metavar=\"\", required=True, help=\"bed file\") parser.add_argument(\"-o\", \"--output\", metavar=\"\", required=True, help=\"output file\") parser.add_argument(\"-w\", \"--window\", metavar=\"\", default=500, type=int, help=\"window size\") parser.add_argument(\"-l\", \"--overlap\", metavar=\"\", default=250, type=int, help=\"overlap size\") args = parser.parse_args() # 解析索引文件 reflen = getRefLen(args.fai) # 解析bed文件 region = bedParse(args.bed) # 输出bin结果 binCal(region, reflen, args.output, args.window, args.overlap) #target_mark2.0.py import re import os import sys import argparse from collections import defaultdict def getRefLen(fai): ''' 读取fai文件，获取基因组长度 ''' fai_file = open(fai, 'r') ref_Length = {} for line in fai_file: chr_id, seq_len, *other = line.strip().split('\\t') ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len) return ref_Length def bedParse(bed): ''' 解析bed文件，分染色体返回预设区间信息 ''' region = defaultdict(list) bed_info = open(bed, 'r') for line in bed_info: chr_id, start, end = re.split('\\s', line.strip()) chr_id = re.sub('chr0|chr', '', chr_id) region[chr_id].append((int(start), int(end))) bed_info.close() return region def binCal(region, reflen, out, win=500, overlap=250): ''' 根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0 ''' out_file = open(out, 'w') bin = 0 for chr in reflen: for i in range(0, reflen[chr]-500, 500): start_tmp = i end_tmp = i+win region_chr = region[chr] for start, end in region_chr: if end_tmp overlap: bin = 1 else: bin = 0 break elif start_tmp>=end: region[chr].remove((start, end)) out_file.write(f'{chr}\\t{i}\\t{bin}\\t{start}\\t{end}\\n') out_file.close() if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"bin data out\") parser.add_argument(\"-f\", \"--fai\", metavar=\"\", required=True, help=\"reference index file in fai\") parser.add_argument(\"-b\", \"--bed\", metavar=\"\", required=True, help=\"bed file\") parser.add_argument(\"-o\", \"--output\", metavar=\"\", required=True, help=\"output file\") parser.add_argument(\"-w\", \"--window\", metavar=\"\", default=500, type=int, help=\"window size\") parser.add_argument(\"-l\", \"--overlap\", metavar=\"\", default=250, type=int, help=\"overlap size\") args = parser.parse_args() # 解析索引文件 reflen = getRefLen(args.fai) # 解析bed文件 region = bedParse(args.bed) # 输出bin结果 binCal(region, reflen, args.output, args.window, args.overlap) #target_mark3.0.py import re import os import sys import argparse from collections import defaultdict def getRefLen(fai): ''' 读取fai文件，获取基因组长度 ''' fai_file = open(fai, 'r') ref_Length = {} for line in fai_file: chr_id, seq_len, *other = line.strip().split('\\t') ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len) return ref_Length def bedParse(bed): ''' 解析bed文件，分染色体返回预设区间信息 ''' region = defaultdict(list) bed_info = open(bed, 'r') for line in bed_info: chr_id, start, end = re.split('\\s', line.strip()) chr_id = re.sub('chr0|chr', '', chr_id) region[chr_id].append((int(start), int(end))) bed_info.close() return region def binCal(region, reflen, out, win=500, overlap=250,threshold = 0.1): ''' 根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0 ''' out_file = open(out, 'w') bin = 0 for chr in reflen: for i in range(0, reflen[chr], 500): if chr == '1': print (i) start_tmp = i end_tmp = i+win region_chr = region[chr] for start, end in region_chr: mid = (start + end)/2 start_mid = mid - (overlap/2) end_mid = mid + (overlap/2) if end_tmp end_mid: bin = 1 break elif start_midthreshold * overlap: bin = 1 else: bin = 0 break elif start_tmp>=end_mid: region[chr].remove((start, end)) out_file.write(f'{chr}\\t{i}\\t{bin}\\t{start}\\t{end}\\n') out_file.close() if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"bin data out\") parser.add_argument(\"-f\", \"--fai\", metavar=\"\", required=True, help=\"reference index file in fai\") parser.add_argument(\"-b\", \"--bed\", metavar=\"\", required=True, help=\"bed file\") parser.add_argument(\"-o\", \"--output\", metavar=\"\", required=True, help=\"output file\") parser.add_argument(\"-w\", \"--window\", metavar=\"\", default=500, type=int, help=\"window size\") parser.add_argument(\"-l\", \"--overlap\", metavar=\"\", default=250, type=int, help=\"overlap size\") args = parser.parse_args() # 解析索引文件 reflen = getRefLen(args.fai) # 解析bed文件 region = bedParse(args.bed) # 输出bin结果 binCal(region, reflen, args.output, args.window, args.overlap) #target_mark4.0.py import re import os import sys import argparse from collections import defaultdict def getRefLen(fai): ''' 读取fai文件，获取基因组长度 ''' fai_file = open(fai, 'r') ref_Length = {} for line in fai_file: chr_id, seq_len, *other = line.strip().split('\\t') ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len) return ref_Length def bedParse(bed): ''' 解析bed文件，分染色体返回预设区间信息 ''' region = defaultdict(list) bed_info = open(bed, 'r') for line in bed_info: chr_id, start, end = re.split('\\s', line.strip()) chr_id = re.sub('chr0|chr', '', chr_id) region[chr_id].append((int(start), int(end))) bed_info.close() return region def binCal(region, reflen, species, histone, out, win=500, overlap=250,threshold = 0.1): ''' 根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0 ''' out_file = open(out, 'w') bin = 0 for chr in reflen: for i in range(0, reflen[chr], 500): if chr == '1': print (i) start_tmp = i end_tmp = i+win region_chr = region[chr] name = f'{species}_{histone}_{chr}_{start_tmp}_{end_tmp}' for start, end in region_chr: mid = (start + end)/2 start_mid = mid - (overlap/2) end_mid = mid + (overlap/2) if end_tmp end_mid: bin = 1 break elif start_midthreshold * overlap: bin = 1 else: bin = 0 break elif start_tmp>=end_mid: region[chr].remove((start, end)) out_file.write(f'{name}\\t{bin}\\n') out_file.close() if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"bin data out\") parser.add_argument(\"-f\", \"--fai\", metavar=\"\", required=True, help=\"reference index file in fai\") parser.add_argument(\"-b\", \"--bed\", metavar=\"\", required=True, help=\"bed file\") parser.add_argument(\"-o\", \"--output\", metavar=\"\", required=True, help=\"output file\") parser.add_argument(\"-w\", \"--window\", metavar=\"\", default=500, type=int, help=\"window size\") parser.add_argument(\"-l\", \"--overlap\", metavar=\"\", default=250, type=int, help=\"overlap size\") parser.add_argument(\"-s\", \"--species\", metavar=\"\", help=\"rice species\") parser.add_argument(\"-m\", \"--histone\", metavar=\"\", help=\"histone modifications\") args = parser.parse_args() # 解析索引文件 reflen = getRefLen(args.fai) # 解析bed文件 region = bedParse(args.bed) # 输出bin结果 binCal(region, reflen, args.species, args.histone, args.output, args.window, args.overlap) #target_mark5.0.py import re import os import sys import argparse from collections import defaultdict def getRefLen(fai): ''' 读取fai文件，获取基因组长度 ''' fai_file = open(fai, 'r') ref_Length = {} for line in fai_file: chr_id, seq_len, *other = line.strip().split('\\t') ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len) return ref_Length def bedParse(bed): ''' 解析bed文件，分染色体返回预设区间信息 ''' region = defaultdict(list) bed_info = open(bed, 'r') for line in bed_info: chr_id, start, end = re.split('\\s', line.strip()) chr_id = re.sub('chr0|chr', '', chr_id) region[chr_id].append((int(start), int(end))) bed_info.close() return region def binCal(region, reflen, species, histone, tar, out, win=500, overlap=250,threshold = 0.1): ''' 根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0 ''' out_file = open(out, 'w') bin = 0 for chr in reflen: for i in range(0, reflen[chr], 500): if chr == '1': print (i) start_tmp = i end_tmp = i+win region_chr = region[chr] name = f'{species}_{histone}_{chr}_{start_tmp}_{end_tmp}' for start, end in region_chr: mid = (start + end)/2 start_mid = mid - (overlap/2) end_mid = mid + (overlap/2) if end_tmp end_mid: bin = tar break elif start_midthreshold * overlap: bin = tar else: bin = 0 break elif start_tmp>=end_mid: region[chr].remove((start, end)) out_file.write(f'{name}\\t{bin}\\n') out_file.close() if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"bin data out\") parser.add_argument(\"-f\", \"--fai\", metavar=\"\", required=True, help=\"reference index file in fai\") parser.add_argument(\"-b\", \"--bed\", metavar=\"\", required=True, help=\"bed file\") parser.add_argument(\"-o\", \"--output\", metavar=\"\", required=True, help=\"output file\") parser.add_argument(\"-w\", \"--window\", metavar=\"\", default=500, type=int, help=\"window size\") #parser.add_argument(\"-l\", \"--overlap\", metavar=\"\", default=250, type=int, help=\"overlap size\") parser.add_argument(\"-s\", \"--species\", metavar=\"\", help=\"rice species\") parser.add_argument(\"-m\", \"--histone\", metavar=\"\", help=\"histone modifications\") args = parser.parse_args() # 解析索引文件 reflen = getRefLen(args.fai) # 解析bed文件 region = bedParse(args.bed) # 输出bin结果 tar = 0 if args.histone == 'H3K4me3': tar = 1 overlap = 250 elif args.histone == 'H3K27ac': tar = 2 overlap = 250 elif args.histone == 'H3K4me1': tar = 3 overlap = 750 elif args.histone == 'H3K27me3': tar = 4 overlap = 750 elif args.histone == 'H3K9me2': tar = 5 overlap = 1000 binCal(region, reflen, args.species, args.histone, tar, args.output, args.window, overlap) 提取bin列作为标签 awk '{print $3}' target_C^^^.bed >> data/target/target_C^^^.txt rm -f target_C^^^.bed 删除fasta文件中的染色体行 sed -i '/>/d' C^^^_C^^^. 合成数据集 data target 500bp sequence 1 for 组蛋白修饰 0 for 无修饰 one-hot编码 [nums, 500, 4 ] [1,0] 将数据导入excel文件（data_C^^^.xlxs) 数据分布(C019) 1 478680 0 267802 总计 746483 合成标签均衡，随机分布的数据集 paste data/sequence/C^^^.fasta data/target/target_C^^^.txt > data/dataset/C^^^.csv #!/bin/bash for n in $(cat histone) do mkdir ${n} for i in $(cat id.txt) do paste data/seq/${i}.fasta data/target/target_${i}_${n}.txt > data/dataset/${n}/${i}_${n}.csv && sed -i '/>/d'data/dataset/${n}/${i}_${n}.csv done done 输入数据 以onehot（[4,500]）的形式输入 OneHotEncoder.py 注意将excel中含有N(n)的序列删去，否则会引起维度不统一 import numpy as np import pandas as pd import torch np.set_printoptions(threshold= np.inf) # function to convert a DNA sequence string to a numpy array # converts to lower case, changes any non 'acgt' characters to 'n' import re def string_to_array(my_string): my_string = my_string.lower() my_string = re.sub('[^acgt]', 'z', my_string) my_array = np.array(list(my_string)) return my_array # create a label encoder with 'acgtn' alphabet from sklearn.preprocessing import LabelEncoder label_encoder = LabelEncoder() label_encoder.fit(np.array(['a','c','g','t','z'])) # function to one-hot encode a DNA sequence string # non 'acgt' bases (n) are 0000 # returns a L x 4 numpy array from sklearn.preprocessing import OneHotEncoder def one_hot_encoder(my_array): integer_encoded = label_encoder.transform(my_array) onehot_encoder = OneHotEncoder(sparse=False, dtype=int) integer_encoded = integer_encoded.reshape(len(integer_encoded), 1) onehot_encoded = onehot_encoder.fit_transform(integer_encoded) return onehot_encoded data = pd.read_excel(r'./data_bal.xlsx',header = None) one_hot_matrix = [] for i in range(10000): one_hot_matrix.append(one_hot_encoder(string_to_array(data[0][i]))) np.save('one_hot',one_hot_matrix) one = np.load('./one_hot.npy',allow_pickle=True) one.shape OneHotEncoder2.0.py 1.加入argparse接口，方便命令行使用 2.改为双功能函数，check：对数据集进行清理，删除不符合编码规则的样本；make：对数据集进行onehot编码 #OneHotEncoder2.0.py #coding: utf-8 import numpy as np import pandas as pd import torch import os import sys import argparse from collections import defaultdict # function to convert a DNA sequence string to a numpy array # converts to lower case, changes any non 'acgt' characters to 'n' import re def string_to_array(my_string): my_string = my_string.lower() my_string = re.sub('[^acgt]', 'z', my_string) my_array = np.array(list(my_string)) return my_array # create a label encoder with 'acgtn' alphabet from sklearn.preprocessing import LabelEncoder label_encoder = LabelEncoder() label_encoder.fit(np.array(['a','c','g','t','z'])) # function to one-hot encode a DNA sequence string # non 'acgt' bases (n) are 0000 # returns a L x 4 numpy array from sklearn.preprocessing import OneHotEncoder def one_hot_encoder(my_array): integer_encoded = label_encoder.transform(my_array) onehot_encoder = OneHotEncoder(sparse=False, dtype=int) integer_encoded = integer_encoded.reshape(len(integer_encoded), 1) onehot_encoded = onehot_encoder.fit_transform(integer_encoded) return onehot_encoded global one_hot_matrix global index_to_delete one_hot_matrix = [] index_to_delete = [] def encoder(data): one_hot_matrix = [] for i in range(len(data)): one_hot_matrix.append(one_hot_encoder(string_to_array(data[0][i]))) return one_hot_matrix def delete(one_hot_matrix): for i in range(len(data)): if one_hot_matrix[i].shape != (500,4): index_to_delete.append(i) #one_hot_matrix = [one_hot_matrix[i] for i in range(0, len(one_hot_matrix),1) if i not in index_to_delete] return index_to_delete def labels_marker(histone, nums): labels = data.iloc[:len(data),1] #labels.drop(index = index_to_delete, axis = 0, inplace = True) labels.to_csv('labels_{a}_{b}.txt'.format(a=histone, b=nums),sep = '\\t',index = False) print(labels.shape) def dataset(histone,nums): global index_to_delete data.drop(index = index_to_delete, axis = 0,inplace = True) data.to_csv('dataset_{a}_{b}.txt'.format(a=histone, b=nums),sep = '\\t',index = False) #os.system(\"sed -i '1d' 'dataset_{a}_{b}.txt'.format(a=histone, b=nums)\") def save(histone,nums): global one_hot_matrix np.save('onehot_{a}_{b}'.format(a=histone, b=nums),one_hot_matrix) one = np.load('onehot_{a}_{b}.npy'.format(a=histone, b=nums),allow_pickle=True) print(one.shape) if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"data choice out\") parser.add_argument(\"-i\", \"--dataset\", metavar=\"\", required=True, help=\"dataset\") parser.add_argument(\"-c\", \"--choice\", metavar=\"\", required=True,default='make', help=\"make or check\") parser.add_argument(\"-m\", \"--histone\", metavar=\"\" , help=\"hitone modifications\") parser.add_argument(\"-n\", \"--nums\", metavar=\"\", help=\"number of samples\") args = parser.parse_args() # 读取数据集 data = pd.read_csv('%s'%(args.dataset) ,sep = '\\t',header = None) # 编码 one_hot_matrix = encoder(data) if args.choice == 'check': index_to_delete = delete(one_hot_matrix) dataset(args.histone, args.nums) elif args.choice == 'make': labels_marker(args.histone, args.nums) save(args.histone, args.nums) else: print('There is no choice') OneHotEncoder3.0 1.输出npz文件包含['keys', 'DNAseq', 'labels'] --make save() ,保证三者的shape，并且能够输出检查 2.labels的onehot 编码函数，按照数字进行onehot编码 3.导入target文件，并且将keys和labels分开 4.np.delete(labels,0,2)删除标签onehot第一列（0） # coding: utf-8 import numpy as np import pandas as pd import torch import os import sys import argparse from collections import defaultdict # function to convert a DNA sequence string to a numpy array # converts to lower case, changes any non 'acgt' characters to 'n' import re def string_to_array(my_string): my_string = my_string.lower() my_string = re.sub('[^acgt]', 'z', my_string) my_array = np.array(list(my_string)) return my_array # create a label encoder with 'acgtn' alphabet from sklearn.preprocessing import LabelEncoder label_encoder = LabelEncoder() label_encoder.fit(np.array(['a','c','g','t','z'])) # function to one-hot encode a DNA sequence string # non 'acgt' bases (n) are 0000 # returns a L x 4 numpy array from sklearn.preprocessing import OneHotEncoder def one_hot_encoder(my_array): integer_encoded = label_encoder.transform(my_array) onehot_encoder = OneHotEncoder(sparse=False, dtype=int) integer_encoded = integer_encoded.reshape(len(integer_encoded), 1) onehot_encoded = onehot_encoder.fit_transform(integer_encoded) return onehot_encoded def dense_to_one_hot(labels_dense, num_classes): \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\" num_labels = labels_dense.shape[0] index_offset = np.arange(num_labels) * num_classes labels_one_hot = np.zeros((num_labels, num_classes)) labels_one_hot.flat[index_offset+labels_dense.ravel()] = 1 return labels_one_hot global one_hot_matrix global index_to_delete one_hot_matrix = [] index_to_delete = [] def encoder(data): one_hot_matrix = [] for i in range(len(data)): one_hot_matrix.append(one_hot_encoder(string_to_array(data[0][i]))) return one_hot_matrix def delete(one_hot_matrix): for i in range(len(data)): if one_hot_matrix[i].shape != (500,4): index_to_delete.append(i) #one_hot_matrix = [one_hot_matrix[i] for i in range(0, len(one_hot_matrix),1) if i not in index_to_delete] return index_to_delete def labels_marker(): #labels = data.iloc[:len(data),1] labels_dense = np.array(data[2].tolist()) num_classes = 6 labels = dense_to_one_hot(labels_dense, num_classes) labels = labels.reshape(len(data), 1,6) labels = np.delete(labels,0,2) return labels #labels.drop(index = index_to_delete, axis = 0, inplace = True) #labels.to_csv('labels_{a}_{b}.txt'.format(a=histone, b=nums),sep = '\\t',index = False) #print(labels.shape) def dataset(): global index_to_delete data.drop(index = index_to_delete, axis = 0,inplace = True) data.to_csv('dataset_rice_all.txt',sep = '\\t',index = False) dataset = open('dataset_rice_all.txt').readlines() dataset[1] = '' with open('dataset_rice_all.txt','w') as f: f.writelines(dataset) #os.system(\"sed -i '1d' 'dataset_{a}_{b}.txt'.format(a=histone, b=nums)\") def save(labels): global one_hot_matrix one_hot_matrix = np.array(one_hot_matrix) print(one_hot_matrix.shape) one_hot_matrix = one_hot_matrix.reshape(len(data),1,4,500) keys = np.array(data[1].tolist()) np.savez('./onehot_rice.npz',keys = keys, DNAseq = one_hot_matrix, labels = labels) with np.load('onehot_rice.npz') as f: indexs = f['keys'] dna = f['DNAseq'] labels = f['labels'] print(indexs.shape, dna.shape, labels.shape) #one = np.load('onehot_{a}_{b}.npy'.format(a=histone, b=nums),allow_pickle=True) #print(one.shape) if __name__ == '__main__': parser = argparse.ArgumentParser(description=\"data choice out\") parser.add_argument(\"-i\", \"--dataset\", metavar=\"\", required=True, help=\"dataset\") parser.add_argument(\"-c\", \"--choice\", metavar=\"\", required=True,default='make', help=\"make or check\") args = parser.parse_args() # 读取数据集 data = pd.read_csv('%s'%(args.dataset) ,sep = '\\t',header = None) # 编码 one_hot_matrix = encoder(data) if args.choice == 'check': index_to_delete = delete(one_hot_matrix) dataset() elif args.choice == 'make': labels = labels_marker() save(labels) else: print('There is no choice') 生成数据集总流程（bash脚本） rice/scripts/sh_scripts id_geno C019 C051 C135 C139 C145 C146 C147 C148 C151 W081 W105 W125 W128 W161 W169 W257 W261 W286 W294 W306 id_sp C019 C051 C135 C139 ZS97 Nip MH63 C148 C151 W081 W105 W125 W128 W161 W169 W257 W261 W286 W294 W306 生成品种基因型 #!/bin/bash #生成品种基因型，参考基因组日本晴第七版 for i in $(cat id_geno) do bsub -q high -e ${i}.err -o ${i}.out \"python3 scripts/py_scripts/geno_sub2.0.py -s data/vcf/sort.total.vcf -n ${i} -r data/ref/IRGSP-1.0_genome.fasta -l 500\" done samtools #!/bin/bash #使用samtools对基因型进行注释 for i in $(cat id_geno) do samtools faidx ${i}.fasta done #!/bin/bash #将原始基因型的名字改为品种名 for i in $(cat id_geno) do if ${i}.fasta.fai == C145.fasta.fai do mv ${i}.fasta.fai ZS97.fasta.fai elif ${i}.fasta.fai == C146.fasta.fai do mv ${i}.fasta.fai Nip.fasta.fai elif ${i}.fasta.fai == C147.fasta.fai do mv ${i}.fasta.fai MH63.fasta.fai done 提取peak范围 #!/bin/bash for n in $(cat histone) do for i in $(cat id_sp) do awk '{print $1,$2,$3}' mapto*/${n}_seedlings/*${i}_peaks.*Peak | sort -t ' ' -k1.4nr | sort -k1,1V -k2,2n -k3,3n > data/signal_area/sort_${i}_${n}.bed done done 生成组蛋白修饰标签 #!/bin/bash for n in $(cat histone) do for i in $(cat id_sp) do python3 scripts/py_scripts/target_mark5.0.py -f data/sequence/${i}.fasta.fai -b data/signal_area/sort_${i}_${n}.bed -o target_${i}_${n}_2.bed -s ${i} -m ${n} && paste data/seq/${i}_2.fasta target_${i}_${n}_2.bed | awk '$3 != 0 {print}' >> dataset_rice_raw.csv | awk '{print $3}' | uniq -c done done data/seq文件夹中无\">\" 数据预处理(check) bsub -q high -e check.err -o check.out 'python3 scripts/py_scripts/OneHotEncoder3.0.py -i dataset_rice_raw -c check' awk '{print $1,$3}' sed -i '/N/d' awk '$2 == 2 {print}' ../dataset_all_90w.txt | awk -v OFS=\"\\t\" '{if ($2 != 0) $3 = 1}1' >> H3K27ac.txt bsub -q high 'shuf -n243105 dataset_0.txt >> H3K4me3.txt' 编码onehot bsub -q high -e make.err -o make.out 'python3 OneHotEncoder3.0.py -i dataset_rice_all -c make' 生成Transformer数据集 提取$1和$3，然后与等数量的阴性样本连接 awk '{print $1,$3}' dataset_rice_all.txt > dataser_trans.txt "},"实验流程/构建模型.html":{"url":"实验流程/构建模型.html","title":"构建模型","keywords":"","body":"构建模型 构建基本模型（pytorch） 初步实验在恒源云服务器上进行 导入模块 import numpy as np import pandas as pd import torch from torch.utils import data import time from torch import nn, optim import sys 设置GPU device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') 数据导入及格式转换 data_np = np.load('./one_hot.npy') target_pd =pd.read_csv('./target6.txt',sep = '\\n') #转换成tensor data_tensor = torch.from_numpy(data_np) target_array = np.array(target_pd) target_tensor = torch.tensor(target_array) #转置成(4，500) data_tensor = data_tensor.reshape(10000,4,500) #转换成float（后续模型输入需要） data_tensor = data_tensor.float() target_tenor = target_tensor.float() 构建训练集和验证集（TensorDataset类和DataLoader类） class TensorDataset(data.Dataset): \"\"\"Dataset wrapping data and target tensors. Each sample will be retrieved by indexing both tensors along the first dimension. Arguments: data_tensor (Tensor): contains sample data. target_tensor (Tensor): contains sample targets (labels). \"\"\" def __init__(self, data_tensor, target_tensor): assert data_tensor.size(0) == target_tensor.size(0) self.data_tensor = data_tensor self.target_tensor = target_tensor def __getitem__(self, index): return self.data_tensor[index], self.target_tensor[index] def __len__(self): return len(self.data_tensor) train_data = TensorDataset(data_tensor[0:9000], target_tensor[0:9000]) val_data = TensorDataset(data_tensor[9000:10000], target_tensor[9000:10000]) train_dataloader = data.DataLoader(train_data,batch_size = 200, shuffle=True,num_workers=0) val_dataloader = data.DataLoader(val_data,batch_size = 200, shuffle=False,num_workers=0) DeepSEA 为防止过拟合增大泛化能力，在卷积层后加入BN层（归一化） class DeepSEA(nn.Module): def __init__(self, sequence_length=500, n_genomic_features=2): \"\"\" Parameters ---------- sequence_length : int n_genomic_features : int \"\"\" super(DeepSEA, self).__init__() conv_kernel_size = 8 pool_kernel_size = 4 self.conv_net = nn.Sequential( nn.Conv1d(4, 320, kernel_size=conv_kernel_size), nn.BatchNorm1d(320), nn.ReLU(inplace=True), nn.MaxPool1d( kernel_size=pool_kernel_size, stride=pool_kernel_size), nn.Dropout(p=0.2), nn.Conv1d(320, 480, kernel_size=conv_kernel_size), nn.BatchNorm1d(480), nn.ReLU(inplace=True), nn.MaxPool1d( kernel_size=pool_kernel_size, stride=pool_kernel_size), nn.Dropout(p=0.2), nn.Conv1d(480, 960, kernel_size=conv_kernel_size), nn.BatchNorm1d(960), nn.ReLU(inplace=True), nn.Dropout(p=0.5)) reduce_by = conv_kernel_size - 1 self.n_channels = int( np.floor( (np.floor( (sequence_length - reduce_by) / pool_kernel_size) - reduce_by) / pool_kernel_size) - reduce_by) self.classifier = nn.Sequential( nn.Linear(960 * self.n_channels, n_genomic_features), nn.ReLU(inplace=True), nn.Linear(n_genomic_features, n_genomic_features), nn.Sigmoid()) def forward(self, x): \"\"\"Forward propagation of a batch. \"\"\" out = self.conv_net(x) reshape_out = out.view(out.size(0), 960 * self.n_channels) predict = self.classifier(reshape_out) return predict 创建训练函数 损失函数：CrossEntropyLoss def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs): net = net.to(device) print(\"training on \", device) loss = torch.nn.CrossEntropyLoss() for epoch in range(num_epochs): train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time() for X, y in train_iter: X = X.to(device) y = y.to(device) y_hat = net(X) y = y.squeeze() l = loss(y_hat, y) optimizer.zero_grad() l.backward() optimizer.step() train_l_sum += l.cpu().item() train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item() n += y.shape[0] batch_count += 1 test_acc = evaluate_accuracy(test_iter, net) print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start)) 创建准确率计算函数 def evaluate_accuracy(data_iter, net, device=None): if device is None and isinstance(net, torch.nn.Module): device = list(net.parameters())[0].device acc_sum, n = 0.0, 0 with torch.no_grad(): for X, y in data_iter: if isinstance(net, torch.nn.Module): net.eval() # 评估模式, 这会关闭dropout acc_sum += (net(X.to(device)).argmax(dim=1)==y.to(device).squeeze()).float().sum().cpu().item() net.train() # 改回训练模式 else: if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数 # 将is_training设置成False acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() else: acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() n += y.shape[0] return acc_sum / n 开启训练 超参数 lr 学习率 num_epochs 训练批次 优化器：Adam 优化器：SGD lr, num_epochs = 0.001, 10 optimizer = torch.optim.SGD(net.parameters(), lr=lr) train(net, train_dataloader, val_dataloader, 256, optimizer, device, num_epochs) 训练结果可视化 更新train函数 恒源云 logger.log_value('loss', train_l_sum/batch_count, epoch*len(train_iter) + batch_count) logger.log_value('train_acc', 100. *train_acc_sum / n, epoch*len(train_iter) + batch_count) logger.log_value('val_acc',test_acc,epoch) TensorBoard_logger from tensorboard_logger import Logger logger = Logger(logdir=\"./tb_logs\", flush_secs=10)#设置输出的log文件位置 def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs): net = net.to(device) print(\"training on \", device) loss = torch.nn.CrossEntropyLoss() for epoch in range(num_epochs): train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time() for X, y in train_iter: X = X.to(device) y = y.to(device) y_hat = net(X) y = y.squeeze() l = loss(y_hat, y) optimizer.zero_grad() l.backward() optimizer.step() train_l_sum += l.cpu().item() train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item() n += y.shape[0] batch_count += 1 test_acc = evaluate_accuracy(test_iter, net) logger.log_value('loss', train_l_sum/batch_count, epoch*len(train_iter) + batch_count) logger.log_value('train_acc', 100. *train_acc_sum / n, epoch*len(train_iter) + batch_count) logger.log_value('val_acc',test_acc,epoch) print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start)) 模型框架 文件组织架构 /public/home/xwli/xwzhang/deeplearningDATA/rice/pytorch_deepsea ├── checkpoints/ ├── data/ │ ├── __init__.py │ ├── dataset.py │ ├── models/ │ ├── __init__.py │ ├── DeepSEA.py │ │ └── utils/ │ ├── __init__.py │ └── visualize.py ├── config.py ├── main.py ├── README.md 数据加载模块 #dataset.py from torch.utils import data class TensorDataset(data.Dataset): \"\"\"Dataset wrapping data and target tensors. Each sample will be retrieved by indexing both tensors along the first dimension. Arguments: data_tensor (Tensor): contains sample data. target_tensor (Tensor): contains sample targets (labels). \"\"\" def __init__(self, data_tensor, target_tensor): assert data_tensor.size(0) == target_tensor.size(0) self.data_tensor = data_tensor self.target_tensor = target_tensor def __getitem__(self, index): return self.data_tensor[index], self.target_tensor[index] def __len__(self): return len(self.data_tensor) 模型定义模块 # coding: utf-8 import torch import time class BasicModule(torch.nn.Module): ''' 封装了nn.Module，主要提供save和load两个方法 ''' def __init__(self,opt=None): super(BasicModule,self).__init__() self.model_name = str(type(self)) # 模型的默认名字 def load(self, path): ''' 可加载指定路径的模型 ''' self.load_state_dict(torch.load(path)) def save(self, name=None): ''' 保存模型，默认使用“模型名字+时间”作为文件名， 如AlexNet_0710_23:57:29.pth ''' if name is None: prefix = 'checkpoints/' + self.model_name + '_' name = time.strftime(prefix + '%m%d_%H:%M:%S.pth') torch.save(self.state_dict(), name) return name #__init__.py from .DeepSEA import DeepSEA #from .new_module import NewModule # coding: utf-8 import numpy as np from torch import nn from .BasicModule import BasicModule class DeepSEA(nn.Module): def __init__(self, sequence_length=500, n_genomic_features=2): \"\"\" Parameters ---------- sequence_length : int n_genomic_features : int \"\"\" super(DeepSEA, self).__init__() conv_kernel_size = 8 pool_kernel_size = 4 self.conv_net = nn.Sequential( nn.Conv1d(4, 320, kernel_size=conv_kernel_size), nn.ReLU(inplace=True), nn.MaxPool1d( kernel_size=pool_kernel_size, stride=pool_kernel_size), nn.Dropout(p=0.2), nn.Conv1d(320, 480, kernel_size=conv_kernel_size), nn.ReLU(inplace=True), nn.MaxPool1d( kernel_size=pool_kernel_size, stride=pool_kernel_size), nn.Dropout(p=0.2), nn.Conv1d(480, 960, kernel_size=conv_kernel_size), nn.ReLU(inplace=True), nn.Dropout(p=0.5)) reduce_by = conv_kernel_size - 1 self.n_channels = int( np.floor( (np.floor( (sequence_length - reduce_by) / pool_kernel_size) - reduce_by) / pool_kernel_size) - reduce_by) self.classifier = nn.Sequential( nn.Linear(960 * self.n_channels, n_genomic_features), nn.ReLU(inplace=True), nn.Linear(n_genomic_features, n_genomic_features), nn.Sigmoid() ) def forward(self, x): \"\"\"Forward propagation of a batch. \"\"\" out = self.conv_net(x) reshape_out = out.view(out.size(0), 960 * self.n_channels) predict = self.classifier(reshape_out) return predict 工具函数 #coding:utf8 #visualize.py import visdom import time import numpy as np class Visualizer(object): ''' 封装了visdom的基本操作，但是你仍然可以通过`self.vis.function` 或者`self.function`调用原生的visdom接口 比如 self.text('hello visdom') self.histogram(t.randn(1000)) self.line(t.arange(0, 10),t.arange(1, 11)) ''' def __init__(self, env='default', **kwargs): self.vis = visdom.Visdom(env=env, **kwargs) # 画的第几个数，相当于横坐标 # 比如（’loss',23） 即loss的第23个点 self.index = {} self.log_text = '' def reinit(self, env='default', **kwargs): ''' 修改visdom的配置 ''' self.vis = visdom.Visdom(env=env, **kwargs) return self def plot_many(self, d): ''' 一次plot多个 @params d: dict (name, value) i.e. ('loss', 0.11) ''' for k, v in d.iteritems(): self.plot(k, v) def img_many(self, d): for k, v in d.iteritems(): self.img(k, v) def plot(self, name, y, **kwargs): ''' self.plot('loss', 1.00) ''' x = self.index.get(name, 0) self.vis.line(Y=np.array([y]), X=np.array([x]), win=unicode(name), opts=dict(title=name), update=None if x == 0 else 'append', **kwargs ) self.index[name] = x + 1 def img(self, name, img_, **kwargs): ''' self.img('input_img', t.Tensor(64, 64)) self.img('input_imgs', t.Tensor(3, 64, 64)) self.img('input_imgs', t.Tensor(100, 1, 64, 64)) self.img('input_imgs', t.Tensor(100, 3, 64, 64), nrows=10) ''' self.vis.images(img_.cpu().numpy(), win=unicode(name), opts=dict(title=name), **kwargs ) def log(self, info, win='log_text'): ''' self.log({'loss':1, 'lr':0.0001}) ''' self.log_text += ('[{time}] {info} '.format( time=time.strftime('%m%d_%H%M%S'),\\ info=info)) self.vis.text(self.log_text, win) def __getattr__(self, name): ''' self.function 等价于self.vis.function 自定义的plot,image,log,plot_many等除外 ''' return getattr(self.vis, name) 配置文件 #config.py class DefaultConfig(object): env = 'default' # visdom 环境 model = 'DeepSEA' # 使用的模型，名字必须与models/__init__.py中的名字一致 train_data_root = './data/one_hot_10w_sh.npy' # 训练集存放路径 test_data_root = './data/test1' # 测试集存放路径 target_data_root = './data/target_10w_sh.txt' load_model_path = 'checkpoints/model.pth' # 加载预训练的模型的路径，为None代表不加载 batch_size = 256 # batch size use_gpu = True # use GPU or not num_workers = 2 # how many workers for loading data print_freq = 20 # print info every N batch #debug_file = '/tmp/debug' # if os.path.exists(debug_file): enter ipdb result_file = 'result.csv' num_epochs = 10 lr = 0.01 # initial learning rate lr_decay = 0.95 # when val_loss increase, lr = lr*lr_decay weight_decay = 1e-4 # 损失函数 def parse(self, kwargs): ''' 根据字典kwargs 更新 config参数 ''' # 更新配置参数 for k, v in kwargs.items(): ''' if not hasattr(self, k): # 警告还是报错，取决于你个人的喜好 warnings.warn(\"Warning: opt has not attribut %s\" %k) ''' setattr(self, k, v) # 打印配置信息 print('user config:') for k, v in self.__class__.__dict__.items(): if not k.startswith('__'): print(k, getattr(self, k)) DefaultConfig.parse = parse opt =DefaultConfig() 主函数 #main.py from config import opt import os import torch from torch.utils import data import models import numpy as np import pandas as pd from data.dataset import TensorDataset from torch.utils.data import DataLoader #from torch.autograd import Variable #from torchnet import meter #from utils.visualize import Visualizer #from tqdm import tqdm import time def evaluate_accuracy(data_iter, net, device=None): if device is None and isinstance(net, torch.nn.Module): # 如果没指定device就使用net的device device = list(net.parameters())[0].device acc_sum, n = 0.0, 0 with torch.no_grad(): for X, y in data_iter: ''' if isinstance(net, torch.nn.Module): net.eval() # 评估模式, 这会关闭dropout acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item() net.train() # 改回训练模式 else: if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数 # 将is_training设置成False acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() else: acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() ''' acc_sum += (net(X.to(device)).argmax(dim=1) == (y.to(device).squeeze())).float().sum().cpu().item() n += y.shape[0] return acc_sum / n def train(**kwargs): opt.parse(kwargs) #vis = Visualizer(opt.env) model = getattr(models, opt.model)() ''' if opt.load_model_path: model.load(opt.load_model_path) if opt.use_gpu: model.cuda() ''' device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') print(\"training on \", device) data_np = np.load(opt.train_data_root) data_tensor = torch.from_numpy(data_np) target_pd =pd.read_csv(opt.target_data_root,sep = '\\n',header = None) target_array = np.array(target_pd) target_tensor = torch.tensor(target_array) data_tensor = data_tensor.reshape(100000,4,500) data_tensor = data_tensor.float() target_tenor = target_tensor.float() train_data = TensorDataset(data_tensor[0:99000], target_tensor[0:99000]) val_data = TensorDataset(data_tensor[99000:100000], target_tensor[99000:100000]) train_dataloader = data.DataLoader(train_data,batch_size = 200, shuffle=True,num_workers=0) val_dataloader = data.DataLoader(val_data,batch_size = 200, shuffle=False,num_workers=0) loss = torch.nn.CrossEntropyLoss() lr = opt.lr optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay = opt.weight_decay) for epoch in range(opt.num_epochs): model = model.to(device) train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time() for X, y in train_dataloader: X = X.to(device) y = y.to(device) y_hat = model(X) y = y.squeeze() l = loss(y_hat, y) optimizer.zero_grad() l.backward() optimizer.step() train_l_sum += l.cpu().item() train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item() n += y.shape[0] batch_count += 1 test_acc = evaluate_accuracy(val_dataloader, model) print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start)) #model.save() def val(model, dataloader): ''' 计算模型在验证集上的准确率等信息，用以辅助训练 ''' pass def test(**kwargs): ''' 测试（inference） ''' pass def help(): ''' 打印帮助的信息 ''' print('help') if __name__=='__main__': import fire fire.Fire() DeepHistone 参考文献： DeepHistone: a deep learning approach to predicting histone modification github：https://github.com/QijinYin/DeepHistone. 模型架构 三个模块：DNA module ，DNase module， joint module DNA and DNase module： densely connected convolutional neural network joint module： distinguish histone modification sites of a marker from those of other markers 图片来自参考文献 DenseNet 图片来自参考文献 利用前面所有层与后面层的“短路连接”来实现特征重用，具有更高的性能，更少的参数量 参考文献： 论文：Densely Connected Convolutional Networks 模型详解： https://blog.csdn.net/u014380165/article/details/75142664 https://zhuanlan.zhihu.com/p/37189203 数据集格式改良 labels onehot encoder 可以将此函数加入OneHotEncoder import numpy as np def dense_to_one_hot(labels_dense, num_classes): \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\" num_labels = labels_dense.shape[0] index_offset = np.arange(num_labels) * num_classes labels_one_hot = np.zeros((num_labels, num_classes)) labels_one_hot.flat[index_offset+labels_dense.ravel()] = 1 return labels_one_hot labels_dense = np.array([0,1,2,3,4]) num_classes = 5 dense_to_one_hot(labels_dense,num_classes) 继续改进target_mark.py : 将组蛋白修饰（m）与数字标签对应，同时改良每种组蛋白的标记方法 npz封装：将npz封装也加入OneHotEncoder，加入到make np.savez('C:/Users/12394/PycharmProjects/Spyder/data.npz',a = a, b = b) 1.将5种组蛋白修饰阳性样本集中在一个数据集 2.reshape(len(data),1,4,500) OneHotEncoder3.0.py完成 bsub -q high -e 12.err -o 12.out 'python3 scripts/py_scripts/OneHotEncoder3.0.py -i dataset_ex1_10w.txt -c make -m ex1 -n 10w' Keys DNA seq labels (nums,) (nums, 1 , 4 , 500 ) (nums ,1, 5) species_histone_chr_start_end onehot onehot DNA-only（DNA module） /public/home/xwli/xwzhang/deeplearningDATA/rice/DeepHistone/ ├── data/ ├── results/ │ └── model.txt │ └── label.txt │ └── pred.txt ├── model_dna.py ├── utils_dna.py ├── train_dna.py model_dna.py import numpy as np import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torch.autograd import Variable from sklearn import metrics from torch.optim import Optimizer import math from torch.nn.parameter import Parameter class BasicBlock(nn.Module): def __init__(self, in_planes, grow_rate,): super(BasicBlock, self).__init__() self.block = nn.Sequential( nn.BatchNorm2d(in_planes), nn.ReLU(), nn.Conv2d(in_planes, grow_rate, (1,9), 1, (0,4)), #nn.Dropout2d(0.2) ) def forward(self, x): out = self.block(x) return torch.cat([x, out],1) class DenseBlock(nn.Module): def __init__(self, nb_layers, in_planes, grow_rate,): super(DenseBlock, self).__init__() layers = [] for i in range(nb_layers): layers.append(BasicBlock(in_planes + i*grow_rate, grow_rate,)) self.layer = nn.Sequential(*layers) def forward(self, x): return self.layer(x) class ModuleDense(nn.Module): def __init__(self): super(ModuleDense, self).__init__() self.conv1 = nn.Sequential( nn.Conv2d(1,128,(4,9),1,(0,4)), #nn.Dropout2d(0.2), ) self.block1 = DenseBlock(3, 128, 128) self.trans1 = nn.Sequential( nn.BatchNorm2d(128+3*128), nn.ReLU(), nn.Conv2d(128+3*128, 256, (1,1),1), #nn.Dropout2d(0.2), nn.MaxPool2d((1,4)), ) self.block2 = DenseBlock(3,256,256) self.trans2 = nn.Sequential( nn.BatchNorm2d(256+3*256), nn.ReLU(), nn.Conv2d(256+3*256, 512, (1,1),1), #nn.Dropout2d(0.2), nn.MaxPool2d((1,4)), ) self.out_size = 500 // 4 // 4 * 512 def forward(self, seq): n, h, w = seq.size() seq = seq.view(n,1,4,w) out = self.conv1(seq) out = self.block1(out) out = self.trans1(out) out = self.block2(out) out = self.trans2(out) n, c, h, w = out.size() out = out.view(n,c*h*w) return out class NetDeepHistone(nn.Module): def __init__(self): super(NetDeepHistone, self).__init__() print('DeepHistone(Dense) is used.') self.seq_map = ModuleDense() self.seq_len = self.seq_map.out_size seq_len = self.seq_len self.linear_map = nn.Sequential( nn.Dropout(0.5), nn.Linear(int(seq_len),925), nn.BatchNorm1d(925), nn.ReLU(), #nn.Dropout(0.1), nn.Linear(925,5), nn.Sigmoid(), ) def forward(self, seq): flat_seq = self.seq_map(seq) out = self.linear_map(flat_seq) return out class DeepHistone(): def __init__(self,use_gpu,learning_rate=0.001): self.forward_fn = NetDeepHistone() self.criterion = nn.BCELoss() self.optimizer = optim.Adam(self.forward_fn.parameters(), lr=learning_rate, weight_decay = 0) self.use_gpu = use_gpu if self.use_gpu : self.criterion,self.forward_fn = self.criterion.cuda(), self.forward_fn.cuda() def updateLR(self, fold): for param_group in self.optimizer.param_groups: param_group['lr'] *= fold def train_on_batch(self,seq_batch,lab_batch,): self.forward_fn.train() seq_batch = Variable(torch.Tensor(seq_batch)) lab_batch = Variable(torch.Tensor(lab_batch)) if self.use_gpu: seq_batch, lab_batch = seq_batch.cuda(), lab_batch.cuda() output = self.forward_fn(seq_batch) loss = self.criterion(output,lab_batch) self.optimizer.zero_grad() loss.backward() self.optimizer.step() return loss.cpu().data def eval_on_batch(self,seq_batch,lab_batch,): self.forward_fn.eval() seq_batch = Variable(torch.Tensor(seq_batch)) lab_batch = Variable(torch.Tensor(lab_batch)) if self.use_gpu: seq_batch, lab_batch = seq_batch.cuda(), lab_batch.cuda() output = self.forward_fn(seq_batch) loss = self.criterion(output,lab_batch) return loss.cpu().data,output.cpu().data.numpy() def test_on_batch(self, seq_batch): self.forward_fn.eval() seq_batch = Variable(torch.Tensor(seq_batch)) if self.use_gpu: seq_batch = seq_batch.cuda() output = self.forward_fn(seq_batch) pred = output.cpu().data.numpy() return pred def save_model(self, path): torch.save(self.forward_fn.state_dict(), path) def load_model(self, path): self.forward_fn.load_state_dict(torch.load(path)) untils_dna.py 在原函数的基础上增加了MCC，Specificity和Sensitivity的计算函数，现在有三个具体评估指标 from sklearn.metrics import auc,roc_auc_score,precision_recall_curve,matthews_corrcoef,precision_score,recall_score import numpy as np histones=['H3K4me3','H3K27ac','H3K4me1','H3K27me3','H3K9me2'] def loadRegions(regions_indexs,dna_dict,label_dict,): if dna_dict is not None: dna_regions = np.concatenate([dna_dict[meta] for meta in regions_indexs],axis=0) else: dna_regions =[] label_regions = np.concatenate([label_dict[meta] for meta in regions_indexs],axis=0).astype(int) return dna_regions,label_regions def model_train(regions,model,batchsize,dna_dict,label_dict,): train_loss = [] regions_len = len(regions) for i in range(0, regions_len , batchsize): regions_batch = [regions[i+j] for j in range(batchsize) if (i+j) train_dna.py from model_dna import DeepHistone import copy import numpy as np from utils_dna import metrics,model_train,model_eval,model_predict import torch #setting batchsize=20 train_file = 'onehot_rice_train.npz' test_file = 'onehot_rice_test.npz' model_save_file = 'results/model.txt' lab_save_file ='results/label.txt' pred_save_file ='results/pred.txt' print('Begin loading data...') with np.load(train_file) as f: indexs = f['keys'] dna_dict = dict(zip(f['keys'],f['DNAseq'])) lab_dict = dict(zip(f['keys'],f['labels'])) np.random.shuffle(indexs) idx_len = len(indexs) train_index=indexs[:int(idx_len*4/5)] valid_index=indexs[int(idx_len*4/5):] use_gpu = torch.cuda.is_available() model = DeepHistone(use_gpu) print('Begin training model...') best_model = copy.deepcopy(model) best_valid_auPRC=0 best_valid_loss = np.float64('Inf') for epoch in range(50): np.random.shuffle(train_index) train_loss= model_train(train_index,model,batchsize,dna_dict,lab_dict,) valid_loss,valid_lab,valid_pred,valid_truths= model_eval(valid_index, model,batchsize,dna_dict,lab_dict,) valid_auPRC,valid_auROC,valid_MCC,valid_Spec,valid_Sen= metrics(valid_lab,valid_pred,valid_truths,'Valid',valid_loss) if np.mean(list(valid_auPRC.values())) >best_valid_auPRC: best_model = copy.deepcopy(model) if valid_loss = 5: break print('Begin predicting...') with np.load(test_file) as f: indexs2 = f['keys'] dna_dict2 = dict(zip(f['keys'],f['DNAseq'])) lab_dict2 = dict(zip(f['keys'],f['labels'])) np.random.shuffle(indexs2) idx_len2 = len(indexs) for i in range(5): test_index=indexs2[int((i/5)*idx_len2):int(((i+1)/5)*idx_len2)] test_lab,test_pred,test_truths = model_predict(test_index,best_model,batchsize,dna_dict2,lab_dict2,) test_auPR,test_roc,test_MCC,test_Spec,test_Sen= metrics(test_lab,test_pred,test_truths,'Test') print('Begin saving...') np.savetxt(lab_save_file, test_lab, fmt='%d', delimiter='\\t') np.savetxt(pred_save_file, test_pred, fmt='%.4f', delimiter='\\t') best_model.save_model(model_save_file) torch.save(model,'model1.pth') print('Finished.') 构建总数据集 20个品种5种组蛋白修饰所有阳性 histone modifications nums H3K4me3（1） 256721 H3K27ac（2） 227526 H3K4me1（3） 152355 H3K27me3（4） 136028 H3K9me2（5） 118142 total 890772 total（after check） 887724 #!/bin/bash for n in $(cat histone) do for i in $(cat id.txt) do python3 target_mark5.0.py -f ${i}.fasta.fai -b data/signal_area/sort_${i}.bed -o target_${i}_${n}.bed -s ${i} -m ${n} && paste $[i}.fasta target_${i}_${n}.bed > data/dataset/ex1/${n}.csv && awk '$3 != 0 {print}' data/dataset/ex1/${n}.csv >> dataset_all.csv | awk '{print $3}' | uniq -c done done bsub -q gpu -o deep_histone_result.out -e histone.err 'python3 train_dna.py' Nt_Transformer 参考文献： NUCLEIC TRANSFORMER: DEEP LEARNING ON NUCLEIC ACIDS WITH SELF-ATTENTION AND CONVOLUTIONS github:https://github.com/Shujun-He/Nucleic-Transformer Transformer：Attention is All You Need 参考文献： Attention Is All You Need 论文解析： https://blog.csdn.net/weixin_42431920/article/details/110731751 https://zhuanlan.zhihu.com/p/48508221 https://www.bilibili.com/video/BV1Di4y1c7Zm?from=search&seid=15155897634554281203 学习笔记 模型架构 /public/home/xwli/xwzhang/deeplearningDATA/rice/Nt_Transformer/ ├── data/ ├── results/ │ └── model.txt │ └── label.txt │ └── pred.txt ├── Dataset.py ├── evalute_test.py ├── Functions.py ├── Logger.py ├── LrScheduler.py ├── Metrics.py ├── Network.py ├── train.py ├── run.sh ├── test.sh Dataset.py import pickle import os import numpy as np import pandas as pd from tqdm import tqdm import torch nt_int={ \"A\": 0, \"T\": 1, \"G\": 2, \"C\": 3,} def nucleatide2int(nt_sequence,target_length=None): int_sequence=[] for nt in nt_sequence: nt=nt.upper() if nt in nt_int: int_sequence.append(nt_int[nt]) int_sequence=np.asarray(int_sequence,dtype='int32') if target_length: int_sequence=np.pad(int_sequence,(0,target_length-len(int_sequence)),constant_values=-1) return int_sequence class ViraminerDataset(torch.utils.data.Dataset): def __init__(self,sequences,labels): self.data=[] for seq in sequences: self.data.append(nucleatide2int(seq)) self.data=np.asarray(self.data,dtype='int') self.labels=np.asarray(labels,dtype='int') print(self.data.shape) print(self.labels.shape) def __len__(self): return len(self.labels) def __getitem__(self,idx): return {'data':self.data[idx], 'labels':self.labels[idx]} evalute_test.py import os import torch import torch.nn as nn import time from Functions import * from Dataset import * from Network import * from LrScheduler import * import Metrics from Logger import CSVLogger import argparse try: #from apex.parallel import DistributedDataParallel as DDP from apex.fp16_utils import * from apex import amp, optimizers from apex.multi_tensor_apply import multi_tensor_applier except ImportError: raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to run this example.\") from tqdm import tqdm def get_args(): parser = argparse.ArgumentParser() parser.add_argument('--gpu_id', type=str, default='0,1', help='which gpu to use') parser.add_argument('--path', type=str, default='../', help='path of csv file with DNA sequences and labels') parser.add_argument('--epochs', type=int, default=150, help='number of epochs to train') parser.add_argument('--batch_size', type=int, default=24, help='size of each batch during training') parser.add_argument('--weight_decay', type=float, default=0, help='weight dacay used in optimizer') parser.add_argument('--ntoken', type=int, default=4, help='number of tokens to represent DNA nucleotides (should always be 4)') parser.add_argument('--nclass', type=int, default=2, help='number of classes from the linear decoder') parser.add_argument('--ninp', type=int, default=512, help='ninp for transformer encoder') parser.add_argument('--nhead', type=int, default=8, help='nhead for transformer encoder') parser.add_argument('--nhid', type=int, default=2048, help='nhid for transformer encoder') parser.add_argument('--nlayers', type=int, default=6, help='nlayers for transformer encoder') parser.add_argument('--save_freq', type=int, default=1, help='saving checkpoints per save_freq epochs') parser.add_argument('--dropout', type=float, default=.1, help='transformer dropout') parser.add_argument('--warmup_steps', type=int, default=3200, help='training schedule warmup steps') parser.add_argument('--lr_scale', type=float, default=0.1, help='learning rate scale') parser.add_argument('--nmute', type=int, default=18, help='number of mutations during training') parser.add_argument('--kmers', type=int, nargs='+', default=[2,3,4,5,6], help='k-mers to be aggregated') #parser.add_argument('--kmer_aggregation', type=bool, default=True, help='k-mers to be aggregated') parser.add_argument('--kmer_aggregation', dest='kmer_aggregation', action='store_true') parser.add_argument('--no_kmer_aggregation', dest='kmer_aggregation', action='store_false') parser.set_defaults(kmer_aggregation=True) parser.add_argument('--nfolds', type=int, default=5, help='number of cross validation folds') parser.add_argument('--fold', type=int, default=0, help='which fold to train') parser.add_argument('--val_freq', type=int, default=1, help='which fold to train') opts = parser.parse_args() return opts opts=get_args() #gpu selection os.environ[\"CUDA_VISIBLE_DEVICES\"] = opts.gpu_id device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #lr=0 #checkpointing checkpoints_folder='checkpoints_fold{}'.format((opts.fold)) csv_file='log_fold{}.csv'.format((opts.fold)) columns=['epoch','train_loss','train_acc','recon_acc', 'val_loss','val_auc','val_acc','val_sens','val_spec'] #logger=CSVLogger(columns,csv_file) #build model and logger MODELS=[] for i in range(3): model=NucleicTransformer(opts.ntoken, opts.nclass, opts.ninp, opts.nhead, opts.nhid, opts.nlayers, opts.kmer_aggregation, kmers=opts.kmers, dropout=opts.dropout).to(device) optimizer=torch.optim.Adam(model.parameters(), weight_decay=opts.weight_decay) criterion=nn.CrossEntropyLoss(reduction='none') lr_schedule=lr_AIAYN(optimizer,opts.ninp,opts.warmup_steps,opts.lr_scale) # Initialization opt_level = 'O1' model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level) model = nn.DataParallel(model) pytorch_total_params = sum(p.numel() for p in model.parameters()) print('Total number of paramters: {}'.format(pytorch_total_params)) model.load_state_dict(torch.load(\"best_weights/fold0top{}.ckpt\".format(i+1))) model.eval() MODELS.append(model) dict=MODELS[0].module.state_dict() for key in dict: for i in range(1,len(MODELS)): dict[key]=dict[key]+MODELS[i].module.state_dict()[key] dict[key]=dict[key]/float(len(MODELS)) MODELS[0].module.load_state_dict(dict) avg_model=MODELS[0] def geometric_mean(preds): gmean=np.ones(preds.shape[1:]) for pred in preds: gmean=gmean*pred gmean=gmean**(1/len(preds)) return gmean df=pd.read_csv('../fullset_test.csv',header=None) seqs=[] labels=[] for i in range(len(df)): seqs.append(nucleatide2int(df.iloc[i,1])) labels.append(df.iloc[i,2]) labels=np.asarray(labels).astype(\"int\") seqs=np.asarray(seqs).astype(\"int\") batch_size=128 batches=np.around(len(df)/batch_size+0.5).astype('int') preds=[] softmax = nn.Softmax(dim=1) for i in tqdm(range(batches)): with torch.no_grad(): outputs=[] #for model in MODELS: x=torch.Tensor(seqs[i*batch_size:(i+1)*batch_size]).to(device).long() y=softmax(avg_model(x)) #outputs.append(softmax(y).cpu().numpy()) for vec in y: preds.append(vec.cpu().numpy()) from sklearn import metrics preds=np.asarray(preds) auc=metrics.roc_auc_score(labels,preds[:,1]) with open(\"test_results.p\",'wb+') as f: pickle.dump([labels,preds],f) print(auc) with open(\"test_score.txt\",'w+') as f: f.write(\"test auc score: {}\".format(auc)) # for i in range(3,10): # ngrams=np.arange(2,i) # print(ngrams) # train_fold(0,ngrams) # # train_fold(0,[2,3,4]) Functions.py import torch import os from sklearn import metrics import numpy as np import torch.nn as nn import torch.nn.functional as F from tqdm import tqdm import Metrics import numpy as np import os import pandas as pd import random def seed_everything(seed=42): random.seed(seed) os.environ['PYTHONHASHSEED'] = str(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed(seed) torch.backends.cudnn.deterministic = True def get_best_weights_from_fold(fold, record, top=3): csv_file='{}log_fold{}.csv'.format(record, fold) history=pd.read_csv(csv_file) scores=np.asarray(history.val_auc) top_epochs=scores.argsort()[-3:][::-1] print(scores[top_epochs]) os.system('mkdir best_weights') for i in range(top): weights_path='{}checkpoints_fold{}/epoch{}.ckpt'.format(record, fold,history.epoch[top_epochs[i]]) print(weights_path) os.system('cp {} best_weights/fold{}top{}.ckpt'.format(weights_path,fold,i+1)) os.system('rm -r {}checkpoints_fold{}'.format(record, fold)) def smoothcrossentropyloss(pred,gold,n_class=2,smoothing=0.05): gold = gold.contiguous().view(-1) one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1) one_hot = one_hot * (1 - smoothing) + (1 - one_hot) * smoothing / (n_class - 1) log_prb = F.log_softmax(pred, dim=1) loss = -(one_hot * log_prb) #loss=loss.sum(1).mean() return loss def mutate_dna_sequence(sequence,nmute=15): mutation=torch.randint(0,4,size=(sequence.shape[0],nmute)) to_mutate = torch.randperm(sequence.shape[1])[:nmute] sequence[:,to_mutate]=mutation return sequence def get_MLM_mask(sequence,nmask=12): mask=np.zeros(sequence.shape,dtype='bool') to_mask=np.random.choice(len(sequence[0]),size=(nmask),replace=False) mask[:,to_mask]=True return mask def get_complementary_sequence(sequence): complementary_sequence=sequence.copy() complementary_sequence[sequence==0]=1 complementary_sequence[sequence==1]=0 complementary_sequence[sequence==2]=3 complementary_sequence[sequence==3]=2 complementary_sequence=complementary_sequence[:,::-1] return complementary_sequence def update_lr(optimizer, lr): for param_group in optimizer.param_groups: param_group['lr'] = lr def save_weights(model,optimizer,epoch,folder): if os.path.isdir(folder)==False: os.makedirs(folder,exist_ok=True) torch.save(model.state_dict(), folder+'/epoch{}.ckpt'.format(epoch+1)) def validate(model,device,dataset,batch_size=64): batches=len(dataset) model.train(False) total=0 predictions=[] outputs=[] ground_truths=[] loss=0 criterion=nn.CrossEntropyLoss() with torch.no_grad(): for data in tqdm(dataset): X=data['data'].to(device) Y=data['labels'].to(device) output= model(X) del X loss+=criterion(output,Y) classification_predictions = torch.argmax(output,dim=1).squeeze() for pred in classification_predictions: predictions.append(pred.cpu().numpy()) for vector in output: outputs.append(vector.cpu().numpy()) for t in Y: ground_truths.append(t.cpu().numpy()) del output torch.cuda.empty_cache() val_loss=(loss/batches).cpu() ground_truths=np.asarray(ground_truths) predictions=np.asarray(predictions) outputs=np.asarray(outputs) #print(predictions) #print(ground_truths) #score=metrics.cohen_kappa_score(ground_truths,predictions,weights='quadratic') val_acc=Metrics.accuracy(predictions,ground_truths) auc=metrics.roc_auc_score(ground_truths,outputs[:,1]) val_sens=Metrics.sensitivity(predictions,ground_truths) val_spec=Metrics.specificity(predictions,ground_truths) print('Val accuracy: {}, Val Loss: {}'.format(val_acc,val_loss)) return val_loss,auc,val_acc,val_sens,val_spec def predict(model,device,dataset,batch_size=64): batches=int(len(dataset.val_indices)/batch_size)+1 model.train(False) total=0 ground_truths=dataset.labels[dataset.val_indices] predictions=[] attention_weights=[] loss=0 criterion=nn.CrossEntropyLoss() dataset.switch_mode(training=False) dataset.update_batchsize(batch_size) with torch.no_grad(): for i in tqdm(range(len(dataset))): data=dataset[i] X=torch.Tensor(data['data']).to(device,).long() Y=torch.Tensor(data['labels']).to(device,dtype=torch.int64) directions=data['directions'] directions=directions.reshape(len(directions),1)*np.ones(X.shape) directions=torch.Tensor(directions).to(device).long() output,_,_,aw= model(X,directions,None) del X loss+=criterion(output,Y) classification_predictions = torch.argmax(output,dim=1).squeeze() for pred in output: predictions.append(pred.cpu().numpy()) for weight in aw: attention_weights.append(weight.cpu().numpy()) del output torch.cuda.empty_cache() val_loss=(loss/batches).cpu() predictions=np.asarray(predictions) attention_weights=np.asarray(attention_weights) binary_predictions=predictions.copy() binary_predictions[binary_predictions==2]=1 binary_ground_truths=ground_truths.copy() binary_ground_truths[binary_ground_truths==2]=1 return predictions,attention_weights,np.asarray(dataset.data[dataset.val_indices]) Logger.py import csv from os import path class CSVLogger: def __init__(self,columns,file): self.columns=columns self.file=file if not self.check_header(): self._write_header() def check_header(self): if path.exists(self.file): header=True else: header=False return header def _write_header(self): with open(self.file,\"a\") as f: string=\"\" for attrib in self.columns: string+=\"{},\".format(attrib) string=string[:len(string)-1] string+=\"\\n\" f.write(string) return self def log(self,row): if len(row)!=len(self.columns): raise Exception(\"Mismatch between row vector and number of columns in logger\") with open(self.file,\"a\") as f: string=\"\" for attrib in row: string+=\"{},\".format(attrib) string=string[:len(string)-1] string+=\"\\n\" f.write(string) return self LrScheduler.py import csv from os import path class CSVLogger: def __init__(self,columns,file): self.columns=columns self.file=file if not self.check_header(): self._write_header() def check_header(self): if path.exists(self.file): header=True else: header=False return header def _write_header(self): with open(self.file,\"a\") as f: string=\"\" for attrib in self.columns: string+=\"{},\".format(attrib) string=string[:len(string)-1] string+=\"\\n\" f.write(string) return self def log(self,row): if len(row)!=len(self.columns): raise Exception(\"Mismatch between row vector and number of columns in logger\") with open(self.file,\"a\") as f: string=\"\" for attrib in row: string+=\"{},\".format(attrib) string=string[:len(string)-1] string+=\"\\n\" f.write(string) return self Metrics.py import numpy as np def accuracy(predictions,ground_truths): return np.sum(predictions==ground_truths)/len(ground_truths) def sensitivity(predictions,ground_truths): ''' Here it is assumed: 0=negative 1=positive ''' return 1-len(predictions[(predictions==0)*(ground_truths==1)])/len(ground_truths[ground_truths==1]) def specificity(predictions,ground_truths): ''' Here it is assumed: 0=negative 1=positive ''' return 1-len(predictions[(predictions==1)*(ground_truths==0)])/len(ground_truths[ground_truths==0]) def MCC(predictions,ground_truths): ''' Here it is assumed: 0=negative 1=positive ''' N1=len(predictions[(predictions==0)&(ground_truths==1)]) N2=len(predictions[(predictions==1)&(ground_truths==0)]) N3=len(ground_truths[ground_truths==1]) N4=len(ground_truths[ground_truths==0]) sens=1-N1/N3 spec=1-N2/N4 denom=np.sqrt((1+(N2-N1)/N3)*(1+(N1-N2)/N4)) return (1-sens-spec)/denom Network.py import math import torch import torch.nn as nn import torch.nn.functional as F #mish activation class Mish(nn.Module): def __init__(self): super().__init__() def forward(self, x): #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!) return x *( torch.tanh(F.softplus(x))) from torch.nn.parameter import Parameter def gem(x, p=3, eps=1e-6): return F.avg_pool1d(x.clamp(min=eps).pow(p), (x.size(-1))).pow(1./p) class GeM(nn.Module): def __init__(self, p=3, eps=1e-6): super(GeM,self).__init__() self.p = Parameter(torch.ones(1)*p) self.eps = eps def forward(self, x): return gem(x, p=self.p, eps=self.eps) def __repr__(self): return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')' class TransformerEncoderLayer(nn.Module): r\"\"\"TransformerEncoderLayer is made up of self-attn and feedforward network. This standard encoder layer is based on the paper \"Attention Is All You Need\". Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000-6010. Users may modify or implement in a different way during application. Args: d_model: the number of expected features in the input (required). nhead: the number of heads in the multiheadattention models (required). dim_feedforward: the dimension of the feedforward network model (default=2048). dropout: the dropout value (default=0.1). activation: the activation function of intermediate layer, relu or gelu (default=relu). Examples:: >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8) >>> src = torch.rand(10, 32, 512) >>> out = encoder_layer(src) \"\"\" def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\"): super(TransformerEncoderLayer, self).__init__() self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout) self.linear1 = nn.Linear(d_model, dim_feedforward) self.dropout = nn.Dropout(dropout) self.linear2 = nn.Linear(dim_feedforward, d_model) self.norm1 = nn.LayerNorm(d_model) self.norm2 = nn.LayerNorm(d_model) self.dropout1 = nn.Dropout(dropout) self.dropout2 = nn.Dropout(dropout) self.activation = Mish() def forward(self, src , src_mask = None, src_key_padding_mask = None): src2,attention_weights = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask) src = src + self.dropout1(src2) src = self.norm1(src) src2 = self.linear2(self.dropout(self.activation(self.linear1(src)))) src = src + self.dropout2(src2) src = self.norm2(src) return src,attention_weights class LinearDecoder(nn.Module): def __init__(self,num_classes,ninp,dropout,pool=True,): super(LinearDecoder, self).__init__() # if pool: # self.pool_layer=GeM() if pool: self.classifier=nn.Linear(ninp,num_classes) else: self.classifier=nn.Linear(ninp,num_classes) self.pool=pool self.pool_layer=GeM() def forward(self,x): if self.pool: # max_x,_=torch.max(x,dim=1) # x=torch.cat([torch.mean(x,dim=1),max_x],dim=-1) #print(x.shape) x=self.pool_layer(x.permute(0,2,1)).permute(0,2,1).squeeze() #print(x.shape) x=self.classifier(x) return x class PositionalEncoding(nn.Module): def __init__(self, d_model, dropout=0.1, max_len=5000): super(PositionalEncoding, self).__init__() self.dropout = nn.Dropout(p=dropout) pe = torch.zeros(max_len, d_model) position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) pe = pe.unsqueeze(0).transpose(0, 1) self.register_buffer('pe', pe) def forward(self, x): x = x + self.pe[:x.size(0), :] return self.dropout(x) class K_mer_aggregate(nn.Module): def __init__(self,kmers,in_dim,out_dim,dropout=0.1): super(K_mer_aggregate, self).__init__() #self.dropout=nn.Dropout(dropout) self.convs=[] for i in kmers: print(i) self.convs.append(nn.Conv1d(in_dim,out_dim,i,padding=0)) self.convs=nn.ModuleList(self.convs) self.norm=nn.LayerNorm(out_dim) #self.activation=nn.ReLU(inplace=True) #self.activation=Mish() def forward(self,x): outputs=[] for conv in self.convs: outputs.append(conv(x)) outputs=torch.cat(outputs,dim=2) return self.norm(outputs.permute(2,0,1)) class NucleicTransformer(nn.Module): def __init__(self, ntoken, nclass, ninp, nhead, nhid, nlayers, kmer_aggregation, kmers, dropout=0.5,return_aw=False): super(NucleicTransformer, self).__init__() self.model_type = 'Transformer' self.src_mask = None self.pos_encoder = PositionalEncoding(ninp, dropout) self.kmers=kmers #if self.ngrams!=None: self.kmer_aggregation=kmer_aggregation if self.kmer_aggregation: self.k_mer_aggregate=K_mer_aggregate(kmers,ninp,ninp) else: print(\"No kmer aggregation is chosen\") self.transformer_encoder = [] for i in range(nlayers): self.transformer_encoder.append(TransformerEncoderLayer(ninp, nhead, nhid, dropout)) self.transformer_encoder= nn.ModuleList(self.transformer_encoder) self.encoder = nn.Embedding(ntoken, ninp) #self.directional_encoder = nn.Embedding(3, ninp//8) self.ninp = ninp self.decoder = LinearDecoder(nclass,ninp,dropout) self.return_aw=False def forward(self, src): src = src.permute(1,0) #dir = dir.permute(1,0) src = self.encoder(src) #* math.sqrt(self.ninp) #dir = self.directional_encoder(dir) #src = torch.cat([src,dir],dim=-1) src = self.pos_encoder(src) #if self.ngrams!=None: if self.kmer_aggregation: kmer_output = self.k_mer_aggregate(src.permute(1,2,0)) #src = torch.cat([src,kmer_output],dim=0) src = kmer_output attention_weights=[] for layer in self.transformer_encoder: src,attention_weights_layer=layer(src) attention_weights.append(attention_weights_layer) encoder_output = src.permute(1,0,2) #print(encoder_output.shape) output = self.decoder(encoder_output) if self.return_aw: attention_weights=torch.stack(attention_weights).permute(1,0,2,3) return output, attention_weights else: return output train.py import os import torch import torch.nn as nn import time from Functions import * from Dataset import * from Network import * from LrScheduler import * import Metrics from Logger import CSVLogger import argparse from tensorboardX import SummaryWriter from torch.cuda.amp import autocast as autocast from torch.cuda.amp import GradScaler as GradScaler def get_args(): parser = argparse.ArgumentParser() parser.add_argument('--gpu_id', type=str, default='0', help='which gpu to use') parser.add_argument('--path', type=str, default='../', help='path of csv file with DNA sequences and labels') parser.add_argument('--epochs', type=int, default=150, help='number of epochs to train') parser.add_argument('--batch_size', type=int, default=24, help='size of each batch during training') parser.add_argument('--weight_decay', type=float, default=0, help='weight dacay used in optimizer') parser.add_argument('--ntoken', type=int, default=4, help='number of tokens to represent DNA nucleotides (should always be 4)') parser.add_argument('--nclass', type=int, default=2, help='number of classes from the linear decoder') parser.add_argument('--ninp', type=int, default=512, help='ninp for transformer encoder') parser.add_argument('--nhead', type=int, default=8, help='nhead for transformer encoder') parser.add_argument('--nhid', type=int, default=2048, help='nhid for transformer encoder') parser.add_argument('--nlayers', type=int, default=6, help='nlayers for transformer encoder') parser.add_argument('--save_freq', type=int, default=1, help='saving checkpoints per save_freq epochs') parser.add_argument('--dropout', type=float, default=.1, help='transformer dropout') parser.add_argument('--warmup_steps', type=int, default=3200, help='training schedule warmup steps') parser.add_argument('--lr_scale', type=float, default=0.1, help='learning rate scale') parser.add_argument('--kmers', type=int, nargs='+', default=[2,3,4,5,6], help='k-mers to be aggregated') #parser.add_argument('--kmer_aggregation', type=bool, default=True, help='k-mers to be aggregated') parser.add_argument('--kmer_aggregation', dest='kmer_aggregation', action='store_true') parser.add_argument('--no_kmer_aggregation', dest='kmer_aggregation', action='store_false') parser.set_defaults(kmer_aggregation=True) parser.add_argument('--nfolds', type=int, default=5, help='number of cross validation folds') parser.add_argument('--fold', type=int, default=0, help='which fold to train') parser.add_argument('--val_freq', type=int, default=1, help='which fold to train') parser.add_argument('--num_workers', type=int, default=1, help='num_workers') parser.add_argument('--record', type=str, default=' ', help='train or test record') opts = parser.parse_args() return opts tb = SummaryWriter('/root/my_train/tblogdir/H3K27me3') def train_fold(): opts = get_args() seed_everything(2020) #gpu selection os.environ[\"CUDA_VISIBLE_DEVICES\"] = opts.gpu_id device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') data = pd.read_csv('/root/my_train/dataset_all/H3K27me3_train_24w.txt', header=None, sep='\\t') dataset = ViraminerDataset(data.iloc[:220000,0],data.iloc[:220000,1]) dataloader = torch.utils.data.DataLoader(dataset,batch_size=opts.batch_size,shuffle=True,num_workers=opts.num_workers) val_dataset = ViraminerDataset(data.iloc[220000:,0],data.iloc[220000:,1]) val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=opts.batch_size,shuffle=False) #exit() #lr=0 #checkpointing checkpoints_folder = '{}checkpoints_fold{}'.format(opts.record, opts.fold) csv_file = '{}log_fold{}.csv'.format(opts.record, opts.fold) columns = ['epoch','train_loss', 'val_loss','val_auc','val_acc','val_sens','val_spec'] logger = CSVLogger(columns,csv_file) #build model and logger model = NucleicTransformer(opts.ntoken, opts.nclass, opts.ninp, opts.nhead, opts.nhid, opts.nlayers, opts.kmer_aggregation, kmers=opts.kmers, dropout=opts.dropout).to(device) optimizer = torch.optim.Adam(model.parameters(), weight_decay=opts.weight_decay) criterion = nn.CrossEntropyLoss(reduction='none') lr_schedule = lr_AIAYN(optimizer,opts.ninp,opts.warmup_steps,opts.lr_scale) softmax = nn.Softmax(dim=1) pytorch_total_params = sum(p.numel() for p in model.parameters()) print('Total number of paramters: {}'.format(pytorch_total_params)) print(\"Starting training for fold {}/{}\".format(opts.fold,opts.nfolds)) #training loop scaler = GradScaler() for epoch in range(opts.epochs): model.train(True) t = time.time() total_loss = 0 total_steps = len(dataloader) for step, data in enumerate(dataloader): #for step in range(1): lr = lr_schedule.step() src = data['data'].to(device) labels = data['labels'].to(device) optimizer.zero_grad() with autocast(): output = model(src) loss = torch.mean(criterion(output,labels)) scaler.scale(loss).backward() scaler.unscale_(optimizer) torch.nn.utils.clip_grad_norm_(model.parameters(),1) scaler.step(optimizer) scaler.update() total_loss += loss print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.3f} Lr:{:.6f} Time: {:.1f}\" .format(epoch+1, opts.epochs, step+1, total_steps, total_loss/(step+1) , lr,time.time()-t),end='\\r',flush=True) #total_loss/(step+1) #break print('') train_loss = total_loss/(step+1) if (epoch+1)%opts.val_freq == 0: val_loss,auc,val_acc,val_sens,val_spec=validate(model,device,val_dataloader,batch_size=opts.batch_size*2) print(\"Epoch {} train loss: {}\".format(epoch+1,train_loss)) tb.add_scalars('train/val/loss', {'train':train_loss, 'val':val_loss}, epoch+1) tb.add_scalar('val_acc', val_acc, epoch+1) tb.add_scalar('auc', auc, epoch+1) tb.add_scalar('val_sens', val_sens, epoch+1) tb.add_scalar('val_spec', val_spec, epoch+1) to_log = [epoch+1,train_loss,val_loss,auc,val_acc,val_sens,val_spec] logger.log(to_log) if (epoch+1)%opts.save_freq == 0: save_weights(model,optimizer,epoch,checkpoints_folder) tb.close() get_best_weights_from_fold(opts.record, opts.fold) train_fold() run.sh #!/bin/bash python train.py --gpu_id 0 --kmer_aggregation --epochs 12 --nlayers 6 \\ --batch_size 64 --kmers 20 --lr_scale 0.1 --ninp 512 --nhid 2048 --num_workers 8 --nhead 8 --record 0504_train1 test.sh #!/bin/bash python evaluate_test.py --gpu_id 0,1 --kmer_aggregation --nmute 20 --epochs 100 --nlayers 6 \\ --batch_size 128 --kmers 13 --lr_scale 0.1 --ninp 512 --nhid 2048 "},"实验流程/模型评估.html":{"url":"实验流程/模型评估.html","title":"模型评估","keywords":"","body":"模型评估 评估指标 参考资料： Python sklearn机器学习各种评价指标——Sklearn.metrics简介及应用示例 Metrics（混淆矩阵） 给定一个二元分类模型和它的阈值，就能从所有样本的（阳性／阴性）真实值和预测值计算出一个 (X=FPR, Y=TPR) 座标点 针对一个二分类问题，将实例分成正类(postive)或者负类(negative)。但是实际中分类时，会出现四种情况. (1)若一个实例是正类并且被预测为正类，即为真正类(True Postive TP) (2)若一个实例是正类，但是被预测成为负类，即为假负类(False Negative FN) (3)若一个实例是负类，但是被预测成为正类，即为假正类(False Postive FP) (4)若一个实例是负类，但是被预测成为负类，即为真负类(True Negative TN) TP:正确的肯定数目 FN:漏报，没有找到正确匹配的数目 FP:误报，没有的匹配不正确 TN:正确拒绝的非匹配数目 列联表如下，1代表正类，0代表负类： 由上表可得出横，纵轴的计算公式： (1)真正类率(True Postive Rate)TPR: TP/(TP+FN),代表分类器预测的正类中实际正实例占所有正实例的比例。Sensitivity (2)负正类率(False Postive Rate)FPR: FP/(FP+TN)，代表分类器预测的正类中实际负实例占所有负实例的比例。1-Specificity (3)真负类率(True Negative Rate)TNR: TN/(FP+TN),代表分类器预测的负类中实际负实例占所有负实例的比例，TNR=1-FPR。Specificity AUC AUC（Area Under Curve）被定义为ROC曲线)下与坐标轴围成的面积，取值范围[0,1],分别随机从正负样本集中抽取一个正样本，一个负样本，正样本的预测值大于负样本的概率。 Roc (Receiver operating characteristic) 曲线是一种二元分类模型分类效果的分析工具，每个点反应这对同一信号刺激的感受性 纵轴TPR（true positive rate）真正例率: 灵敏度（Sensitivity）在所有实际为阳性的样本中，被正确地判断为阳性之比率 TPR = TP/P = TP/(TP+FN) 纵轴FPR（false positive rate）: 在所有实际为阴性的样本中，被错误地判定为阳性之比率 FPR = FP/N = FP/(FP+TN) auPRC PRC(Precision Recall Curve,准确召回率曲线)，相关性评价： 数据库里有500条记录，其中50个是相关的（正样本），你通过一个检索，返回了75个你认为相关，其中只有45个是真正相关的；那么在这个检索对应下的： recall=45/50=0.9【横坐标】 precision=45/75=0.6【纵坐标】（这两个数比值都是在0到1置内的） 结论： 在negative instances的数量远远大于positive instances的data set里， PRC更能有效衡量检测器的好坏。 MCC 马修斯相关系数（Matthews correlation coefficient） 马修斯相关系数是在使用机器学习作为二进制（2类）的质量的度量的分类，通过布赖恩W.马修斯在1975年由生物化学引入 它考虑到真和假阳性和假阴性，并且通常是被视为一种平衡的措施，即使这些类别的规模大小不同也可以使用。 MC实质上是观察到的类别和预测的二元分类之间的相关系数; 它返回介于-1和+1之间的值。系数+1表示完美预测，0表示不比随机预测好，-1表示预测和观察之间的完全不一致。统计数据也称为phi系数。MCC与2×2 列联表的卡方统计量相关 其中n是观察总数。虽然没有完美的方法用一个数字来描述真假阳性和阴性的混淆矩阵，但马修斯相关系数通常被认为是最好的这种测量之一。 当两个类别具有非常不同的大小时，其它度量（例如正确预测的比例（也称为准确性））无用。例如，将每个对象分配给较大的集合可以实现高比例的正确预测，但通常不是有用的分类。可以使用以下公式直接从混淆矩阵计算MCC ： 在这个公式中，TP是真阳性数量，TN的真阴性数量，FP的假阳性数量和FN的假阴性数量。如果分母中的四个和中的任何一个为零，则分母可以任意设置为1; 这导致Matthews相关系数为零，这可以显示为正确的限制值。 马修斯给出的原始公式是： 这等于上面给出的公式。 作为相关系数， 马修斯相关系数是问题及其对偶的回归系数的几何平均数。 Matthews相关系数的分量回归系数是Markedness（Δp）和Youden的J统计量（Informedness或Δp’）。 标记和知情对应于不同的信息流方向，并推广了Youden的J统计量， {\\ displaystyle \\ delta}p统计和（作为它们的几何平均值）马修斯相关系数超过两个类。 一些科学家声称，马修斯相关系数是在混淆矩阵环境中建立二元分类器预测质量的最具信息性的单一分数 过拟合问题 学习曲线 偏差/方差 高偏差—欠拟合 高方差—过拟合 Train set error /Dev set error 参考资料： http://www.ai-start.com/dl2017/ 吴恩达深度学习 https://blog.csdn.net/huangfei711/article/details/79436698 获取和使用更多的数据集 对于解决过拟合的办法就是给与足够多的数据集，让模型在更可能多的数据上进行“观察”和拟合，从而不断修正自己。然而事实上，收集无限多的数据集几乎是不 可能的，因此一个常用的办法就是调整已有的数据，添加大量的“噪音”，或者对图像进行锐化、旋转、明暗度调整等优化。 采用合适的模型 目前来说，针对不同的情况和分类要求，对使用的模型也是千差万别。过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律“deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越 多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。因此对于模型的设计需要合理参考各种模型的取舍。 ​ 使用 Dropout Dropout 是一个非常有用和常用的方法。Dropout 指的是在训练过程中每次按一定的几率关闭或忽略某些层的节点。使得模型在使用同样的数据进行训练时相当于从不同的模型中随机选择一个进行训练至于 Dropout 起作用的原因，可以简单理解成在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果， 随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。 正则化 正则化又称为权重衰减，具体做法是将权值的大小加入到损失函数中，在实际使用中分为 L1 正则与 L2 正则。关于正则化能够防止过拟合的原因 正则化 使神经网络在保持原有深度的同时，每一层的隐藏单元产生的影响更小，防止过拟合 https://blog.csdn.net/guyuealian/article/details/88426648 L2正则化： ||w||是欧几里得范数，平方等于所有w的平方和 神经网络中的L2正则化：平方范数被定义为所有元素的平方和 弗罗贝尼乌斯范数：矩阵范数， L2范数正则化，也被称为权重衰减，因为在进行backprop时，增加权重项会使原本的梯度下降更多 直观上理解就是如果正则化设置得足够大，权重矩阵被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。 Dropout正则化 （随机失活） dropout会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用backprop方法进行训练。 不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；对不同权重的衰减是不同的，它取决于激活函数倍增的大小。 inverted dropout反向随机失活 可以改变Dropout层的参数Dropout（keep—prob） Early Stopping Early Stopping 是参数微调中的一种，即在每个循环结束一次以后（这里的循环可能是 full data batch,也可能是 mini batch size），计算模型的准确率（accuracy）。当准确率不再增加时就停止训练。这是一种非常简单和自然的办法，准确率不再增加时就停止训练，防止模型对已有的数据继续训练。但是问题在于，准确率在每个循环之后的计算是变化的，没有任何人和任何模型能保证准确率不会变化，可能某次循环结束后，准确率很高，但是下一轮结束后准确率又降得很低 ​ 人为地设定一个范围。当连续10次准确率在此范围内波动时就停止循环。 可变化的学习率 可变化的学习率也是根据模型计算出的准确率进行调整。一个简单的方法是在人为设定的准确率范围内，达到10次范围内的波动后，依次将学习率减半，直到最终的学习率降为原始的 1/1024 时停止模型的训练。 使用 Batch_Normalization 还有一个数据处理的方法 Batch_Normalization，即数据在经过卷积层之后，真正进入激活函数之前需要对其进行一次 Batch_Normalization，分批对输入的数据求取均值和方差之后重新对数据进行归一化计算。这样做的好处就是对数据进行一定程度的预处理，使得无论是训练集还是测试集都在一定范围内进行分布和波动，对数据点中包含的误差进行掩盖化处理，从而增大模型的泛化能力。 超参数调试 贝叶斯优化（BayesianOptimization） https://www.cnblogs.com/yangruiGB2312/p/9374377.html optuna https://tigeraus.gitee.io/doc-optuna-chinese-build/ ROC曲线绘制 ROC曲线和AUC https://blog.csdn.net/pipisorry/article/details/51788927 torch.save(net.state_dict(), 'params.pkl') test_data = TensorDataset(data_tensor[150000:151000], target_tensor[150000:151000]) test_dataloader = data.DataLoader(test_data,batch_size = 1000, shuffle=True,num_workers=0) y_label = [] y_pre = [] def predict(data_iter, net, device=None): net.load_state_dict(torch.load('params.pkl')) if device is None and isinstance(net, torch.nn.Module): device = list(net.parameters())[0].device acc_sum, n = 0.0, 0 with torch.no_grad(): for X, y in data_iter: if isinstance(net, torch.nn.Module): net.eval() # 评估模式, 这会关闭dropout acc_sum += (net(X.to(device)).argmax(dim=1) == (y.to(device).squeeze())).float().sum().cpu().item() y_label = y.cpu().numpy().tolist() y_pre = net(X.to(device))[:,1].cpu().numpy().tolist() fpr, tpr, thersholds = roc_curve(y_label, y_pre, pos_label=1) for i, value in enumerate(thersholds): print(\"%f %f %f\" % (fpr[i], tpr[i], value)) roc_auc = auc(fpr, tpr) plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2) plt.xlim([-0.05, 1.05]) # 设置x、y轴的上下限，以免和边缘重合，更好的观察图像的整体 plt.ylim([-0.05, 1.05]) plt.xlabel('False Positive Rate') plt.ylabel('True Positive Rate') # 可以使用中文，但需要导入一些库即字体 plt.title('ROC Curve') plt.legend(loc=\"lower right\") plt.show() predict(test_dataloader, net, device=None) 改良标签方法 计算每种组蛋白修饰peak的中位数，平均数 histone modifications mid average H3K4me3（1） 880 950.52 H3K27ac（2） 799 854.329 H3K4me1（3） 2694 3446.12 H3K27me3（4） 1586 3149.9 H3K9me2（5） 2158 4094.97 histone modifications function H3K4me3（1） 取peak中央250bp作为标准，win在其中的比例占到10%则标记为阳性 H3K27ac（2） 250 H3K4me1（3） 750 H3K27me3（4） 750 H3K9me2（5） 1000 将H3K4me3和H3K27ac按照同一种标签计算 将H3K4me1和H3K9me2按照同一种标签计算 "},"实验流程/特征提取.html":{"url":"实验流程/特征提取.html","title":"特征提取","keywords":"","body":"特征提取 参考文献： Deep Learning for Genomics: A Concise Overview 3.1Model Interpretation 方法一： Zeiler and Fergus (2014) gave insights into the function of intermediate features by mapping hidden layers back to input through deconvolution Matthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In European conference on computer vision, pages 818–833. Springer, 2014. 方法二： Simonyan et al. (2013) linearly approximate the network by first-order Taylor expansion and obtained Saliency Maps from a ConvNet by projecting back from the dense layers of the network. People also searched for an understanding of genes by deep networks Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutionalnetworks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034, 2013. 方法三： Denas and Taylor (2013) managed to pass the model knowledge back into the input space through the inverse of the activa- tion function, so that biologically-meaningful patterns can be highlighted. Olgert Denas and James Taylor. Deep modeling of gene expression regulation in an ery-thropoiesis model. In Representation Learning, ICML Workshop, 2013. 方法四：saliency map（显著性图) 一阶泰勒展开和梯度下降的推导 https://mathpretty.com/10683.html Lanchantin et al. (2016b, Dashboard) adopted Saliency Maps to measure nucleotide importance. Their work provided a series of visualization techniques to detect motifs, or sequence patterns from deep learning models, and went further to discuss about the features extracted by CNNs and RNNs Jack Lanchantin, Ritambhara Singh, Beilun Wang, and Yanjun Qi. Deep gdashboard: Visualizing and understanding genomic sequences using deep neural networks. CoRR, abs/1608.03644, 2016b. URL http://arxiv.org/abs/1608.03644. which which parts of the sequence are most influential for the classification? sequence：X0 length：|X0| class : c score: Sc(X0) 衡量碱基重要性的指标，根据碱基变化对Sc的影响来表示重要性 w是神经网络反向传播的一步 This derivative is simply one step of backpropagation in the DNN model, and is therefore easy to compute. We do a pointwise multiplication of the saliency map with the one-hot encoded sequence to get the derivative values for the actual nucleotide characters of the sequence (A,T,C, or G) so we can see the influence of the character at each position on the output score. Finally, we take the element-wise magnitude of the resulting derivative vector to visualize how important each character is regardless of derivative direction. Saliency.py import torch import matplotlib.pyplot as plt import numpy as np import pandas as pd import re from sklearn.preprocessing import LabelEncoder,OneHotEncoder import torchvision from model_dna import NetDeepHistone model= NetDeepHistone() model.load_state_dict(torch.load('D:/桌面/model.txt',map_location=torch.device('cpu'))) #停止梯度更新 for param in model.parameters(): param.requires_grad = False #读入X，y X = pd.read_csv('D:/桌面/data_motif.txt',header = None) Y = pd.read_csv('D:/桌面/target_motif.txt',header = None) #转成onehot # function to convert a DNA sequence string to a numpy array # converts to lower case, changes any non 'acgt' characters to 'n' def string_to_array(my_string): my_string = my_string.lower() my_string = re.sub('[^acgt]', 'z', my_string) my_array = np.array(list(my_string)) return my_array label_encoder = LabelEncoder() label_encoder.fit(np.array(['a','c','g','t','z'])) def one_hot_encoder(my_array): integer_encoded = label_encoder.transform(my_array) onehot_encoder = OneHotEncoder(sparse=False, dtype=int) integer_encoded = integer_encoded.reshape(len(integer_encoded), 1) onehot_encoded = onehot_encoder.fit_transform(integer_encoded) return onehot_encoded one_hot_matrix = [] for i in range(2): one_hot_matrix.append(one_hot_encoder(string_to_array(X[0][i]))) print(one_hot_matrix) X_tensor = torch.Tensor(one_hot_matrix) X_tensor = X_tensor.reshape(len(X),4,500) print(X_tensor.shape) #开启测试模式 model.eval() #确定梯度 X_tensor.requires_grad_() y_tensor = torch.LongTensor([1,1]) print(y_tensor.shape) saliency = None logits = model.forward(X_tensor) print(logits) logits = logits.gather(1, y_tensor.view(-1, 1)).squeeze() logits.backward(torch.FloatTensor([1., 1.])) saliency = abs(X_tensor.grad.data) print(saliency[0]) PWM = pd.DataFrame(saliency[0].numpy()) print(PWM) PWM.to_csv('C:/Users/DELL/Documents/PWM1.txt',sep='\\t',index=False) ggseqlogo > library(ggseqlogo) > matrix row.names(matrix) matrix motif ggseqlogo(motif) 方法五：Mutation Map Alipanahi et al. (2015) visualized the sequence specificities deter- mined by DeepBind through mutation maps that indicate the effect of variations on bound sequences. Babak Alipanahi, Andrew Delong, Matthew T. Weirauch, and Brendan J. Frey. Predicting the sequence specificities of dna- and rna-binding proteins by deep learning. Nat Biotech, 33(8):831–838, Aug 2015. ISSN 1087-0156. URL http://dx.doi.org/10.1038/nbt.3300. Computational Biology Mutation map 1.通过给定序列碱基的高度来表示在DeepBind分析中的重要性 2.heat map （4 * n）（n是序列长度）表示每个可能出现的突变对结合能力的影响 绘制方法 通过计算原始序列（参考基因组）的binding score p(s) 然后依次让每个位点都发生突变生成新的序列，计算p(s)^ ΔSij = （p(s)^ - p(s)) * max(0,p(s),p(s)^) 方法六：Deepmotif https://github.com/bakirillov/deepmotif4pytorch Method for motif generation via class optimization. We find the input matrix which corresponds to the highest locally optimum TFBS probability via backpropagation, and generate a PWM from the matrix. 方法七： 参考文献： DeepHistone: a deep learning approach to predicting histone modifications TSPTFBS: a Docker image for trans-species prediction of transcription factor binding sites in plants github：https://github.com/liulifenyf/TSPTFBS get_PWM.py import numpy as np import pandas as pd import re import torch from model_dna import NetDeepHistone def NUMPY2STRING(input_array): # convert numpy to string for 2 dimension numpy array. output_str = \"\" for i in range(input_array.shape[0]): for j in range(input_array.shape[1]): output_str = output_str + str(input_array[i, j]) + \"\\t\" output_str += \"\\n\" return output_str def matrix2meme(pwm_txt_name, pwm_meme_name, pwm_len): # convert PWM to meme format used in tomtom. write_ofl = open(pwm_meme_name, \"w\") ##### write_ofl.write(\"MEME version 5.0.4\\n\\n\") write_ofl.write(\"ALPHABET= ACGT\\n\\n\") write_ofl.write(\"strands: + -\\n\\n\") write_ofl.write(\"Background letter frequencies\\n\") write_ofl.write(\"A 0.25 C 0.25 G 0.25 T 0.25\\n\\n\") read_ofl = open(pwm_txt_name) ##### oflst = read_ofl.readlines() read_ofl.close() count = 0 for line in oflst: line = line.strip() if re.search(\">\", line): write_ofl.write(\"\\n\") write_ofl.write(\"MOTIF\" + \"\\t\" + \"filter\" + str(count + 1) + \"\\n\") write_ofl.write(\"letter-probability matrix: alength= 4 w= \" + str(pwm_len) + \"\\n\") ####### count += 1 else: write_ofl.write(line + \"\\n\") write_ofl.close() # 用于存储pwm矩阵的文件 input_path = \"onehot_test.npy\" # DNA one-hot encoding with .npy foramt. model_path = \"D:/桌面/model.txt\" # trained model path X = np.load(input_path) X = torch.Tensor(X).reshape(len(X),4,500) pwm_meme_name = \"pwm.meme\" pwm_txt_name = \"pwm.txt\" model = NetDeepHistone() model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu'))) # check out the name of first conv_layer parm = {} for name,parameters in model.seq_map.named_parameters(): print(name,':',parameters.size()) parm[name]=parameters.detach().numpy() '''According to your model, return the output of first conv_layer. please change the \"outputs\" para according to your model construction. And the bias and weights of first conv_layer.''' WEIGHTS, BIAS = parm['conv1.0.weight'],parm['conv1.0.bias'] WEIGHTS = WEIGHTS.squeeze() INSTANCE_LENGTH = WEIGHTS.shape[2] # return the length of filter print(WEIGHTS.shape) conv_out = model.seq_map.get_conv1(X) conv_out = conv_out.squeeze() print(conv_out.shape) ''' layer_output = Model(inputs=model.input, outputs=model.layers[1].output) conv_out = layer_output.predict(X) conv_out = conv_out.squeeze()# 根据模型卷积核数目调整最后一位 print(conv_out.shape) ''' # 用于提取pwm矩阵 ''' WEIGHTS(128,4,9)(Kernels_num,(width,length)) BIAS(128) THRESHOLD INSTANCE_FILTERED_NUMBER INSTANCE_FILTERED INSTANCE_LENGTH ''' motif_ofl = open(pwm_txt_name, \"w\") for i in range(WEIGHTS.shape[0]): one_filter_weight = WEIGHTS[i,: ,: ] THRESHOLD = (np.sum(np.max(one_filter_weight, 1))+ BIAS[i]) * 0.9 #阈值可以调整0.5-1.0 model_c = conv_out[:,i,:] - BIAS[i] position_m = np.where(model_c >= THRESHOLD) print(position_m[1].shape[0]) #(samples,position) INSTANCE_FILTERED_NUMBER = position_m[1].shape[0] print(INSTANCE_FILTERED_NUMBER) INSTANCE_FILTERED = np.zeros( [INSTANCE_FILTERED_NUMBER, 4, INSTANCE_LENGTH]) for j in range(INSTANCE_FILTERED_NUMBER): if position_m[1][j] MOTIF\" + str(i + 1) + \"\\n\" motif_ofl.write(outline) outline = NUMPY2STRING(pwm_matrix.T) motif_ofl.write(outline) motif_ofl.flush() motif_ofl.close() print(\"PWM-txt Done\") matrix2meme(pwm_txt_name, pwm_meme_name, INSTANCE_LENGTH) print(\"PWM-meme Done\") "},"结果分析.html":{"url":"结果分析.html","title":"结果分析","keywords":"","body":""},"训练日志.html":{"url":"训练日志.html","title":"训练日志","keywords":"","body":""},"背景知识/":{"url":"背景知识/","title":"背景知识","keywords":"","body":"背景知识 "},"背景知识/生物学/":{"url":"背景知识/生物学/","title":"生物学","keywords":"","body":"生物学 "},"背景知识/生物学/数据来源.html":{"url":"背景知识/生物学/数据来源.html","title":"数据来源","keywords":"","body":"数据来源 Integrative analysis of reference epigenomesin 20 rice varieties enhanced chromatin immunoprecipitation (eChIP) highly improved the efficiency of chromatin extraction via direct sonication of formaldehyde-fixed tissues five histone modifications and RNA polymerase II occupancy Chromatin states (CSs) Minghui 63 (MH63), Zhensha97 (ZS97), Nipponbare (Nip) and 17 other varieties Mapping epigenomic marks in 20 rice varieties H3K4me3, H3K27ac, H3K4me1, H3K27me3， H3K9me2 young leaf, mature leaf, root, and panicle genome-wide DNA methylation,open chromatin regions, RNA polymerase II (RNAPII) binding sites, and the transcriptome for these tissues and varieties. Breeding signatures of rice improvement revealed by a genomic variation map from a large germplasm collection 从一个大型种质资源的基因组变异图谱揭示水稻改良的育种特征 indica籼稻 landraces地方品种 modern cultivars现代品质 rice green revolution ：semidwarf半矮杆 abotic stress resistance 非生物抗逆性 broad-spectrum resistances to biotic stresses广谱生物抗逆性 better grain quality更高的产量 20个水稻品种的变异信息 1,479 rice accessions sequence reads were aligned to the rice reference genome [Nipponbare; Michigan State Uni-versity (MSU), version 6.1]. Sequencing of Diverse Rice Varieties. 1483 accessions Genetic Structure and Diversity of the Rice Varieties Neighbor Joining tree NJ法要求输入的数据必须是待聚类数据(taxa)之间的距离信息,matching distance of 188,637 evenly distributed and randomly selected SNPs. NJ法是一种bottom-up的聚类，故首先要计算出进化距离最近的两个物种，将其聚为一类，再计算出距离该新类最近的一个物种再次聚为一个类，如此迭代，遍历所有输入的物种，构建系统发育树。 https://www.jianshu.com/p/6fc635972c11 XP-CLR (cross-population likelihood method) "},"背景知识/生物学/表观遗传.html":{"url":"背景知识/生物学/表观遗传.html","title":"表观遗传基础","keywords":"","body":"表观遗传 组蛋白修饰基础 组蛋白结构 组蛋白（histone）是真核生物体细胞染色质与原核细胞中的碱性蛋白质，和DNA共同组成核小体结构。它们是染色质的主要蛋白质组分，作为DNA缠绕的线轴，并在基因调控中发挥作用，但是原核细胞组蛋白对基因调控的作用非常微弱。没有组蛋白，染色体中未缠绕的DNA将非常长（人类DNA中的长宽比超过1000万比1）。 组蛋白在染色质中被DNA紧密缠绕，如同念珠一般 核小体 = 组蛋白 + DNA(147bp) 组蛋白八聚体 = 2个H2B + 2个H2A + 2个H3 + 2个H4 每种组蛋白结构都会伸出一个“尾巴”(tail)，是蛋白质的N端，组蛋白修饰就是在tail上进行 组蛋白修饰的描述规则 以共价方式进行的蛋白质翻译后修饰（PTM），包括：甲基化（M)，磷酸化（P），乙酰化（A） 描述规则：组蛋白结构 + 氨基酸名称 + 氨基酸位置 + 修饰类型 H3K4me3：代表H3组蛋白的第4位赖氨酸的三甲基化 H3K14ac：代表H3组蛋白的第14位赖氨酸的乙酰化 组蛋白修饰类型 组蛋白甲基化 甲基化取决于其位置和状态，与抑制或激活有关。 组蛋白甲基化的位点是赖氨酸(K)和精氨酸(R)。 赖氨酸可以分别被一、二、三甲基化，精氨酸只能被一、二甲基化。 研究表明，组蛋白精氨酸甲基化是一种相对动态的标记，精氨酸甲基化与基因激活相关。 相反，赖氨酸甲基化似乎是基因表达调控中一种较为稳定的标记。 例如， H3K4 的甲基化与基因激活相关 H3K9，H3K27单甲基化与基因激活有关，三甲基化与基因沉默相关 H3K9，H3K27甲基化会介导异染色质的形成 组蛋白乙酰化 组蛋白甲基化和乙酰化主要发生在它们的N-末端尾部并且可以影响基因的转录。 组蛋白乙酰化主要与基因激活有关，组蛋白乙酰化主要发生在H3、H4的N端比较保守的赖氨酸位置上，是由组蛋白乙酰转移酶和组蛋白去乙酰化酶协调进行。 特定基因区域的组蛋白乙酰化和去乙酰化是以一种非随机的、位置特异的方式进行。 乙酰化可能通过对组蛋白电荷以及相互作用蛋白的影响，来调节基因转录。 组蛋白修饰也可以发生共同作用 组蛋白修饰在水稻基因表达中的调控机制 组蛋白乙酰化 histone lysine acetylation： dynamic reversible switch for interconversion between permissive and repressive transcriptional states of chromatin domains. dynamic and reversible changes of histone H3K4 methylation and H3 acetylation in responses to environmental changes in rice. （submergence-inducible genes ） 核小体乙酰化动态平衡：histone acetyltransferases and histone deacetylases (HDAC) 组蛋白乙酰转移酶和组蛋白去乙酰化酶 参考资料： https://blog.csdn.net/u011262253/article/details/109957163 https://www.jianshu.com/p/4719b4cfa7d9 "},"背景知识/生物学/文献笔记.html":{"url":"背景知识/生物学/文献笔记.html","title":"文献笔记","keywords":"","body":"文献笔记 "},"背景知识/深度学习/":{"url":"背景知识/深度学习/","title":"深度学习","keywords":"","body":"深度学习 "},"背景知识/深度学习/Pytorch.html":{"url":"背景知识/深度学习/Pytorch.html","title":"Pytorch","keywords":"","body":"Pytorch "},"背景知识/深度学习/CNN.html":{"url":"背景知识/深度学习/CNN.html","title":"CNN","keywords":"","body":"CNN "},"背景知识/深度学习/Transformer.html":{"url":"背景知识/深度学习/Transformer.html","title":"Transformer","keywords":"","body":"Transformer Encoder 1 输入部分 Embedding word2vec 自动初始化 位置编码 RNN：所有的time steps共享一套参数，只更新一套UWV RNN的梯度消失：总梯度和被近距离梯度主导，被远距离梯度忽略不计 天然的时序关系非常符合 Transformer是可以并行化的，所有的单词一起处理，不考虑时序关系，增加了速度，忽略了顺序关系，所以需要位置编码 位置编码公式 偶数位置使用sin，奇数位置使用cos 拓展 位置嵌入的作用 同一个位置，使用sin和cos可以表示绝对位置，绝对位置向量信息中包含着相对位置向量信息 2 注意力机制 基本的注意力机制 人类在观察一张图片时，肯定会有注意力的差别，如图颜色越深代表对此部分的注意力越大，更加关注该区域 比如说提出问题“婴儿在干嘛”，我们需要提取图片中和该问题有关的信息 注意力机制公式 QKV三个矩阵最关键，Q（Query：查询向量）K（Key：键向量）V（Value：值向量） 第一步：Q和K做点乘，得到s 相似度计算：点乘，MLP（网络），cos相似性 点乘：一个向量在另一个向量上投影的长度，是一个标量，可以反映两个向量之间的相似度，点乘结果越大说明距离越近越相似更关注 第二步：对s进行类Softmax()归一化，生成a（相似度，相加为一） 第三步：对V进行加权平均，相加相乘，得到最终结果Attention value Transformer中的注意力机制 如何获取QKV 初始的词向量X，与对应的W矩阵（权重矩阵，可以随机初始化迭代更新）相乘，获取QKV三个向量 Divide by 8 根号下dk ：由于Softmax本身梯度很小，但是S值很大，所以容易发生梯度消失，才需要进行此处理 实际代码使用矩阵进行并行操作 多头注意力机制 相当于将原始数据使用不同的参数在多个空间内进行并行计算， 最后将多个head 的多个输出Z共同输出 残差和LayNorm 处理流程：将词向量x进行位置编码，生成新的词向量X，作为输入，经过self-attention处理，输出Z，然后用Z和X进行对位相加作为残差结果，再进行LayerNorm()处理 残差 为什么残差结构会有用？ 连乘应为1+ (のXc/のXb)*(のXb/のXaout) 确保了梯度不会为零，缓解梯度消失，可以使网络加深 Layer Normalization 为什么使用LN而不使用BN？ BatchNormlization：BN在NLP任务中效果很差，BN本身的作用是在存在多个特征的情况下，对多个特征进行归一化使其能迅速收敛，可以解决内部协变量偏移，缓解了梯度饱和问题，加快收敛 BN针对一个batch中的所有样本的所有特征进行Normliaze，每个特征都是对应的， 缺点： batch_size较小时，效果差，使用一个batch中所有样本的均值和方差来模拟整体的均值和方差，但是如果样本很小不具有代表性 在NLP中，RNN的输入是动态的，与时序有关，如果是一个1*20的向量，就不能用很小的batch来代表整体 LayerNormalization：针对一个样本的所有单词做缩放（均值方差），BN是针对每个单词的不同特征进行缩放，不适合NLP https://academic.oup.com/bib/ 3 Feed Forward前馈神经网络 两层的全连接 ＋ 残差LN Decoder 1 Masked Multi-Head Attention 需要对当前单词和之后的单词做Mask（掩盖） 为什么需要Mask？ 如果不进行mask，在进行训练时，是由所有的单词共同提供的信息进行计算，但是预测时不能看到未来时刻的单词，会产生训练和预测的gap，所以需要掩盖后面的两个单词提供的信息 2 交互层 所有的Encoder生成一个输出，然后这一个输出对每个Decoder进行交互 Encoder生成KV矩阵，Decoder生成Q矩阵，交互层Q矩阵来自于本身，KV矩阵来自于Encoders，进行多头注意力机制 "},"背景知识/深度学习/多模态学习.html":{"url":"背景知识/深度学习/多模态学习.html","title":"多模态学习","keywords":"","body":"多模态学习 "},"背景知识/深度学习/文献笔记.html":{"url":"背景知识/深度学习/文献笔记.html","title":"文献笔记","keywords":"","body":"文献笔记 "}}