# 数据获取与预处理



## 数据命名规则和存放位置

/public/home/xwli/xwzhang/deeplearningDATA/rice/data/

|                                  | name                | location     |
| -------------------------------- | ------------------- | ------------ |
| 序列文件                         | C^^^_C^^^.fasta     | /sequence    |
| 注释文件                         | C^^^_C^^^.fasta.fai | /faidx       |
| 信号区域处理后                   | sort_C^^^.bed       | /signal_area |
| 单品种标签                       | target_C^^^.txt     | /target      |
| 单品种数据集                     | data_C^^^.xlsx      | /dataset     |
| 数据集（data_(数据量)_（随机）） | data_10w_sh.xlsx    | /dataset     |
| onehot编码                       | one_hot_10w_sh.npy  | /onehot      |
| 数据集对应标签                   | labels_10w_sh.txt   | /label       |
| DeepSEA                          | dataset_rice1.npz   | /DeepSEA     |
| DeepHistone                      | dataset_rice2.npz   | /DeepHistone |
| Transformer                      | dataset_rice3.npz   | /Transformer |



## 数据格式

#### fasta

在生物信息学中，FASTA格式（又称为Pearson格式）是一种基于文本的、用于表示核苷酸序列或氨基酸序列的格式。在这种格式中碱基对或氨基酸用单个字母来表示，且允许在序列前添加序列名及注释。

FASTA文件以序列表示和序列作为一个基本单元，各行记录信息如下：

- 第一行是由大于号">"开头的任意文字说明，用于序列标记，为了保证后续分析软件能够区分每条序列，单个序列的标识必须具有唯一性。；
- 从第二行开始为序列本身，只允许使用既定的核苷酸或氨基酸编码符号。通常核苷酸符号大小写均可，而氨基酸常用大写字母。使用时应注意有些程序对大小写有明确要求。文件每行的字母一般不应超过80个字符。

**IRGSP-1.0_genome.fasta**

![image-20210303162337240](https://img.imgdb.cn/item/604b63c15aedab222cd617e3.png)

#### vcf

VCF格式：Variant Call Format，用于记录variants (SNP / InDel)的文件格式

水稻12条染色体的变异信息

SNP汇总： **nip_total.vcf**

**注释部分**

\#

vcf版本

日期

水稻12条染色体的长度

**主体部分** 

CHROM ： 参考序列名称

POS ： variant所在的left-most位置(1-base position)（发生变异的位置的第一个碱基所在的位置）

ID ： variant的ID。同时对应着dbSNP数据库中的ID，若没有，则默认使用‘.’

REF ： 参考序列的Allele，（等位碱基，即参考序列该位置的碱基类型及碱基数量）

ALT ： variant的Allele，**若有多个，则使用逗号分隔**，（变异所支持的碱基类型及碱基数量）这里的碱基类型和碱基数量，对于SNP来说是单个碱基类型的编号，而对于Indel来说是指碱基个数的添加或缺失，以及碱基类型的变化

QUAL ： variants的质量。Phred格式的数值，代表着此位点是**纯合的概率**，**此值越大**，则概率越低，代表着次位点是**variants的可能性越大**。（表示变异碱基的可能性）

FILTER ： 次位点是否要被过滤掉。**如果是PASS，则表示此位点可以考虑为variant。**

INFO ： variant的相关信息

FORMAT ： variants的格式，例如GT:AD:DP:GQ:PL

SAMPLES ： 各个Sample的值，由BAM文件中的@RG下的SM标签所决定，这些值对应着第9列的各个格式，不同格式的值用冒号分开，每一个sample对应着1列；多个samples则对应着多列，这种情况下列的数多余10列。

**nip_total.vcf**

![image-20210303163008087](https://img.imgdb.cn/item/604b63c15aedab222cd617e7.png)

#### narrowPeak

ChIP-seq产生的数据格式

*narrowPeak文件是BED6+4格式，可以上传到UCSC浏览。输出文件每列信息分别包含：

- 1；染色体号

- 2：peak起始位点

- 3：结束位点

- 4：peak name

- 5：int(-10*log10qvalue)

- 6 ：正负链

- 7：fold change

- 8：-log10pvalue

- 9：-log10qvalue

- 10：relative summit position to peak start（？）

  ![image-20210505215028480](https://img.imgdb.cn/item/6092a2c1d1a9ae528ff98f57.png)

![image-20210303164143130](https://img.imgdb.cn/item/604b63c15aedab222cd617ea.png)

#### fai

fasta是常用的序列存储格式，软件对序列进行快速查找的时候通常需要建立索引文件，例如在GATK、IGV等软件中导入序列的时候都需要建立索引。fasta格式文件的一种索引为fai结尾的文件，可以使用samtools faidx命令创建，具体用法如下：

用法：

```shell
samtools faidx input.fa
```

该命令对输入的fasta序列有一定要求：对于每条序列，除了最后一行外， 其他行的长度必须相同

第一列 NAME  :  序列的名称，只保留“>”后，第一个空白之前的内容；

第二列 LENGTH:  序列的长度， 单位为bp；

第三列 OFFSET :  第一个碱基的偏移量， 从0开始计数，换行符也统计进行；

第四列 LINEBASES : 除了最后一行外， 其他代表序列的行的碱基数， 单位为bp；

第五列 LINEWIDTH : 行宽， 除了最后一行外， 其他代表序列的行的长度， 包括换行符， 在windows系统中换行符为\r\n, 要在序列长度的基础上加2；

![image-20210303164442136](https://img.imgdb.cn/item/604b63c15aedab222cd617ee.png)

#### bed

> BED (Browser Extensible Data)格式文件就是通过规定行的内容来展示注释信息

- BED文件每行至少包括**chrom**，**chromStart**，**chromEnd**三列；另外还可以添加额外的9列，这些列的顺序是固定的。
- 在自定义BED文件时，前面可以有注释行，以“browser”或“track”开头，可以设置一些参数便于浏览器更好展示BED文件信息。但是，下游的一些分析工具，例如bedToBigBed，是不接受有注释的BED文件的。

------

**# BED文件必须的3列:**

1. **chrom** - 染色体号; 例如，chr1，chrX。。。。。。。
2. **chromStart** - feature在染色体上起始位置. 从0开始算，染色体上第一个碱基位置标记为0。
3. **chromEnd** - feature在染色体上终止位置。染色体上前100个碱基片段的位置位置标记为：chromStart=0, chromEnd=100。 实际上，第100个碱基不属于当前片段中，当前片段的碱基应该是0-99。所以在BED文件中，起始位置从0开始，终止位置从1开始。

**# BED文件可选的9列:**

1. **name** - BED行名，在基因组浏览器左边显示；
2. **score** - 在基因组浏览器中显示的灰度设定，值介于0-1000；

![img](https://img.imgdb.cn/item/6092a2fad1a9ae528ffc45f2.png)

gray score

1. **strand** - 正负链标记. Either "." (=no strand) or "+" or "-".

2. **thickStart** - feature起始位置(for example, the start codon in gene displays)。 When there is no thick part, thickStart and thickEnd are usually set to the chromStart position.

3. **thickEnd** -  feature编码终止位置 (for example the stop codon in gene displays).

4. **itemRgb** - R,G,B (e.g. 255,0,0)值，当*itemRgb* 设置为 "On"，BED的行会显示颜色.

5. **blockCount** - blocks (exons)数目.

6. **blockSizes** - blocks (exons)大小列表，逗号分隔，对应于*blockCount*.

7. **blockStarts** -blocks (exons)起始位置列表，逗号分隔，对应于*blockCount*.；这个起始位置是与*chromStart*的一个相对位置。

   **sort_C019_peak.bed**

![image-20210303165719055](https://img.imgdb.cn/item/604b63c15aedab222cd617f4.png)

#### .npy/.npz

npy文件是Numpy专用的二进制格式文件，可以用来保存numpy.array

```python
import numpy as np

# 将数组以二进制格式保存到磁盘
arr=np.arange(5)
np.save('test',arr)
# 读取数组
print(np.load('test.npy'))
```

npz文件是Numpy的压缩文件，可以将多个数组压缩保存到同一个文件中。

```python
import numpy as np

# 将多个数组保存到磁盘
a = np.arange(5)
b = np.arange(6)
c = np.arange(7)
np.savez('test', a, b, c_array=c)  # c_array是数组c的命名
# 读取数组
data = np.load('test.npz')  #类似于字典{‘arr_0’:a,’arr_1’:b,’c_array’:c}
print('arr_0 : ', data['arr_0'])
print('arr_1 : ', data['arr_1'])
print('c_array : ', data['c_array'])

--------------------------------------------------------------------------------
arr_0 :  [0 1 2 3 4]
arr_1 :  [0 1 2 3 4 5]
c_array :  [0 1 2 3 4 5 6]
```



## 生成数据集

本部分包含数据处理脚本的全部更新过程，想查看最新版本数据处理流程请跳转至**[生成数据集总流程（bash脚本）](###生成数据集总流程（bash脚本）)**

### 参考基因组下载

水稻日本晴第七版

```shell
wget http://rapdb.dna.affrc.go.jp/download/archive/irgsp1/IRGSP-1.0_genome.fasta.gz
gunzip IRGSP-1.0_genome.fasta.gz
```

查看基因组的大小和ID

```shell
bioawk -c fastx '{print $1 "\t" length($seq)}' IRGSP-1.0_genome.fasta
```

![image-20210303152902570](https://img.imgdb.cn/item/604b63b85aedab222cd611fc.png)

### 生成品种基因型

以NIP为示例，后续使用其他品种扩大数据集

![image-20210317091915614](https://img.imgdb.cn/item/6092a31ad1a9ae528ffdd058.png)

##### python脚本 geno_sub.py

*目前使用脚本geno_sub2.0.py, 解决兼并碱基的问题*（2021.3.28）

*使用bash脚本批量并行提交作业*

注：bash脚本在windows上编辑后在Linux运行会报错

```txt
scripts/sh_scripts/geno_make.sh: line 4: syntax error near unexpected token `$'do\r''
'cripts/sh_scripts/geno_make.sh: line 4: `do
```

解决方法：

https://www.jianshu.com/p/55597646fa84

```shell
sed 's/\r//' input.sh > output.sh
```



```shell
#!/bin/bash
#生成品种基因型，参考基因组日本晴第七版
for i in $(cat id1)
do
    bsub -q high -e ${i}.err -o ${i}.out "python3 scripts/py_scripts/geno_sub.py -s data/vcf/sort.total.vcf -n ${i} -r data/ref/IRGSP-1.0_genome.fasta -l 500"
done

```

**python脚本使用方法**

```shell
$ python3 geno_sub.py  -h
usage: geno_sub.py [-h] -s  -n  -r  [-l]

New sample genome sequence based on snp data

optional arguments:
  -h, --help          show this help message and exit
  -s , --snpfile      snp file in vcf format
  -n , --samplename   sample name, which mest be in snpfile
  -r , --reference    reference file
  -l , --seqlen       seq length per line in output file
```

*input*

| Format              | Description                                      | location |
| ------------------- | ------------------------------------------------ | -------- |
| [.fasta](####fasta) | 日本晴第七版参考基因组（IRGSP-1.0_genome.fasta） | data/ref |
| [.vcf](####vcf)     | 水稻变异信息(vcf)                                | data/vcf |

*output*

| Format              | Description                       | Location      |
| ------------------- | --------------------------------- | ------------- |
| [.fasta](####fasta) | 水稻品种自定义基因组（C^^^.fasta) | data/sequence |
| .fasta              | 水稻基因组（无>,paste时使用)      | data/seq      |

**示例**

```shell
bsub 'python3 scripts/geno_sub.py -s data/vcf/*.vcf -n C^^^ -r data/ref/*fasta -l 500'
```



```python
#geno_sub.py
import re
import os
import sys
import argparse
from collections import defaultdict

def defaultdict_list():
    return defaultdict(list)

def snpInfo(snp):
    '''
    处理位点文件，记录样本发生变异的位点坐标信息
    '''
    snp_file = open(snp, 'r')
    snp_info = defaultdict(defaultdict_list)
    snp_geno = defaultdict(defaultdict_list)
    for line in snp_file:
        if line.startswith('##') or re.search('^$',line.strip()):
            continue
        elif line.startswith('#CHROM'):
            line_info = line.strip().split('\t')
            sample_list = line_info[9:]
        else:
            line_info = line.strip().split('\t')
            for i in range(len(sample_list)):
                if  line_info[i+9]!='0|0':
                    snp_info[sample_list[i]][line_info[0]].append(int(line_info[1]))
                    snp_geno[sample_list[i]][line_info[0]].append([line_info[3], line_info[4]])
    snp_file.close()
    return snp_info, snp_geno

def genomePar(genome):
    '''
    解析基因组文件
    '''
    genome_file = open(genome, 'r')
    seq = ''
    seq_name = ''
    seq_info = {}
    for line in genome_file:
        if line.startswith('>') and seq == '':
            seq_name = re.sub('chr0|chr', '',line.strip()[1:])
        elif line.startswith('>') and seq != '':
            seq_info[seq_name] = seq
            seq_name = re.sub('chr0|chr', '',line.strip()[1:])
            seq = ''
        else:
            seq += line.strip()
    seq_info[seq_name] = seq
    genome_file.close()
    return seq_info

def seqFormat(seq, lenset=60):
    '''
    按指定长度替换数据
    '''
    format_seq = ''
    for i in range(1, len(seq)+1):
        if i % lenset == 0:
            format_seq += seq[i-1]+"\n"
        else:
            format_seq += seq[i-1]
    return format_seq

def faOut(snppos, snpgeno, fasta, sample, lenset=60):
    '''
    根据snppos内储存的信息，对基因组中的碱基进行替换
    '''
    out_fasta = open(f'{sample}.fasta', 'w')
    for key in fasta:
        n = 1
        seq = ''
        for i in fasta[key]:
            if len(snppos[sample][key])!=0 and n==snppos[sample][key][0]:
                try:
                    ref_index = snpgeno[sample][key][0].index(i.upper())
                    #print (ref_index, snpgeno[sample][key][0])
                    if ref_index == 0:
                        seq += snpgeno[sample][key][0][1]
                    else:
                        seq += snpgeno[sample][key][0][0]
                except:
                    print (f'chr {key} in pos {n} for sample {sample} is wrong: the ref is {i}, but geno is {snpgeno[sample][key][0]}')
                    seq += i
                finally:
                    snppos[sample][key].pop(0)
                    snpgeno[sample][key].pop(0)
            else:
                seq += i
            n += 1
        chr_id = 'chr{:0>2d}'.format(int(key))
        seq = seqFormat(seq, lenset)
        out_fasta.write(f'>{chr_id}\n{seq}\n')
    out_fasta.close()
    
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="New sample genome sequence based on snp data")
    parser.add_argument("-s", "--snpfile", metavar="", required=True, help="snp file in vcf format")
    parser.add_argument("-n", "--samplename", metavar="", required=True, help="sample name, which mest be in snpfile")
    parser.add_argument("-r", "--reference", metavar="", required=True, help="reference file")
    parser.add_argument("-l", "--seqlen", metavar="", default=60, type=int, help="seq length per line in output file")
    args = parser.parse_args()
    # 解析变异信息文件
    snppos, snpgeno = snpInfo(args.snpfile)
    # 解析基因组文件
    fasta = genomePar(args.reference)
    # 输出替换的结果
    faOut(snppos, snpgeno, fasta, args.samplename, args.seqlen)
   

```

```shell
#删除含有N（n）的行
sed -i '/N/d' C^^^.fasta | sed -i '/n/d'
```

```python
#geno_sub2.0.py
import re
import os
import sys
import argparse
from collections import defaultdict

def defaultdict_list():
    return defaultdict(list)

def snpInfo(snp):
    '''
    处理位点文件，记录样本发生变异的位点坐标信息
    '''
    degeneration = {'AG':'R','GA':'R','CT':'Y','TC':'Y',
                    'AC':'M','CA':'M','GT':'K','TG':'K',
                    'GC':'S','CG':'S','AT':'W','TA':'W'}
    snp_file = open(snp, 'r')
    snp_info = defaultdict(defaultdict_list)
    snp_geno = defaultdict(defaultdict_list)
    for line in snp_file:
        if line.startswith('##') or re.search('^$',line.strip()):
            continue
        elif line.startswith('#CHROM'):
            line_info = line.strip().split('\t')
            sample_list = line_info[9:]
        else:
            line_info = line.strip().split('\t')
            for i in range(len(sample_list)):
                if line_info[i+9]!='' and line_info[i+9]!='0|0' and line_info!=".|.":
                    sample_allele = list(set(line_info[i+9].split('|')))
                    ref = line_info[3]
                    alts = [ref]
                    alts.extend(line_info[4].split(','))
                    if len(ref) == 1:
                        snp_info[sample_list[i]][line_info[0]].append(int(line_info[1]))
                        if len(sample_allele) == 1:
                            snp_geno[sample_list[i]][line_info[0]].append([alts[int(sample_allele[0])]])
                        else:
                            biallele = ''.join([alts[int(sample_allele[0])],alts[int(sample_allele[1])]])
                            if len(biallele)!=2:
                                snp_geno[sample_list[i]][line_info[0]].append(alts[int(sample_allele[1])])
                            else:
                                snp_geno[sample_list[i]][line_info[0]].append(degeneration[biallele])
                    else:
                        snp_info[sample_list[i]][line_info[0]].append([int(line_info[1]),int(line_info[1])+len(alts[0])-1])
                        if len(sample_allele) == 1:
                            snp_geno[sample_list[i]][line_info[0]].append([alts[int(sample_allele[0])]])
                        else:
                            biallele = ''.join([alts[int(sample_allele[0])],alts[int(sample_allele[1])]])
                            snp_geno[sample_list[i]][line_info[0]].append(alts[int(sample_allele[0])])

    snp_file.close()
    return snp_info, snp_geno

def genomePar(genome):
    '''
    解析基因组文件
    '''
    genome_file = open(genome, 'r')
    seq = ''
    seq_name = ''
    seq_info = {}
    for line in genome_file:
        if line.startswith('>') and seq == '':
            seq_name = re.sub('chr0|chr', '',line.strip()[1:])
        elif line.startswith('>') and seq != '':
            seq_info[seq_name] = seq
            seq_name = re.sub('chr0|chr', '',line.strip()[1:])
            seq = ''
        else:
            seq += line.strip()
    seq_info[seq_name] = seq
    genome_file.close()
    return seq_info

def seqFormat(seq, lenset=500):
    '''
    按指定长度替换数据
    '''
    format_seq = ''
    for i in range(1, len(seq)+1):
        if i % lenset == 0:
            format_seq += seq[i-1]+"\n"
        else:
            format_seq += seq[i-1]
    return format_seq

def faOut(snppos, snpgeno, fasta, sample, lenset=60):
    '''
    根据snppos内储存的信息，对基因组中的碱基进行替换
    '''
    fasta_file = open(fasta, 'r')
    out_fasta = open(f'{sample}.fasta', 'w')
    for line in fasta_file:
        if line.startswith('>'):
            #print (line)
            seq_name = re.sub('chr0|chr', '',line.strip()[1:])
            out_fasta.write(f'>{seq_name}\n')
            start = 1
        else:
            for i in range(len(line.strip())):
                if len(snppos[sample][seq_name]) == 0:
                    out_fasta.write(line[i])
                elif i == snppos[sample][seq_name][0]:
                    out_fasta.write(snpgeno[sample][seq_name][0])
                    snppos[sample][seq_name].pop(0)
                    snpgeno[sample][seq_name].pop(0)
                elif isinstance(snppos[sample][seq_name][0], list) and i in snppos[sample][seq_name][0]:
                    out_fasta.write(snpgeno[sample][seq_name][0])
                    i = snppos[sample][seq_name][0]
                    snppos[sample][seq_name].pop(0)
                    snpgeno[sample][seq_name].pop(0)
                else:
                    out_fasta.write(line[i])
            out_fasta.write('\n')

    '''
    for key in fasta:
        n = 1
        seq = ''
        for i in fasta[key]:
            if len(snppos[sample][key])!=0 and n==snppos[sample][key][0]:
                try:
                    ref_index = snpgeno[sample][key][0].index(i.upper())
                    #print (ref_index, snpgeno[sample][key][0])
                    if ref_index == 0:
                        seq += snpgeno[sample][key][0][1]
                    else:
                        seq += snpgeno[sample][key][0][0]
                except:
                    print (f'chr {key} in pos {n} for sample {sample} is wrong: the ref is {i}, but geno is {snpgeno[sample][key][0]}')
                    seq += i
                finally:
                    snppos[sample][key].pop(0)
                    snpgeno[sample][key].pop(0)
            else:
                seq += i
            n += 1
        chr_id = 'chr{:0>2d}'.format(int(key))
        seq = seqFormat(seq, lenset)
        out_fasta.write(f'>{chr_id}\n{seq}\n')
    out_fasta.close()
    '''
    
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="New sample genome sequence based on snp data")
    parser.add_argument("-s", "--snpfile", metavar="", required=True, help="snp file in vcf format")
    parser.add_argument("-n", "--samplename", metavar="", required=True, help="sample name, which mest be in snpfile")
    parser.add_argument("-r", "--reference", metavar="", required=True, help="reference file")
    parser.add_argument("-l", "--seqlen", metavar="", default=60, type=int, help="seq length per line in output file")
    args = parser.parse_args()
    # 解析变异信息文件
    snppos, snpgeno = snpInfo(args.snpfile)
    # 输出替换的结果
    faOut(snppos, snpgeno, args.reference, args.samplename, args.seqlen)

```



### 生成组蛋白修饰标签

*目前使用bash脚本自动化并行处理标签生成任务(2021.3.28)*



**分别提取组蛋白修饰信号区域**

*input* ：narrowPeak文件

*output*：bed文件

组蛋白修饰**H3K4me3, H3K27ac, H3K4me1, H3K27me3， H3K9me2**

```shell
awk '{print $1,$2,$3}' mapto*/*_seedlings/*C^^^_peaks.narrowPeak | sort -t ' '  -k1.4nr >> C^^^.bed
```

`按照染色体顺序排列，并计数

```shell
sort -k1,1V -k2,2n -k3,3n C^^^.bed > data/signal_area/sort_C^^^.bed
rm -f C^^^.bed
cat data/signal_area/sort_C^^^.bed | awk '{print $1}' | uniq -c
```

```shell
ls *fasta | while read id;do echo ${id%.*} >> id.txt;done
#提取品种id

#area_extract.sh
#!/bin/bash
for n in $(cat histone)
do
    for i in $(cat id.txt)
    do
      awk '{print $1,$2,$3}' mapto*/${n}_seedlings/*${i}_peaks.*Peak | sort -t ' ' -k1,4nr | sort -k1,1V -k2,2n -k3,3n > data/signal_area/sort_${i}_${n}.bed
      done
done

```

**生成自定义基因组的fai文件**

```shell
samtools faidx data/sequence/C^^^.fasta
```



**生成标签**

##### python脚本target_mark.py

**使用方法**

```shell
$ python3 target_mark.py -h
usage: 20210302_bin_count.py [-h] -f  -b  -o  [-w] [-l]

bin data out

optional arguments:
  -h, --help       show this help message and exit
  -f , --fai       reference index file in fai
  -b , --bed       bed file
  -o , --output    output file
  -w , --window    window size
  -l , --overlap   overlap size
```

*input*

| Format                        | Description                           | Location              |
| ----------------------------- | ------------------------------------- | --------------------- |
| [.narrowPeak](####narrowPeak) | 20个水稻品种的ChIP-seq结果            | mapto_MSU7/*seedlings |
| [.bed](####bed)               | 组蛋白修饰信号区域 sort_C^^^_C^^^.bed | data/signal_area      |
| [.fai](####fai)               | fasta文件的索引 C^^^_C^^^.fasta.fai   | data/faidx            |

*output*

| Format       | Description   | Location    |
| ------------ | ------------- | ----------- |
| .txt（1.0）  | 标签[0,1]     | data/target |
| .txt   (2.0) | onehot标签1-5 | da          |

**示例**

```shell
bsub 'python3 scripts/target_mark.py -f data/faidx/C019_C019.fasta.fai -b data/signal_area/sort_C^^^.bed -o target_C^^^.bed'
bsub -e 11.err -o 11.out 'python3 target_mark3.0.py -f data/sequence/C019.fasta.fai -b data/signal_area/sort_C019_H3K4me3.bed -o target_C019_H3K4me3.bed -s C019 -m H3K4me3'
```

```shell
#!/bin/bash
for n in $(cat histone)
do 
    for i in $(cat id.txt)
    do 
    python3 scripts/py_scripts/target_mark3.0.py -f data/seq/${i}.fasta.fai -b data/signal_area/sort_${i}_${n}.bed -o target_${i}_${n}.bed && awk '{print $3}' target_${i}_${n}.bed > data/target/target_${i}_${n}.txt && rm -f *bed
    done
done
bsub -e 11.err -o 11.out 'python3 target_mark3.0.py -f data/sequence/C019.fasta.fai -b data/signal_area/sort_C019_H3K4me3.bed -o target_C019_H3K4me3.bed -s C019 -m H3K4me3'
```



```python
import re
import os
import sys
import argparse
from collections import defaultdict

def getRefLen(fai):
    '''
    读取fai文件，获取基因组长度
    '''
    fai_file = open(fai, 'r')
    ref_Length = {}
    for line in fai_file:
        chr_id, seq_len, *other = line.strip().split('\t')
        ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len)
    return ref_Length

def bedParse(bed):
    '''
    解析bed文件，分染色体返回预设区间信息
    '''
    region = defaultdict(list)
    bed_info = open(bed, 'r')
    for line in bed_info:
        chr_id, start, end = re.split('\s', line.strip())
        chr_id = re.sub('chr0|chr', '', chr_id)
        region[chr_id].append((int(start), int(end)))
    bed_info.close()
    return region

def binCal(region, reflen, out, win=500, overlap=250):
    '''
    根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0
    '''
    out_file = open(out, 'w')
    bin = 0
    for chr in reflen:
        for i in range(0, reflen[chr]-500, 500):
            start_tmp = i
            end_tmp = i+win
            region_chr = region[chr]
            for start, end in region_chr:
                
                if end_tmp < start+overlap:
                    bin = 0
                    break
                elif start<=start_tmp<=end:
                    if end_tmp<=end :
                        bin = 1
                        break
                    else:
                        if end-start_tmp>overlap:
                            bin = 1
                        else:
                            bin = 0
                        break
                elif start_tmp>=end:
                    region[chr].remove((start, end))
            out_file.write(f'{chr}\t{i}\t{bin}\t{start}\t{end}\n')
    out_file.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="bin data out")
    parser.add_argument("-f", "--fai", metavar="", required=True, help="reference index file in fai")
    parser.add_argument("-b", "--bed", metavar="", required=True, help="bed file")
    parser.add_argument("-o", "--output", metavar="", required=True, help="output file")
    parser.add_argument("-w", "--window", metavar="", default=500, type=int, help="window size")
    parser.add_argument("-l", "--overlap", metavar="", default=250, type=int, help="overlap size")
    args = parser.parse_args()
    # 解析索引文件
    reflen = getRefLen(args.fai)
    # 解析bed文件
    region = bedParse(args.bed)
    # 输出bin结果
    binCal(region, reflen, args.output, args.window, args.overlap)

```



```python
#target_mark2.0.py
import re
import os
import sys
import argparse
from collections import defaultdict

def getRefLen(fai):
    '''
    读取fai文件，获取基因组长度
    '''
    fai_file = open(fai, 'r')
    ref_Length = {}
    for line in fai_file:
        chr_id, seq_len, *other = line.strip().split('\t')
        ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len)
    return ref_Length

def bedParse(bed):
    '''
    解析bed文件，分染色体返回预设区间信息
    '''
    region = defaultdict(list)
    bed_info = open(bed, 'r')
    for line in bed_info:
        chr_id, start, end = re.split('\s', line.strip())
        chr_id = re.sub('chr0|chr', '', chr_id)
        region[chr_id].append((int(start), int(end)))
    bed_info.close()
    return region

def binCal(region, reflen, out, win=500, overlap=250):
    '''
    根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0
    '''
    out_file = open(out, 'w')
    bin = 0
    for chr in reflen:
        for i in range(0, reflen[chr]-500, 500):
            start_tmp = i
            end_tmp = i+win
            region_chr = region[chr]
            for start, end in region_chr:
                
                if end_tmp < start+overlap:
                    bin = 0
                    break
                elif start<=start_tmp<=end:
                    if end_tmp<=end :
                        bin = 1
                        break
                    else:
                        if end-start_tmp>overlap:
                            bin = 1
                        else:
                            bin = 0
                        break
                elif start_tmp>=end:
                    region[chr].remove((start, end))
            out_file.write(f'{chr}\t{i}\t{bin}\t{start}\t{end}\n')
    out_file.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="bin data out")
    parser.add_argument("-f", "--fai", metavar="", required=True, help="reference index file in fai")
    parser.add_argument("-b", "--bed", metavar="", required=True, help="bed file")
    parser.add_argument("-o", "--output", metavar="", required=True, help="output file")
    parser.add_argument("-w", "--window", metavar="", default=500, type=int, help="window size")
    parser.add_argument("-l", "--overlap", metavar="", default=250, type=int, help="overlap size")
    args = parser.parse_args()
    # 解析索引文件
    reflen = getRefLen(args.fai)
    # 解析bed文件
    region = bedParse(args.bed)
    # 输出bin结果
    binCal(region, reflen, args.output, args.window, args.overlap)
```



```python
#target_mark3.0.py
import re
import os
import sys
import argparse
from collections import defaultdict

def getRefLen(fai):
    '''
    读取fai文件，获取基因组长度
    '''
    fai_file = open(fai, 'r')
    ref_Length = {}
    for line in fai_file:
        chr_id, seq_len, *other = line.strip().split('\t')
        ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len)
    return ref_Length

def bedParse(bed):
    '''
    解析bed文件，分染色体返回预设区间信息
    '''
    region = defaultdict(list)
    bed_info = open(bed, 'r')
    for line in bed_info:
        chr_id, start, end = re.split('\s', line.strip())
        chr_id = re.sub('chr0|chr', '', chr_id)
        region[chr_id].append((int(start), int(end)))
    bed_info.close()
    return region

def binCal(region, reflen, out, win=500, overlap=250,threshold = 0.1):
    '''
    根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0
    '''
    out_file = open(out, 'w')
    bin = 0
    for chr in reflen:
        for i in range(0, reflen[chr], 500):
            if chr == '1':
                print (i)
            start_tmp = i
            end_tmp = i+win
            region_chr = region[chr]
            for start, end in region_chr:
                mid = (start + end)/2
                start_mid = mid - (overlap/2)
                end_mid = mid + (overlap/2)
                if end_tmp < start_mid + threshold * overlap :
                    bin = 0
                    break
                elif start_tmp < start_mid and end_tmp > end_mid:
                    bin = 1
                    break 
                elif start_mid<=start_tmp<=end_mid:
                    if end_mid-start_tmp>threshold * overlap:
                        bin = 1
                    else:
                        bin = 0
                        break
                elif start_tmp>=end_mid:
                    region[chr].remove((start, end))
            out_file.write(f'{chr}\t{i}\t{bin}\t{start}\t{end}\n')
    out_file.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="bin data out")
    parser.add_argument("-f", "--fai", metavar="", required=True, help="reference index file in fai")
    parser.add_argument("-b", "--bed", metavar="", required=True, help="bed file")
    parser.add_argument("-o", "--output", metavar="", required=True, help="output file")
    parser.add_argument("-w", "--window", metavar="", default=500, type=int, help="window size")
    parser.add_argument("-l", "--overlap", metavar="", default=250, type=int, help="overlap size")
    args = parser.parse_args()
    # 解析索引文件
    reflen = getRefLen(args.fai)
    # 解析bed文件
    region = bedParse(args.bed)
    # 输出bin结果
    binCal(region, reflen, args.output, args.window, args.overlap)

```



```python
#target_mark4.0.py
import re
import os
import sys
import argparse
from collections import defaultdict

def getRefLen(fai):
    '''
    读取fai文件，获取基因组长度
    '''
    fai_file = open(fai, 'r')
    ref_Length = {}
    for line in fai_file:
        chr_id, seq_len, *other = line.strip().split('\t')
        ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len)
    return ref_Length

def bedParse(bed):
    '''
    解析bed文件，分染色体返回预设区间信息
    '''
    region = defaultdict(list)
    bed_info = open(bed, 'r')
    for line in bed_info:
        chr_id, start, end = re.split('\s', line.strip())
        chr_id = re.sub('chr0|chr', '', chr_id)
        region[chr_id].append((int(start), int(end)))
    bed_info.close()
    return region

def binCal(region, reflen, species, histone, out, win=500, overlap=250,threshold = 0.1):
    '''
    根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0
    '''
    out_file = open(out, 'w')
    bin = 0
    for chr in reflen:
        for i in range(0, reflen[chr], 500):
            if chr == '1':
                print (i)
            start_tmp = i
            end_tmp = i+win
            region_chr = region[chr]
            name = f'{species}_{histone}_{chr}_{start_tmp}_{end_tmp}'
            for start, end in region_chr:
                mid = (start + end)/2
                start_mid = mid - (overlap/2)
                end_mid = mid + (overlap/2)
                if end_tmp < start_mid + threshold * overlap :
                    bin = 0
                    break
                elif start_tmp < start_mid and end_tmp > end_mid:
                    bin = 1
                    break 
                elif start_mid<=start_tmp<=end_mid:
                    if end_mid-start_tmp>threshold * overlap:
                        bin = 1
                    else:
                        bin = 0
                        break
                elif start_tmp>=end_mid:
                    region[chr].remove((start, end))
            out_file.write(f'{name}\t{bin}\n')
    out_file.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="bin data out")
    parser.add_argument("-f", "--fai", metavar="", required=True, help="reference index file in fai")
    parser.add_argument("-b", "--bed", metavar="", required=True, help="bed file")
    parser.add_argument("-o", "--output", metavar="", required=True, help="output file")
    parser.add_argument("-w", "--window", metavar="", default=500, type=int, help="window size")
    parser.add_argument("-l", "--overlap", metavar="", default=250, type=int, help="overlap size")
    parser.add_argument("-s", "--species", metavar="", help="rice species")
    parser.add_argument("-m", "--histone", metavar="", help="histone modifications")
    args = parser.parse_args()
    # 解析索引文件
    reflen = getRefLen(args.fai)
    # 解析bed文件
    region = bedParse(args.bed)
    # 输出bin结果
    binCal(region, reflen, args.species, args.histone, args.output, args.window, args.overlap)

```



```python
#target_mark5.0.py
import re
import os
import sys
import argparse
from collections import defaultdict

def getRefLen(fai):
    '''
    读取fai文件，获取基因组长度
    '''
    fai_file = open(fai, 'r')
    ref_Length = {}
    for line in fai_file:
        chr_id, seq_len, *other = line.strip().split('\t')
        ref_Length[re.sub('chr0|chr','',chr_id)] = int(seq_len)
    return ref_Length

def bedParse(bed):
    '''
    解析bed文件，分染色体返回预设区间信息
    '''
    region = defaultdict(list)
    bed_info = open(bed, 'r')
    for line in bed_info:
        chr_id, start, end = re.split('\s', line.strip())
        chr_id = re.sub('chr0|chr', '', chr_id)
        region[chr_id].append((int(start), int(end)))
    bed_info.close()
    return region

def binCal(region, reflen, species, histone, tar, out, win=500, overlap=250,threshold = 0.1):
    '''
    根据预设的region，遍历基因组，统计每窗口win内的交集片段大小，overlap超过一定范围后输出1，否则输出0
    '''
    out_file = open(out, 'w')
    bin = 0
    for chr in reflen:
        for i in range(0, reflen[chr], 500):
            if chr == '1':
                print (i)
            start_tmp = i
            end_tmp = i+win
            region_chr = region[chr]
            name = f'{species}_{histone}_{chr}_{start_tmp}_{end_tmp}'
            for start, end in region_chr:
                mid = (start + end)/2
                start_mid = mid - (overlap/2)
                end_mid = mid + (overlap/2)
                if end_tmp < start_mid + threshold * overlap :
                    bin = 0
                    break
                elif start_tmp < start_mid and end_tmp > end_mid:
                    bin = tar
                    break 
                elif start_mid<=start_tmp<=end_mid:
                    if end_mid-start_tmp>threshold * overlap:
                        bin = tar
                    else:
                        bin = 0
                        break
                elif start_tmp>=end_mid:
                    region[chr].remove((start, end))
            out_file.write(f'{name}\t{bin}\n')
    out_file.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="bin data out")
    parser.add_argument("-f", "--fai", metavar="", required=True, help="reference index file in fai")
    parser.add_argument("-b", "--bed", metavar="", required=True, help="bed file")
    parser.add_argument("-o", "--output", metavar="", required=True, help="output file")
    parser.add_argument("-w", "--window", metavar="", default=500, type=int, help="window size")
    #parser.add_argument("-l", "--overlap", metavar="", default=250, type=int, help="overlap size")
    parser.add_argument("-s", "--species", metavar="", help="rice species")
    parser.add_argument("-m", "--histone", metavar="", help="histone modifications")
    args = parser.parse_args()
    # 解析索引文件
    reflen = getRefLen(args.fai)
    # 解析bed文件
    region = bedParse(args.bed)
    # 输出bin结果
    tar = 0
    if args.histone == 'H3K4me3':
        tar = 1 
        overlap = 250
    elif args.histone == 'H3K27ac':
        tar = 2
        overlap = 250
    elif args.histone == 'H3K4me1':
        tar = 3
        overlap = 750
    elif args.histone == 'H3K27me3':
        tar = 4 
        overlap = 750
    elif args.histone == 'H3K9me2':
        tar = 5
        overlap = 1000
       
    binCal(region, reflen, args.species, args.histone, tar, args.output, args.window, overlap)
```





**提取bin列作为标签**

```shell
awk '{print $3}' target_C^^^.bed  >> data/target/target_C^^^.txt
rm -f target_C^^^.bed
```

**删除fasta文件中的染色体行**

```shell
sed -i '/>/d' C^^^_C^^^.
```

### 合成数据集

| data                        | target                        |
| --------------------------- | ----------------------------- |
| 500bp sequence              | 1 for 组蛋白修饰 0 for 无修饰 |
| one-hot编码 [nums, 500, 4 ] | [1,0]                         |

**将数据导入excel文件**（data_C^^^.xlxs)

![image-20210309164729766](https://img.imgdb.cn/item/604b63d65aedab222cd6247b.png)



**数据分布**(C019)

| 1    | 478680 |
| ---- | ------ |
| 0    | 267802 |
| 总计 | 746483 |



**合成标签均衡，随机分布的数据集**

```shell
paste data/sequence/C^^^.fasta data/target/target_C^^^.txt > data/dataset/C^^^.csv
```

```shell
#!/bin/bash
for n in $(cat histone)
do  
    mkdir ${n}
    for i in $(cat id.txt)
    do
       paste data/seq/${i}.fasta data/target/target_${i}_${n}.txt > data/dataset/${n}/${i}_${n}.csv && sed -i '/>/d'data/dataset/${n}/${i}_${n}.csv
    done
done
```

**输入数据**

以onehot（[4,500]）的形式输入

![image-20210309165331885](https://img.imgdb.cn/item/604b63e25aedab222cd62b39.png)

**OneHotEncoder.py**

注意将excel中含有N(n)的序列删去，否则会引起维度不统一

```python
import numpy as np
import pandas as pd
import torch

np.set_printoptions(threshold= np.inf)

# function to convert a DNA sequence string to a numpy array
# converts to lower case, changes any non 'acgt' characters to 'n'
import re
def string_to_array(my_string):
    my_string = my_string.lower()
    my_string = re.sub('[^acgt]', 'z', my_string)
    my_array = np.array(list(my_string))
    return my_array
# create a label encoder with 'acgtn' alphabet
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
label_encoder.fit(np.array(['a','c','g','t','z']))

# function to one-hot encode a DNA sequence string
# non 'acgt' bases (n) are 0000
# returns a L x 4 numpy array
from sklearn.preprocessing import OneHotEncoder
def one_hot_encoder(my_array):
    integer_encoded = label_encoder.transform(my_array)
    onehot_encoder = OneHotEncoder(sparse=False, dtype=int)
    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)
    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)
    return onehot_encoded

data = pd.read_excel(r'./data_bal.xlsx',header = None)

one_hot_matrix = []
for i in range(10000):
    one_hot_matrix.append(one_hot_encoder(string_to_array(data[0][i])))

np.save('one_hot',one_hot_matrix)
one = np.load('./one_hot.npy',allow_pickle=True)
one.shape
```

**OneHotEncoder2.0.py**

1.加入argparse接口，方便命令行使用

2.改为双功能函数，check：对数据集进行清理，删除不符合编码规则的样本；make：对数据集进行onehot编码



```python
#OneHotEncoder2.0.py
#coding: utf-8

import numpy as np
import pandas as pd
import torch
import os
import sys
import argparse
from collections import defaultdict

# function to convert a DNA sequence string to a numpy array
# converts to lower case, changes any non 'acgt' characters to 'n'
import re
def string_to_array(my_string):
    my_string = my_string.lower()
    my_string = re.sub('[^acgt]', 'z', my_string)
    my_array = np.array(list(my_string))
    return my_array

# create a label encoder with 'acgtn' alphabet
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
label_encoder.fit(np.array(['a','c','g','t','z']))




# function to one-hot encode a DNA sequence string
# non 'acgt' bases (n) are 0000
# returns a L x 4 numpy array
from sklearn.preprocessing import OneHotEncoder
def one_hot_encoder(my_array):
    integer_encoded = label_encoder.transform(my_array)
    onehot_encoder = OneHotEncoder(sparse=False, dtype=int)
    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)
    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)
    return onehot_encoded


global one_hot_matrix
global index_to_delete
one_hot_matrix = []
index_to_delete = []
 
def encoder(data):
    one_hot_matrix = []
    for i in range(len(data)):
        one_hot_matrix.append(one_hot_encoder(string_to_array(data[0][i])))
    return one_hot_matrix

def delete(one_hot_matrix):
    
    for i in range(len(data)):
        if one_hot_matrix[i].shape != (500,4):
            index_to_delete.append(i)
    #one_hot_matrix = [one_hot_matrix[i] for i in range(0, len(one_hot_matrix),1) if i not in index_to_delete]
    return index_to_delete
def labels_marker(histone, nums):
    
    labels = data.iloc[:len(data),1]
    #labels.drop(index = index_to_delete, axis = 0, inplace = True)
    labels.to_csv('labels_{a}_{b}.txt'.format(a=histone, b=nums),sep = '\t',index = False)
    print(labels.shape)

def dataset(histone,nums):
    global index_to_delete
    data.drop(index = index_to_delete, axis = 0,inplace = True)
    data.to_csv('dataset_{a}_{b}.txt'.format(a=histone, b=nums),sep = '\t',index = False)
   #os.system("sed -i '1d' 'dataset_{a}_{b}.txt'.format(a=histone, b=nums)")
def save(histone,nums):
    global one_hot_matrix
    np.save('onehot_{a}_{b}'.format(a=histone, b=nums),one_hot_matrix)
    one = np.load('onehot_{a}_{b}.npy'.format(a=histone, b=nums),allow_pickle=True)
    print(one.shape)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="data choice out")
    parser.add_argument("-i", "--dataset", metavar="", required=True, help="dataset")
    parser.add_argument("-c", "--choice", metavar="", required=True,default='make', help="make or check")
    parser.add_argument("-m", "--histone", metavar="" , help="hitone modifications")
    parser.add_argument("-n", "--nums", metavar="", help="number of samples")
    args = parser.parse_args()
    # 读取数据集
    data = pd.read_csv('%s'%(args.dataset) ,sep = '\t',header = None)
    # 编码
 
    one_hot_matrix = encoder(data)
    
    if args.choice == 'check':
        index_to_delete = delete(one_hot_matrix)
        dataset(args.histone, args.nums)
    elif args.choice == 'make':
        labels_marker(args.histone, args.nums)
        save(args.histone, args.nums)
    else:
        print('There is no choice')


```

**OneHotEncoder3.0**

1.输出npz文件包含['keys', 'DNAseq', 'labels']  --make save() ,保证三者的shape，并且能够输出检查

2.labels的onehot 编码函数，按照数字进行onehot编码

3.导入target文件，并且将keys和labels分开

4.np.delete(labels,0,2)删除标签onehot第一列（0）

```python
# coding: utf-8

import numpy as np
import pandas as pd
import torch
import os
import sys
import argparse
from collections import defaultdict

# function to convert a DNA sequence string to a numpy array
# converts to lower case, changes any non 'acgt' characters to 'n'
import re
def string_to_array(my_string):
    my_string = my_string.lower()
    my_string = re.sub('[^acgt]', 'z', my_string)
    my_array = np.array(list(my_string))
    return my_array

# create a label encoder with 'acgtn' alphabet
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
label_encoder.fit(np.array(['a','c','g','t','z']))




# function to one-hot encode a DNA sequence string
# non 'acgt' bases (n) are 0000
# returns a L x 4 numpy array
from sklearn.preprocessing import OneHotEncoder
def one_hot_encoder(my_array):
    integer_encoded = label_encoder.transform(my_array)
    onehot_encoder = OneHotEncoder(sparse=False, dtype=int)
    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)
    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)
    return onehot_encoded

def dense_to_one_hot(labels_dense, num_classes):
    """Convert class labels from scalars to one-hot vectors."""
    num_labels = labels_dense.shape[0]
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset+labels_dense.ravel()] = 1
    return labels_one_hot


global one_hot_matrix
global index_to_delete
one_hot_matrix = []
index_to_delete = []
 
def encoder(data):
    one_hot_matrix = []
    for i in range(len(data)):
        one_hot_matrix.append(one_hot_encoder(string_to_array(data[0][i])))
    
    return one_hot_matrix

def delete(one_hot_matrix):
    
    for i in range(len(data)):
        if one_hot_matrix[i].shape != (500,4):
            index_to_delete.append(i)
    #one_hot_matrix = [one_hot_matrix[i] for i in range(0, len(one_hot_matrix),1) if i not in index_to_delete]
    return index_to_delete
def labels_marker():
    
    #labels = data.iloc[:len(data),1]
    labels_dense = np.array(data[2].tolist())
    num_classes = 6
    labels = dense_to_one_hot(labels_dense, num_classes)
    labels = labels.reshape(len(data), 1,6)
    labels = np.delete(labels,0,2)  
    return labels
    
    #labels.drop(index = index_to_delete, axis = 0, inplace = True)
    #labels.to_csv('labels_{a}_{b}.txt'.format(a=histone, b=nums),sep = '\t',index = False)
    #print(labels.shape)

def dataset():
    global index_to_delete
    data.drop(index = index_to_delete, axis = 0,inplace = True)
    data.to_csv('dataset_rice_all.txt',sep = '\t',index = False)

    dataset = open('dataset_rice_all.txt').readlines()
    dataset[1] = ''
    with open('dataset_rice_all.txt','w') as f:
        f.writelines(dataset)

    #os.system("sed -i '1d' 'dataset_{a}_{b}.txt'.format(a=histone, b=nums)")

def save(labels):
    global one_hot_matrix
    one_hot_matrix = np.array(one_hot_matrix)
    print(one_hot_matrix.shape)
    one_hot_matrix = one_hot_matrix.reshape(len(data),1,4,500)
    keys = np.array(data[1].tolist())
    np.savez('./onehot_rice.npz',keys = keys, DNAseq = one_hot_matrix, labels = labels)
    with np.load('onehot_rice.npz') as f:
        indexs = f['keys']
        dna = f['DNAseq']
        labels = f['labels']
    print(indexs.shape, dna.shape, labels.shape)
    
	
    #one = np.load('onehot_{a}_{b}.npy'.format(a=histone, b=nums),allow_pickle=True)
    #print(one.shape)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="data choice out")
    parser.add_argument("-i", "--dataset", metavar="", required=True, help="dataset")
    parser.add_argument("-c", "--choice", metavar="", required=True,default='make', help="make or check")
  
    args = parser.parse_args()
    # 读取数据集
    data = pd.read_csv('%s'%(args.dataset) ,sep = '\t',header = None)
    # 编码
 
    one_hot_matrix = encoder(data)
    
    if args.choice == 'check':
        index_to_delete = delete(one_hot_matrix)
        dataset()
    elif args.choice == 'make':
        labels = labels_marker()
        save(labels)
    else:
        print('There is no choice')



```



### 生成数据集总流程（bash脚本）

rice/scripts/sh_scripts

id_geno

```txt
C019
C051
C135
C139
C145
C146
C147
C148
C151
W081
W105
W125
W128
W161
W169
W257
W261
W286
W294
W306
```

id_sp

```
C019
C051
C135
C139
ZS97
Nip
MH63
C148
C151
W081
W105
W125
W128
W161
W169
W257
W261
W286
W294
W306
```



##### 生成品种基因型

```bash
#!/bin/bash
#生成品种基因型，参考基因组日本晴第七版
for i in $(cat id_geno)
do
    bsub -q high -e ${i}.err -o ${i}.out "python3 scripts/py_scripts/geno_sub2.0.py -s data/vcf/sort.total.vcf -n ${i} -r data/ref/IRGSP-1.0_genome.fasta -l 500"
done
```

##### samtools

```bash
#!/bin/bash
#使用samtools对基因型进行注释
for i in $(cat id_geno)
    do
    samtools faidx ${i}.fasta
done
```

```bash
#!/bin/bash
#将原始基因型的名字改为品种名
for i in $(cat id_geno)
   do
   if ${i}.fasta.fai == C145.fasta.fai
       do
       mv ${i}.fasta.fai ZS97.fasta.fai
   elif ${i}.fasta.fai == C146.fasta.fai
       do 
       mv ${i}.fasta.fai Nip.fasta.fai
   elif ${i}.fasta.fai == C147.fasta.fai
       do 
       mv ${i}.fasta.fai MH63.fasta.fai
done
```



##### 提取peak范围

```bash
#!/bin/bash
for n in $(cat histone)
do
    for i in $(cat id_sp)
    do
      awk '{print $1,$2,$3}' mapto*/${n}_seedlings/*${i}_peaks.*Peak | sort -t ' ' -k1.4nr | sort -k1,1V -k2,2n -k3,3n > data/signal_area/sort_${i}_${n}.bed
      done
done
```



##### 生成组蛋白修饰标签

```bash
#!/bin/bash
for n in $(cat histone)
do
    for i in $(cat id_sp)
    do
    python3 scripts/py_scripts/target_mark5.0.py -f data/sequence/${i}.fasta.fai -b data/signal_area/sort_${i}_${n}.bed -o target_${i}_${n}_2.bed -s ${i} -m ${n} && paste data/seq/${i}_2.fasta target_${i}_${n}_2.bed |  awk '$3 != 0 {print}'  >> dataset_rice_raw.csv | awk '{print $3}' | uniq -c
    done
done
```

data/seq文件夹中无">"

##### 数据预处理(check)

```bash
bsub -q high -e check.err -o check.out 'python3 scripts/py_scripts/OneHotEncoder3.0.py -i dataset_rice_raw -c check'
awk '{print $1,$3}' 
sed -i '/N/d' 
awk '$2 == 2 {print}' ../dataset_all_90w.txt | awk -v OFS="\t" '{if ($2 != 0) $3 = 1}1' >> H3K27ac.txt
bsub -q high 'shuf -n243105 dataset_0.txt >> H3K4me3.txt'
```



##### 编码onehot

```shell
bsub -q high -e make.err -o make.out 'python3 OneHotEncoder3.0.py -i dataset_rice_all -c make'
```



#####  生成Transformer数据集

提取$1和$3，然后与等数量的阴性样本连接

```python
awk '{print $1,$3}' dataset_rice_all.txt > dataser_trans.txt
```

