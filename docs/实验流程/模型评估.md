## 模型评估



#### 评估指标

AUC

auPRC

MCC

Specificity

Sensitivity

#### 过拟合问题

https://blog.csdn.net/huangfei711/article/details/79436698

1. **获取和使用更多的数据集**

  对于解决过拟合的办法就是给与足够多的数据集，让模型在更可能多的数据上进行“观察”和拟合，从而不断修正自己。然而事实上，收集无限多的数据集几乎是不可能的，因此一个常用的办法就是调整已有的数据，添加大量的“噪音”，或者对图像进行锐化、旋转、明暗度调整等优化。

2. **采用合适的模型**
   目前来说，针对不同的情况和分类要求，对使用的模型也是千差万别。过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律“deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越     多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。因此对于模型的设计需要合理参考各种模型的取舍。

​        

3. **使用 Dropout**
   Dropout 是一个非常有用和常用的方法。Dropout 指的是在训练过程中每次按一定的几率关闭或忽略某些层的节点。使得模型在使用同样的数据进行训练时相当于从不同的模型中随机选择一个进行训练至于 Dropout 起作用的原因，可以简单理解成在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果， 随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。



4. **正则化**
   正则化又称为权重衰减，具体做法是将权值的大小加入到损失函数中，在实际使用中分为 L1 正则与 L2 正则。关于正则化能够防止过拟合的原因

  

5. **Early Stopping**
   Early Stopping 是参数微调中的一种，即在每个循环结束一次以后（这里的循环可能是 full data batch,也可能是 mini batch size），计算模型的准确率（accuracy）。当准确率不再增加时就停止训练。这是一种非常简单和自然的办法，准确率不再增加时就停止训练，防止模型对已有的数据继续训练。但是问题在于，准确率在每个循环之后的计算是变化的，没有任何人和任何模型能保证准确率不会变化，可能某次循环结束后，准确率很高，但是下一轮结束后准确率又降得很低

​       人为地设定一个范围。当连续10次准确率在此范围内波动时就停止循环。



6. **可变化的学习率**
   可变化的学习率也是根据模型计算出的准确率进行调整。一个简单的方法是在人为设定的准确率范围内，达到10次范围内的波动后，依次将学习率减半，直到最终的学习率降为原始的 1/1024 时停止模型的训练。
7. **使用 Batch_Normalization**
   还有一个数据处理的方法 Batch_Normalization，即数据在经过卷积层之后，真正进入激活函数之前需要对其进行一次 Batch_Normalization，分批对输入的数据求取均值和方差之后重新对数据进行归一化计算。这样做的好处就是对数据进行一定程度的预处理，使得无论是训练集还是测试集都在一定范围内进行分布和波动，对数据点中包含的误差进行掩盖化处理，从而增大模型的泛化能力。

参考：http://www.ai-start.com/dl2017/   吴恩达深度学习

**学习曲线**

AUC

偏差/方差

高偏差—欠拟合

高方差—过拟合

Train set error /Dev set error

**正则化**

使神经网络在保持原有深度的同时，每一层的隐藏单元产生的影响更小，防止过拟合

https://blog.csdn.net/guyuealian/article/details/88426648

L2正则化：

||w||是欧几里得范数，平方等于所有w的平方和

神经网络中的L2正则化：平方范数被定义为所有元素的平方和

弗罗贝尼乌斯范数：矩阵范数，

L2范数正则化，也被称为权重衰减，因为在进行backprop时，增加权重项会使原本的梯度下降更多

直观上理解就是如果正则化设置得足够大，权重矩阵被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。

Dropout正则化 （随机失活）

**dropout**会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用**backprop**方法进行训练。

不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，**dropout**将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施**dropout**的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；对不同权重的衰减是不同的，它取决于激活函数倍增的大小。

inverted dropout反向随机失活

可以改变Dropout层的参数Dropout（keep—prob）

归一化

**权重初始化**



**超参数调试**

贝叶斯优化（BayesianOptimization）

https://www.cnblogs.com/yangruiGB2312/p/9374377.html

optuna

https://tigeraus.gitee.io/doc-optuna-chinese-build/



**ROC曲线绘制**



**ROC曲线和AUC**

https://blog.csdn.net/pipisorry/article/details/51788927

AUC(auROC)

AUC 的全称是 `AreaUnderRoc` 即 Roc 曲线与坐标轴形成的面积，取值范围 [0, 1].分别随机从正负样本集中抽取一个正样本，一个负样本，正样本的预测值大于负样本的概率。

![img](https://pic1.zhimg.com/80/v2-33abc4c7d3ba5146701f60bea40ebc58_720w.jpg)

Roc (Receiver operating characteristic) 曲线是一种二元分类模型分类效果的分析工具，每个点反应这对同一信号刺激的感受性

- 纵轴**TPR**（true positive rate）真正例率: 灵敏度（Sensitivity）在所有实际为阳性的样本中，被正确地判断为阳性之比率 `TPR = TP/P = TP/(TP+FN)`
- 纵轴**FPR**（false positive rate）: 在所有实际为阴性的样本中，被错误地判定为阳性之比率 `FPR = FP/N = FP/(FP+TN)`

给定一个二元分类模型和它的阈值，就能从所有样本的（阳性／阴性）真实值和预测值计算出一个 (X=FPR, Y=TPR) 座标点



针对一个二分类问题，将实例分成正类(postive)或者负类(negative)。但是实际中分类时，会出现四种情况.

(1)若一个实例是正类并且被预测为正类，即为真正类(True Postive TP)

(2)若一个实例是正类，但是被预测成为负类，即为假负类(False Negative FN)

(3)若一个实例是负类，但是被预测成为正类，即为假正类(False Postive FP)

(4)若一个实例是负类，但是被预测成为负类，即为真负类(True Negative TN)

TP:正确的肯定数目

FN:漏报，没有找到正确匹配的数目

FP:误报，没有的匹配不正确

TN:正确拒绝的非匹配数目

列联表如下，1代表正类，0代表负类：

![img](http://images.cnitblog.com/blog2015/712297/201504/081953479158732.jpg)

由上表可得出横，纵轴的计算公式：

(1)真正类率(True Postive Rate)TPR: TP/(TP+FN),代表分类器预测的正类中实际正实例占所有正实例的比例。Sensitivity

(2)负正类率(False Postive Rate)FPR: FP/(FP+TN)，代表分类器预测的正类中实际负实例占所有负实例的比例。1-Specificity

(3)真负类率(True Negative Rate)TNR: TN/(FP+TN),代表分类器预测的负类中实际负实例占所有负实例的比例，TNR=1-FPR。Specificity


```python
torch.save(net.state_dict(), 'params.pkl')

test_data = TensorDataset(data_tensor[150000:151000], target_tensor[150000:151000])
test_dataloader = data.DataLoader(test_data,batch_size = 1000,
                        shuffle=True,num_workers=0)
y_label = []
y_pre = []
  
def predict(data_iter, net, device=None):
    net.load_state_dict(torch.load('params.pkl'))
    if device is None and isinstance(net, torch.nn.Module):
        device = list(net.parameters())[0].device
    acc_sum, n = 0.0, 0
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(net, torch.nn.Module):
                net.eval() # 评估模式, 这会关闭dropout
                acc_sum += (net(X.to(device)).argmax(dim=1) == (y.to(device).squeeze())).float().sum().cpu().item()
                y_label = y.cpu().numpy().tolist()
          
                y_pre = net(X.to(device))[:,1].cpu().numpy().tolist()
         

        fpr, tpr, thersholds = roc_curve(y_label, y_pre, pos_label=1)
 
        for i, value in enumerate(thersholds):
            print("%f %f %f" % (fpr[i], tpr[i], value))

        roc_auc = auc(fpr, tpr)
 
        plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)
 
        plt.xlim([-0.05, 1.05])  # 设置x、y轴的上下限，以免和边缘重合，更好的观察图像的整体
        plt.ylim([-0.05, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')  # 可以使用中文，但需要导入一些库即字体
        plt.title('ROC Curve')
        plt.legend(loc="lower right")
        plt.show()

predict(test_dataloader, net, device=None)
```





















