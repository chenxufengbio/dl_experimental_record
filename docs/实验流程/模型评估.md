# 模型评估



## 评估指标

**参考资料：**

[Python sklearn机器学习各种评价指标——Sklearn.metrics简介及应用示例](https://blog.csdn.net/Yqq19950707/article/details/90169913)

- ##### **Metrics（混淆矩阵）**

给定一个二元分类模型和它的阈值，就能从所有样本的（阳性／阴性）真实值和预测值计算出一个 (X=FPR, Y=TPR) 座标点



针对一个二分类问题，将实例分成正类(postive)或者负类(negative)。但是实际中分类时，会出现四种情况.

(1)若一个实例是正类并且被预测为正类，即为真正类(True Postive TP)

(2)若一个实例是正类，但是被预测成为负类，即为假负类(False Negative FN)

(3)若一个实例是负类，但是被预测成为正类，即为假正类(False Postive FP)

(4)若一个实例是负类，但是被预测成为负类，即为真负类(True Negative TN)

TP:正确的肯定数目

FN:漏报，没有找到正确匹配的数目

FP:误报，没有的匹配不正确

TN:正确拒绝的非匹配数目

列联表如下，1代表正类，0代表负类：

![img](http://images.cnitblog.com/blog2015/712297/201504/081953479158732.jpg)

由上表可得出横，纵轴的计算公式：

(1)真正类率(True Postive Rate)TPR: TP/(TP+FN),代表分类器预测的正类中实际正实例占所有正实例的比例。Sensitivity

(2)负正类率(False Postive Rate)FPR: FP/(FP+TN)，代表分类器预测的正类中实际负实例占所有负实例的比例。1-Specificity

(3)真负类率(True Negative Rate)TNR: TN/(FP+TN),代表分类器预测的负类中实际负实例占所有负实例的比例，TNR=1-FPR。Specificity

- ##### **AUC**

AUC（Area Under Curve）被定义为ROC曲线)下与坐标轴围成的面积，取值范围[0,1],分别随机从正负样本集中抽取一个正样本，一个负样本，正样本的预测值大于负样本的概率。



![img](https://pic1.zhimg.com/80/v2-33abc4c7d3ba5146701f60bea40ebc58_720w.jpg)

Roc (Receiver operating characteristic) 曲线是一种二元分类模型分类效果的分析工具，每个点反应这对同一信号刺激的感受性

- 纵轴**TPR**（true positive rate）真正例率: 灵敏度（Sensitivity）在所有实际为阳性的样本中，被正确地判断为阳性之比率 `TPR = TP/P = TP/(TP+FN)`
- 纵轴**FPR**（false positive rate）: 在所有实际为阴性的样本中，被错误地判定为阳性之比率 `FPR = FP/N = FP/(FP+TN)`



![img](http://images.cnitblog.com/blog2015/712297/201504/081954327748728.jpg)

- ##### **auPRC**

PRC(Precision Recall Curve,准确召回率曲线)，相关性评价：

数据库里有500条记录，其中50个是相关的（正样本），你通过一个检索，返回了75个你认为相关，其中只有45个是真正相关的；那么在这个检索对应下的：

**recall=45/50=0.9【横坐标】**

**precision=45/75=0.6【纵坐标】（这两个数比值都是在0到1置内的）**

**结论： 在negative instances的数量远远大于positive instances的data set里， PRC更能有效衡量检测器的好坏。**

- ##### **MCC**

马修斯相关系数（Matthews correlation coefficient）

------

马修斯相关系数是在使用机器学习作为二进制（2类）的质量的度量的分类，通过布赖恩W.马修斯在1975年由生物化学引入

它考虑到真和假阳性和假阴性，并且通常是被视为一种平衡的措施，即使这些类别的规模大小不同也可以使用。
MC实质上是观察到的类别和预测的二元分类之间的相关系数; 它返回介于-1和+1之间的值。系数+1表示完美预测，0表示不比随机预测好，-1表示预测和观察之间的完全不一致。统计数据也称为phi系数。MCC与2×2 列联表的卡方统计量相关
![|MCC|=\sqrt{\frac{\chi _2}{n}}](https://private.codecogs.com/gif.latex?%7CMCC%7C%3D%5Csqrt%7B%5Cfrac%7B%5Cchi%20_2%7D%7Bn%7D%7D)
其中n是观察总数。虽然没有完美的方法用一个数字来描述真假阳性和阴性的混淆矩阵，但马修斯相关系数通常被认为是最好的这种测量之一。
当两个类别具有非常不同的大小时，其它度量（例如正确预测的比例（也称为准确性））无用。例如，将每个对象分配给较大的集合可以实现高比例的正确预测，但通常不是有用的分类。可以使用以下公式直接从混淆矩阵计算MCC ：
![MCC=\frac{TP*TN-FP*FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}](https://private.codecogs.com/gif.latex?MCC%3D%5Cfrac%7BTP*TN-FP*FN%7D%7B%5Csqrt%7B%28TP&plus;FP%29%28TP&plus;FN%29%28TN&plus;FP%29%28TN&plus;FN%29%7D%7D)
在这个公式中，TP是真阳性数量，TN的真阴性数量，FP的假阳性数量和FN的假阴性数量。如果分母中的四个和中的任何一个为零，则分母可以任意设置为1; 这导致Matthews相关系数为零，这可以显示为正确的限制值。
马修斯给出的原始公式是：
![N=TN+TP+FN+FP](https://private.codecogs.com/gif.latex?N%3DTN&plus;TP&plus;FN&plus;FP)

![S=\frac{TP+FN}{N}](https://private.codecogs.com/gif.latex?S%3D%5Cfrac%7BTP&plus;FN%7D%7BN%7D)

![P=\frac{TP+FP}{N}](https://private.codecogs.com/gif.latex?P%3D%5Cfrac%7BTP&plus;FP%7D%7BN%7D)

![MCC=\frac{TP/N-S*P}{\sqrt{PS(1-S)(1-P)}}](https://private.codecogs.com/gif.latex?MCC%3D%5Cfrac%7BTP/N-S*P%7D%7B%5Csqrt%7BPS%281-S%29%281-P%29%7D%7D)
这等于上面给出的公式。
作为相关系数，
马修斯相关系数是问题及其对偶的回归系数的几何平均数。
Matthews相关系数的分量回归系数是Markedness（Δp）和Youden的J统计量（Informedness或Δp’）。
标记和知情对应于不同的信息流方向，并推广了Youden的J统计量， {\ displaystyle \ delta}p统计和（作为它们的几何平均值）马修斯相关系数超过两个类。
一些科学家声称，马修斯相关系数是在混淆矩阵环境中建立二元分类器预测质量的最具信息性的单一分数





## 过拟合问题

**学习曲线**

偏差/方差

高偏差—欠拟合

高方差—过拟合

Train set error /Dev set error

**参考资料：**

http://www.ai-start.com/dl2017/   吴恩达深度学习

https://blog.csdn.net/huangfei711/article/details/79436698

1. **获取和使用更多的数据集**

  对于解决过拟合的办法就是给与足够多的数据集，让模型在更可能多的数据上进行“观察”和拟合，从而不断修正自己。然而事实上，收集无限多的数据集几乎是不  可能的，因此一个常用的办法就是调整已有的数据，添加大量的“噪音”，或者对图像进行锐化、旋转、明暗度调整等优化。



2. **采用合适的模型**
   目前来说，针对不同的情况和分类要求，对使用的模型也是千差万别。过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律“deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越     多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。因此对于模型的设计需要合理参考各种模型的取舍。

​        

3. **使用 Dropout**
   Dropout 是一个非常有用和常用的方法。Dropout 指的是在训练过程中每次按一定的几率关闭或忽略某些层的节点。使得模型在使用同样的数据进行训练时相当于从不同的模型中随机选择一个进行训练至于 Dropout 起作用的原因，可以简单理解成在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果， 随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。



4. **正则化**
   正则化又称为权重衰减，具体做法是将权值的大小加入到损失函数中，在实际使用中分为 L1 正则与 L2 正则。关于正则化能够防止过拟合的原因

>  正则化 使神经网络在保持原有深度的同时，每一层的隐藏单元产生的影响更小，防止过拟合
>
> https://blog.csdn.net/guyuealian/article/details/88426648
>
> **L2正则化：**
>
> ||w||是欧几里得范数，平方等于所有w的平方和
>
> 神经网络中的L2正则化：平方范数被定义为所有元素的平方和
>
> 弗罗贝尼乌斯范数：矩阵范数，
>
> L2范数正则化，也被称为权重衰减，因为在进行backprop时，增加权重项会使原本的梯度下降更多
>
> 直观上理解就是如果正则化设置得足够大，权重矩阵被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。
>
> **Dropout正则化 （随机失活）**
>
> **dropout**会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用**backprop**方法进行训练。
>
> 不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，**dropout**将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施**dropout**的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；对不同权重的衰减是不同的，它取决于激活函数倍增的大小。
>
> inverted dropout反向随机失活
>
> 可以改变Dropout层的参数Dropout（keep—prob）



5. **Early Stopping**
   Early Stopping 是参数微调中的一种，即在每个循环结束一次以后（这里的循环可能是 full data batch,也可能是 mini batch size），计算模型的准确率（accuracy）。当准确率不再增加时就停止训练。这是一种非常简单和自然的办法，准确率不再增加时就停止训练，防止模型对已有的数据继续训练。但是问题在于，准确率在每个循环之后的计算是变化的，没有任何人和任何模型能保证准确率不会变化，可能某次循环结束后，准确率很高，但是下一轮结束后准确率又降得很低

​       人为地设定一个范围。当连续10次准确率在此范围内波动时就停止循环。



6. **可变化的学习率**
   可变化的学习率也是根据模型计算出的准确率进行调整。一个简单的方法是在人为设定的准确率范围内，达到10次范围内的波动后，依次将学习率减半，直到最终的学习率降为原始的 1/1024 时停止模型的训练。



6. **使用 Batch_Normalization**
   还有一个数据处理的方法 Batch_Normalization，即数据在经过卷积层之后，真正进入激活函数之前需要对其进行一次 Batch_Normalization，分批对输入的数据求取均值和方差之后重新对数据进行归一化计算。这样做的好处就是对数据进行一定程度的预处理，使得无论是训练集还是测试集都在一定范围内进行分布和波动，对数据点中包含的误差进行掩盖化处理，从而增大模型的泛化能力。



#### 超参数调试

贝叶斯优化（BayesianOptimization）

https://www.cnblogs.com/yangruiGB2312/p/9374377.html

optuna

https://tigeraus.gitee.io/doc-optuna-chinese-build/



## ROC曲线绘制

**ROC曲线和AUC**

https://blog.csdn.net/pipisorry/article/details/51788927




```python
torch.save(net.state_dict(), 'params.pkl')

test_data = TensorDataset(data_tensor[150000:151000], target_tensor[150000:151000])
test_dataloader = data.DataLoader(test_data,batch_size = 1000,
                        shuffle=True,num_workers=0)
y_label = []
y_pre = []
  
def predict(data_iter, net, device=None):
    net.load_state_dict(torch.load('params.pkl'))
    if device is None and isinstance(net, torch.nn.Module):
        device = list(net.parameters())[0].device
    acc_sum, n = 0.0, 0
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(net, torch.nn.Module):
                net.eval() # 评估模式, 这会关闭dropout
                acc_sum += (net(X.to(device)).argmax(dim=1) == (y.to(device).squeeze())).float().sum().cpu().item()
                y_label = y.cpu().numpy().tolist()
          
                y_pre = net(X.to(device))[:,1].cpu().numpy().tolist()
         

        fpr, tpr, thersholds = roc_curve(y_label, y_pre, pos_label=1)
 
        for i, value in enumerate(thersholds):
            print("%f %f %f" % (fpr[i], tpr[i], value))

        roc_auc = auc(fpr, tpr)
 
        plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)
 
        plt.xlim([-0.05, 1.05])  # 设置x、y轴的上下限，以免和边缘重合，更好的观察图像的整体
        plt.ylim([-0.05, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')  # 可以使用中文，但需要导入一些库即字体
        plt.title('ROC Curve')
        plt.legend(loc="lower right")
        plt.show()

predict(test_dataloader, net, device=None)
```



## 改良标签方法

计算每种组蛋白修饰peak的中位数，平均数

| histone modifications | mid  | average |
| --------------------- | ---- | ------- |
| H3K4me3（1）          | 880  | 950.52  |
| H3K27ac（2）          | 799  | 854.329 |
| H3K4me1（3）          | 2694 | 3446.12 |
| H3K27me3（4）         | 1586 | 3149.9  |
| H3K9me2（5）          | 2158 | 4094.97 |

| histone modifications | function                                                     |
| --------------------- | ------------------------------------------------------------ |
| H3K4me3（1）          | 取peak中央**250bp**作为标准，win在其中的比例占到**10%**则标记为阳性 |
| H3K27ac（2）          | 250                                                          |
| H3K4me1（3）          | 750                                                          |
| H3K27me3（4）         | 750                                                          |
| H3K9me2（5）          | 1000                                                         |

![image-20210406221649915](https://img.imgdb.cn/item/609292efd1a9ae528f485f8b.png)

> 将H3K4me3和H3K27ac按照同一种标签计算
>
> 将H3K4me1和H3K9me2按照同一种标签计算

