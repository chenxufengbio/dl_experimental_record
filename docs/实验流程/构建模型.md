## 构建模型

[TOC]

### **构建基本模型（pytorch）**

初步实验在恒源云服务器上进行

#### 导入模块

```python
import numpy as np
import pandas as pd
import torch
from torch.utils import data
import time
from torch import nn, optim
import sys
```

#### 设置GPU

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

#### 数据导入及格式转换

```python
data_np = np.load('./one_hot.npy')
target_pd =pd.read_csv('./target6.txt',sep = '\n')
#转换成tensor
data_tensor = torch.from_numpy(data_np)
target_array = np.array(target_pd)
target_tensor = torch.tensor(target_array)
#转置成(4，500)
data_tensor = data_tensor.reshape(10000,4,500)
#转换成float（后续模型输入需要）
data_tensor = data_tensor.float()
target_tenor = target_tensor.float()
```

#### 构建训练集和验证集（TensorDataset类和DataLoader类）

```python
class TensorDataset(data.Dataset):
    """Dataset wrapping data and target tensors.
    Each sample will be retrieved by indexing both tensors along the first
    dimension.
    Arguments:
        data_tensor (Tensor): contains sample data.
        target_tensor (Tensor): contains sample targets (labels).
    """

    def __init__(self, data_tensor, target_tensor):
        assert data_tensor.size(0) == target_tensor.size(0)
        self.data_tensor = data_tensor
        self.target_tensor = target_tensor

    def __getitem__(self, index):
        return self.data_tensor[index], self.target_tensor[index]

    def __len__(self):
        return len(self.data_tensor)
  
```

```python
train_data = TensorDataset(data_tensor[0:9000], target_tensor[0:9000])
val_data = TensorDataset(data_tensor[9000:10000], target_tensor[9000:10000])
train_dataloader = data.DataLoader(train_data,batch_size = 200,
                        shuffle=True,num_workers=0)
val_dataloader = data.DataLoader(val_data,batch_size = 200,
                        shuffle=False,num_workers=0)
```



### **DeepSEA**

为防止过拟合增大泛化能力，在卷积层后加入BN层（归一化）

```python
class DeepSEA(nn.Module):
    def __init__(self, sequence_length=500, n_genomic_features=2):
        """
        Parameters
        ----------
        sequence_length : int
        n_genomic_features : int
        """
        super(DeepSEA, self).__init__()
        conv_kernel_size = 8
        pool_kernel_size = 4

        self.conv_net = nn.Sequential(
            nn.Conv1d(4, 320, kernel_size=conv_kernel_size),
            nn.BatchNorm1d(320),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=0.2),

            nn.Conv1d(320, 480, kernel_size=conv_kernel_size),
            nn.BatchNorm1d(480),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=0.2),

            nn.Conv1d(480, 960, kernel_size=conv_kernel_size),
            nn.BatchNorm1d(960),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5))

        reduce_by = conv_kernel_size - 1
       
        self.n_channels = int(
            np.floor(
                (np.floor(
                    (sequence_length - reduce_by) / pool_kernel_size)
                 - reduce_by) / pool_kernel_size)
            - reduce_by)
        self.classifier = nn.Sequential(
            nn.Linear(960 * self.n_channels, n_genomic_features),
            nn.ReLU(inplace=True),
            nn.Linear(n_genomic_features, n_genomic_features),
            nn.Sigmoid())

    def forward(self, x):
        """Forward propagation of a batch.
        """
        out = self.conv_net(x)
        reshape_out = out.view(out.size(0), 960 * self.n_channels)
        predict = self.classifier(reshape_out)
        return predict
```

**创建训练函数**

损失函数：CrossEntropyLoss

```python
def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):
    net = net.to(device)
    print("training on ", device)
    loss = torch.nn.CrossEntropyLoss()
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()
        for X, y in train_iter:
            X = X.to(device)
            y = y.to(device)
            y_hat = net(X)
            y = y.squeeze()
            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.cpu().item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()
            n += y.shape[0]
            batch_count += 1
        test_acc = evaluate_accuracy(test_iter, net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'
              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))
```

**创建准确率计算函数**

```python
def evaluate_accuracy(data_iter, net, device=None):
    if device is None and isinstance(net, torch.nn.Module):
        device = list(net.parameters())[0].device
    acc_sum, n = 0.0, 0
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(net, torch.nn.Module):
                net.eval() # 评估模式, 这会关闭dropout
                acc_sum += (net(X.to(device)).argmax(dim=1)==y.to(device).squeeze()).float().sum().cpu().item()
                net.train() # 改回训练模式
            else: 
                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数
                    # 将is_training设置成False
                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() 
                else:
                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() 
            n += y.shape[0]
    return acc_sum / n

```

**开启训练**

| 超参数     |          |
| ---------- | -------- |
| lr         | 学习率   |
| num_epochs | 训练批次 |

优化器：Adam

优化器：SGD

```python
lr, num_epochs = 0.001, 10
optimizer = torch.optim.SGD(net.parameters(), lr=lr)
train(net, train_dataloader, val_dataloader, 256, optimizer, device, num_epochs)
```

**训练结果可视化**

更新train函数

恒源云

```python
logger.log_value('loss', train_l_sum/batch_count,  epoch*len(train_iter) + batch_count)
logger.log_value('train_acc', 100. *train_acc_sum / n, epoch*len(train_iter) + batch_count)
logger.log_value('val_acc',test_acc,epoch)
```

**TensorBoard_logger**

```python
from tensorboard_logger import Logger
logger = Logger(logdir="./tb_logs", flush_secs=10)#设置输出的log文件位置

def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):
    net = net.to(device)
    print("training on ", device)
    loss = torch.nn.CrossEntropyLoss()
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()
        for X, y in train_iter:
            X = X.to(device)
            y = y.to(device)
            y_hat = net(X)
            y = y.squeeze()
            
            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.cpu().item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()
            n += y.shape[0]
            batch_count += 1


        test_acc = evaluate_accuracy(test_iter, net)
        logger.log_value('loss', train_l_sum/batch_count,  epoch*len(train_iter) + batch_count)
        logger.log_value('train_acc', 100. *train_acc_sum / n, epoch*len(train_iter) + batch_count)
        logger.log_value('val_acc',test_acc,epoch)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'
              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))

```



#### **模型框架**

**文件组织架构**

```text
/public/home/xwli/xwzhang/deeplearningDATA/rice/pytorch_deepsea

├── checkpoints/
├── data/
│   ├── __init__.py
│   ├── dataset.py
│  
├── models/
│   ├── __init__.py
│   ├── DeepSEA.py
│   
│  
└── utils/
│   ├── __init__.py
│   └── visualize.py
├── config.py
├── main.py
├── README.md
```

**数据加载模块**

```python
#dataset.py
from torch.utils import data 

class TensorDataset(data.Dataset):
    """Dataset wrapping data and target tensors.
    Each sample will be retrieved by indexing both tensors along the first
    dimension.
    Arguments:
        data_tensor (Tensor): contains sample data.
        target_tensor (Tensor): contains sample targets (labels).
    """

    def __init__(self, data_tensor, target_tensor):
        assert data_tensor.size(0) == target_tensor.size(0)
        self.data_tensor = data_tensor
        self.target_tensor = target_tensor

    def __getitem__(self, index):
        return self.data_tensor[index], self.target_tensor[index]

    def __len__(self):
        return len(self.data_tensor) 
        

```

**模型定义模块**

```python
# coding: utf-8


import torch
import time


class BasicModule(torch.nn.Module):
    '''
    封装了nn.Module，主要提供save和load两个方法
    '''

    def __init__(self,opt=None):
        super(BasicModule,self).__init__()
        self.model_name = str(type(self)) # 模型的默认名字

    def load(self, path):
        '''
        可加载指定路径的模型
        '''
        self.load_state_dict(torch.load(path))

    def save(self, name=None):
        '''
        保存模型，默认使用“模型名字+时间”作为文件名，
        如AlexNet_0710_23:57:29.pth
        '''
        if name is None:
            prefix = 'checkpoints/' + self.model_name + '_'
            name = time.strftime(prefix + '%m%d_%H:%M:%S.pth')
        torch.save(self.state_dict(), name)
        return name


```

```python
#__init__.py
from .DeepSEA import DeepSEA
#from .new_module import NewModule
```

```python
# coding: utf-8

import numpy as np
from torch import nn
from .BasicModule import BasicModule

class DeepSEA(nn.Module):
    def __init__(self, sequence_length=500, n_genomic_features=2):
        """
        Parameters
        ----------
        sequence_length : int
        n_genomic_features : int
        """
        super(DeepSEA, self).__init__()
        conv_kernel_size = 8
        pool_kernel_size = 4

        self.conv_net = nn.Sequential(
            nn.Conv1d(4, 320, kernel_size=conv_kernel_size),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=0.2),

            nn.Conv1d(320, 480, kernel_size=conv_kernel_size),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=0.2),

            nn.Conv1d(480, 960, kernel_size=conv_kernel_size),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5))

        reduce_by = conv_kernel_size - 1

        self.n_channels = int(
            np.floor(
                (np.floor(
                    (sequence_length - reduce_by) / pool_kernel_size)
                 - reduce_by) / pool_kernel_size)
            - reduce_by)
        self.classifier = nn.Sequential(
            nn.Linear(960 * self.n_channels, n_genomic_features),
            nn.ReLU(inplace=True),
            nn.Linear(n_genomic_features, n_genomic_features),
            nn.Sigmoid()
        )

    def forward(self, x):
        """Forward propagation of a batch.
        """
        out = self.conv_net(x)
        reshape_out = out.view(out.size(0), 960 * self.n_channels)
        predict = self.classifier(reshape_out)
        return predict



```

**工具函数**

```python
#coding:utf8
#visualize.py
import visdom
import time
import numpy as np

class Visualizer(object):
    '''
    封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`
    或者`self.function`调用原生的visdom接口
    比如 
    self.text('hello visdom')
    self.histogram(t.randn(1000))
    self.line(t.arange(0, 10),t.arange(1, 11))
    '''

    def __init__(self, env='default', **kwargs):
        self.vis = visdom.Visdom(env=env, **kwargs)

       # 画的第几个数，相当于横坐标
       # 比如（’loss',23） 即loss的第23个点
        self.index = {}
        self.log_text = ''
    def reinit(self, env='default', **kwargs):
        '''
        修改visdom的配置
        '''
        self.vis = visdom.Visdom(env=env, **kwargs)
        return self

    def plot_many(self, d):
        '''
        一次plot多个
        @params d: dict (name, value) i.e. ('loss', 0.11)
        '''
        for k, v in d.iteritems():
            self.plot(k, v)

    def img_many(self, d):
        for k, v in d.iteritems():
            self.img(k, v)

    def plot(self, name, y, **kwargs):
        '''
        self.plot('loss', 1.00)
        '''
        x = self.index.get(name, 0)
        self.vis.line(Y=np.array([y]), X=np.array([x]),
                     win=unicode(name),
                     opts=dict(title=name),
                     update=None if x == 0 else 'append',
                     **kwargs
                     )
        self.index[name] = x + 1

    def img(self, name, img_, **kwargs):
        '''
        self.img('input_img', t.Tensor(64, 64))
        self.img('input_imgs', t.Tensor(3, 64, 64))
        self.img('input_imgs', t.Tensor(100, 1, 64, 64))
        self.img('input_imgs', t.Tensor(100, 3, 64, 64), nrows=10)
        '''
        self.vis.images(img_.cpu().numpy(),
                      win=unicode(name),
                      opts=dict(title=name),
                      **kwargs
                      )

    def log(self, info, win='log_text'):
        '''
        self.log({'loss':1, 'lr':0.0001})
        '''

        self.log_text += ('[{time}] {info} <br>'.format(
                           time=time.strftime('%m%d_%H%M%S'),\
                           info=info))
        self.vis.text(self.log_text, win)

    def __getattr__(self, name):
        '''
        self.function 等价于self.vis.function
        自定义的plot,image,log,plot_many等除外
        '''
        return getattr(self.vis, name)

                                                                      
```

**配置文件**

```python
#config.py
class DefaultConfig(object):
    env = 'default' # visdom 环境
    model = 'DeepSEA' # 使用的模型，名字必须与models/__init__.py中的名字一致

    train_data_root = './data/one_hot_10w_sh.npy' # 训练集存放路径
    test_data_root = './data/test1' # 测试集存放路径
    target_data_root = './data/target_10w_sh.txt'
    load_model_path = 'checkpoints/model.pth' # 加载预训练的模型的路径，为None代表不加载

    batch_size = 256 # batch size
    use_gpu = True # use GPU or not
    num_workers = 2 # how many workers for loading data
    print_freq = 20 # print info every N batch
    #debug_file = '/tmp/debug' # if os.path.exists(debug_file): enter ipdb
    result_file = 'result.csv'

    num_epochs = 10
    lr = 0.01 # initial learning rate
    lr_decay = 0.95 # when val_loss increase, lr = lr*lr_decay
    weight_decay = 1e-4 # 损失函数
def parse(self, kwargs):
        '''
        根据字典kwargs 更新 config参数
        '''
        # 更新配置参数
        for k, v in kwargs.items():
            '''
            if not hasattr(self, k):
                # 警告还是报错，取决于你个人的喜好
               
                warnings.warn("Warning: opt has not attribut %s" %k)
            '''
            setattr(self, k, v)

        # 打印配置信息  
        print('user config:')
        for k, v in self.__class__.__dict__.items():
            if not k.startswith('__'):
                print(k, getattr(self, k))

DefaultConfig.parse = parse
opt =DefaultConfig()
```

**主函数**

```python
#main.py
from config import opt
import os
import torch
from torch.utils import data
import models
import numpy as np
import pandas as pd
from data.dataset import TensorDataset
from torch.utils.data import DataLoader
#from torch.autograd import Variable
#from torchnet import meter
#from utils.visualize import Visualizer
#from tqdm import tqdm
import time




def evaluate_accuracy(data_iter, net, device=None):
    if device is None and isinstance(net, torch.nn.Module):
        # 如果没指定device就使用net的device
        device = list(net.parameters())[0].device
    acc_sum, n = 0.0, 0
    with torch.no_grad():
        for X, y in data_iter:
            '''
            if isinstance(net, torch.nn.Module):
                net.eval() # 评估模式, 这会关闭dropout
                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()
                net.train() # 改回训练模式
            else: 
                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数
                    # 将is_training设置成False
                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() 
                else:
                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()
            '''
            acc_sum += (net(X.to(device)).argmax(dim=1) == (y.to(device).squeeze())).float().sum().cpu().item()
            n += y.shape[0]

    return acc_sum / n



def train(**kwargs):
    opt.parse(kwargs)
    #vis = Visualizer(opt.env)

    model = getattr(models, opt.model)()

    '''
    if opt.load_model_path:
        model.load(opt.load_model_path)
    if opt.use_gpu: model.cuda()
    '''
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print("training on ", device)

    data_np = np.load(opt.train_data_root)
    data_tensor = torch.from_numpy(data_np)

    target_pd =pd.read_csv(opt.target_data_root,sep = '\n',header = None)
    target_array = np.array(target_pd)
    target_tensor = torch.tensor(target_array)

    data_tensor = data_tensor.reshape(100000,4,500)
    data_tensor = data_tensor.float()
    target_tenor = target_tensor.float()

    train_data = TensorDataset(data_tensor[0:99000], target_tensor[0:99000])
    val_data = TensorDataset(data_tensor[99000:100000], target_tensor[99000:100000])
    train_dataloader = data.DataLoader(train_data,batch_size = 200,
                        shuffle=True,num_workers=0)
    val_dataloader = data.DataLoader(val_data,batch_size = 200,
                        shuffle=False,num_workers=0)

    loss = torch.nn.CrossEntropyLoss()
    lr = opt.lr
    optimizer = torch.optim.SGD(model.parameters(),
                                lr=lr,
                                weight_decay = opt.weight_decay)




    for epoch in range(opt.num_epochs):
        model = model.to(device)
        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()
        for X, y in train_dataloader:
            X = X.to(device)
            y = y.to(device)
            y_hat = model(X)
            y = y.squeeze()
            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.cpu().item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()
            n += y.shape[0]
            batch_count += 1
        test_acc = evaluate_accuracy(val_dataloader, model)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'
              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))


        #model.save()

def val(model, dataloader):
    '''
    计算模型在验证集上的准确率等信息，用以辅助训练
    '''
    pass

def test(**kwargs):
    '''
    测试（inference）
    '''
    pass

def help():
    '''
    打印帮助的信息 
    '''
    print('help')

if __name__=='__main__':
    import fire
    fire.Fire()

```



### **DeepHistone**

**参考文献：**

[DeepHistone: a deep learning approach to predicting histone modification](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-5489-4)

github：https://github.com/QijinYin/DeepHistone.

#### **模型架构**

三个模块：DNA module ，DNase module， joint module

DNA and DNase module： **densely connected** convolutional neural network

joint module： distinguish histone modification sites of a marker from those of other markers

![Fig. 1](https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12864-019-5489-4/MediaObjects/12864_2019_5489_Fig1_HTML.png)



*图片来自参考文献*

#### DenseNet

<img src="https://pic2.zhimg.com/v2-c81da515c8fa9796601fde82e4d36f61_r.jpg" alt="preview" style="zoom:67%;" />

*图片来自参考文献*

利用前面所有层与后面层的“短路连接”来实现特征重用，具有更高的性能，更少的参数量

**参考文献**：

论文：[Densely Connected Convolutional Networks](https://ieeexplore.ieee.org/document/8099726)

模型详解：

https://blog.csdn.net/u014380165/article/details/75142664

https://zhuanlan.zhihu.com/p/37189203



#### 数据集格式改良

labels onehot encoder

可以将此函数加入OneHotEncoder

```python
import numpy as np
def dense_to_one_hot(labels_dense, num_classes):
    """Convert class labels from scalars to one-hot vectors."""
    num_labels = labels_dense.shape[0]
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset+labels_dense.ravel()] = 1
    return labels_one_hot

labels_dense = np.array([0,1,2,3,4]) 
num_classes  = 5
dense_to_one_hot(labels_dense,num_classes)
```

继续改进target_mark.py : 将组蛋白修饰（m）与数字标签对应，同时**改良每种组蛋白的标记方法**

npz封装：将npz封装也加入OneHotEncoder，加入到make

```python
np.savez('C:/Users/12394/PycharmProjects/Spyder/data.npz',a = a, b = b)
```

1.将5种组蛋白修饰阳性样本集中在一个数据集

2.reshape(len(data),1,4,500)

OneHotEncoder3.0.py完成

```shell
bsub -q high -e 12.err -o 12.out 'python3 scripts/py_scripts/OneHotEncoder3.0.py -i dataset_ex1_10w.txt -c make -m ex1 -n 10w' 
```

| Keys                          | DNA seq              | labels       |
| ----------------------------- | -------------------- | ------------ |
| (nums,)                       | (nums, 1 , 4 , 500 ) | (nums ,1, 5) |
| species_histone_chr_start_end | onehot               | onehot       |



#### **DNA-only**（DNA module）

```txt
/public/home/xwli/xwzhang/deeplearningDATA/rice/DeepHistone/

├── data/
├── results/
│   └── model.txt
│   └── label.txt
│   └── pred.txt
├── model_dna.py 
├── utils_dna.py
├── train_dna.py

    
```

**model_dna.py**

```python
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
from sklearn import metrics
from torch.optim import  Optimizer
import math 
from torch.nn.parameter import Parameter

class BasicBlock(nn.Module):
	def __init__(self, in_planes, grow_rate,):
		super(BasicBlock, self).__init__()
		self.block = nn.Sequential(
			nn.BatchNorm2d(in_planes),
			nn.ReLU(),
			nn.Conv2d(in_planes, grow_rate, (1,9), 1, (0,4)),
			#nn.Dropout2d(0.2)
		)
	def forward(self, x):
		out = self.block(x)
		return torch.cat([x, out],1)

class DenseBlock(nn.Module):
	def __init__(self, nb_layers, in_planes, grow_rate,):
		super(DenseBlock, self).__init__()
		layers = []
		for i in range(nb_layers):
			layers.append(BasicBlock(in_planes + i*grow_rate, grow_rate,))
		self.layer = nn.Sequential(*layers)
	def forward(self, x):
		return self.layer(x)


class ModuleDense(nn.Module):
	def __init__(self):
		super(ModuleDense, self).__init__()


		self.conv1 = nn.Sequential(
			nn.Conv2d(1,128,(4,9),1,(0,4)),
			#nn.Dropout2d(0.2),
			)
	
		self.block1 = DenseBlock(3, 128, 128)	
		self.trans1 = nn.Sequential(
			nn.BatchNorm2d(128+3*128),
			nn.ReLU(),
			nn.Conv2d(128+3*128, 256, (1,1),1),
			#nn.Dropout2d(0.2),
			nn.MaxPool2d((1,4)),
		)
		self.block2 = DenseBlock(3,256,256)
		self.trans2 = nn.Sequential(
			nn.BatchNorm2d(256+3*256),
			nn.ReLU(),
			nn.Conv2d(256+3*256, 512, (1,1),1),
			#nn.Dropout2d(0.2),
			nn.MaxPool2d((1,4)),
		)
		self.out_size = 500 // 4 // 4  * 512

	def forward(self, seq):
		n, h, w = seq.size()
		
		seq = seq.view(n,1,4,w)
	
		out = self.conv1(seq)
		out = self.block1(out)
		out = self.trans1(out)
		out = self.block2(out)
		out = self.trans2(out)
		n, c, h, w = out.size()
		out = out.view(n,c*h*w) 
		return out



class NetDeepHistone(nn.Module):
	def __init__(self):
		super(NetDeepHistone, self).__init__()
		print('DeepHistone(Dense) is used.')
		self.seq_map = ModuleDense()
		self.seq_len = self.seq_map.out_size
		seq_len = self.seq_len

		self.linear_map = nn.Sequential(
			nn.Dropout(0.5),
			nn.Linear(int(seq_len),925),
			nn.BatchNorm1d(925),
			nn.ReLU(),
			#nn.Dropout(0.1),
			nn.Linear(925,5),
			nn.Sigmoid(),
		)

	def forward(self, seq):
		flat_seq = self.seq_map(seq)	
		out = self.linear_map(flat_seq)
		return out


class DeepHistone():
	def __init__(self,use_gpu,learning_rate=0.001):
		self.forward_fn = NetDeepHistone()
		self.criterion  = nn.BCELoss()
		self.optimizer  = optim.Adam(self.forward_fn.parameters(), lr=learning_rate, weight_decay = 0)
		self.use_gpu    = use_gpu
		if self.use_gpu : self.criterion,self.forward_fn = self.criterion.cuda(), self.forward_fn.cuda()

	def updateLR(self, fold):
		for param_group in self.optimizer.param_groups:
			param_group['lr'] *= fold

	def train_on_batch(self,seq_batch,lab_batch,): 
		self.forward_fn.train()
		seq_batch  = Variable(torch.Tensor(seq_batch))
		lab_batch  = Variable(torch.Tensor(lab_batch))
		if self.use_gpu: seq_batch, lab_batch = seq_batch.cuda(), lab_batch.cuda()
		output = self.forward_fn(seq_batch)
		loss = self.criterion(output,lab_batch)
		self.optimizer.zero_grad()
		loss.backward()
		self.optimizer.step()
		return loss.cpu().data

	def eval_on_batch(self,seq_batch,lab_batch,):
		self.forward_fn.eval()
		seq_batch  = Variable(torch.Tensor(seq_batch))
		lab_batch  = Variable(torch.Tensor(lab_batch))
		if self.use_gpu: seq_batch,  lab_batch = seq_batch.cuda(), lab_batch.cuda()
		output = self.forward_fn(seq_batch)
		loss = self.criterion(output,lab_batch)
		return loss.cpu().data,output.cpu().data.numpy()
			
	def test_on_batch(self, seq_batch):
		self.forward_fn.eval()
		seq_batch  = Variable(torch.Tensor(seq_batch))
		if self.use_gpu: seq_batch = seq_batch.cuda()
		output = self.forward_fn(seq_batch)
		pred = output.cpu().data.numpy()
		return pred
	
	def save_model(self, path):
		torch.save(self.forward_fn.state_dict(), path)


	def load_model(self, path):
		self.forward_fn.load_state_dict(torch.load(path))

```

**untils_dna.py**

在原函数的基础上增加了MCC，Specificity和Sensitivity的计算函数，现在有三个具体评估指标

```python
from sklearn.metrics import auc,roc_auc_score,precision_recall_curve,matthews_corrcoef,precision_score,recall_score
import numpy as np
histones=['H3K4me3','H3K27ac','H3K4me1','H3K27me3','H3K9me2']

def loadRegions(regions_indexs,dna_dict,label_dict,):
    if dna_dict is not None:
        dna_regions = np.concatenate([dna_dict[meta]  for meta in regions_indexs],axis=0)
    else: dna_regions =[]

    label_regions = np.concatenate([label_dict[meta] for meta in regions_indexs],axis=0).astype(int)
    return dna_regions,label_regions

def model_train(regions,model,batchsize,dna_dict,label_dict,):
    train_loss = []
    regions_len = len(regions)
    for i in range(0, regions_len , batchsize):
        regions_batch = [regions[i+j] for j in range(batchsize) if (i+j) < regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _loss= model.train_on_batch(seq_batch, lab_batch)
        train_loss.append(_loss)
    return np.mean(train_loss) 

def model_eval(regions,model,batchsize,dna_dict,label_dict,):
    loss = []
    pred =[]
    lab =[]
    regions_len = len(regions)
    for i in range(0, regions_len , batchsize):
        regions_batch = [regions[i+j] for j in range(batchsize) if (i+j) < regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _loss,_pred = model.eval_on_batch(seq_batch, lab_batch)
        loss.append(_loss)
        lab.extend(lab_batch)
        pred.extend(_pred)
        ground_truths = np.eye(np.array(pred).shape[1])[np.array(pred).argmax(1)]
    return np.mean(loss), np.array(lab),np.array(pred),ground_truths

def model_predict(regions,model,batchsize,dna_dict,label_dict,):
    lab  = []
    pred = []
    regions_len = len(regions)
    for i in range(0, len(regions), batchsize):
        regions_batch = [regions[i+j] for j in range(batchsize) if (i+j) < regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _pred = model.test_on_batch(seq_batch)
        lab.extend(lab_batch)
        pred.extend(_pred)		
        ground_truths = np.eye(np.array(pred).shape[1])[np.array(pred).argmax(1)]
    return np.array(lab), np.array(pred) ,ground_truths


def ROC(label,pred):
    if len(np.unique(np.array(label).reshape(-1)))  == 1:
        print("all the labels are the same !")
        return 0
    else:
        label = np.array(label).reshape(-1)
        pred = np.array(pred).reshape(-1)
        return roc_auc_score(label,pred)
def auPR(label,pred):
    if len(np.unique(np.array(label).reshape(-1)))  == 1:
        print("all the labels are the same !")
        return 0
    else:
        label = np.array(label).reshape(-1)
        pred = np.array(pred).reshape(-1)
        precision, recall, thresholds = precision_recall_curve(label,pred)
        return auc(recall,precision)

def MCC(label,truths):
    if len(np.unique(np.array(label).reshape(-1)))  == 1:
        print("all the labels are the same !")
        return 0
    else:
        label = np.array(label).reshape(-1)
        truths = np.array(truths).reshape(-1)
        return matthews_corrcoef(label, truths)

def Spec(label,truths):
    if len(np.unique(np.array(label).reshape(-1)))  == 1:
        print("all the labels are the same !")
        return 0
    else:
        label = np.array(label).reshape(-1)
        truths = np.array(truths).reshape(-1)
        return precision_score(label, truths)

def Sen(label,truths):
    if len(np.unique(np.array(label).reshape(-1)))  == 1:
        print("all the labels are the same !")
        return 0
    else:
        label = np.array(label).reshape(-1)
        truths = np.array(truths).reshape(-1)
        return recall_score(label, truths)

def metrics(lab,pred,truths,Type='test',loss=None):
        if Type == 'Valid':
            training_color = '\033[0;34m'
        elif Type == 'Test':
            training_color = '\033[0;35m'
        else:
            training_color = '\033[0;36m'

        auPRC_dict={}
        auROC_dict ={}
        MCC_dict ={}
        Spec_dict ={}
        Sen_dict ={}
        for i in range(len(histones)):
            auPRC_dict[histones[i]] = auPR(lab[:,i],pred[:,i])
            auROC_dict[histones[i]] = ROC(lab[:,i],pred[:,i])
            MCC_dict[histones[i]] = MCC(lab[:,i],truths[:,i])
            Spec_dict[histones[i]] = Spec(lab[:,i],truths[:,i])   
            Sen_dict[histones[i]] = Sen(lab[:,i],truths[:,i])
        print_str = training_color + '\t%s\t%s\tauROC : %.4f,auPRC : %.4f,MCC : %.4f,Specificity : %.4f,Sensitivity : %.4f\033[0m'
        print('-'*25+Type+'-'*25)
        if loss is not None: loss_str = ',Loss : %.4f'%loss
        else :loss_str =''
        print('\033[0;36m%s\tTotalMean\tauROC : %.4f,auPRC : %.4f,MCC : %.4f,Specificity : %.4f,Sensitivity : %.4f%s\033[0m'%(Type,np.mean(list(auROC_dict.values())),np.mean(list(auPRC_dict.values())),np.mean(list(MCC_dict.values())),np.mean(list(Spec_dict.values())),np.mean(list(Sen_dict.values())),loss_str) )
        for histone in histones:
                print(print_str%(Type,histone.ljust(10),auROC_dict[histone],auPRC_dict[histone],MCC_dict[histone],Spec_dict[histone],Sen_dict[histone]))
        return auPRC_dict,auROC_dict,MCC_dict,Spec_dict,Sen_dict

```

**train_dna.py**

```python
from model_dna import DeepHistone
import copy
import numpy as np
from utils_dna import metrics,model_train,model_eval,model_predict
import torch
#setting 
batchsize=20
train_file = 'onehot_rice_train.npz'
test_file = 'onehot_rice_test.npz'
model_save_file = 'results/model.txt'
lab_save_file ='results/label.txt'
pred_save_file ='results/pred.txt'

print('Begin loading data...')
with np.load(train_file) as f:
    indexs = f['keys']
    dna_dict = dict(zip(f['keys'],f['DNAseq']))
    lab_dict = dict(zip(f['keys'],f['labels']))
np.random.shuffle(indexs)
idx_len = len(indexs)
train_index=indexs[:int(idx_len*4/5)]
valid_index=indexs[int(idx_len*4/5):]






use_gpu = torch.cuda.is_available()
model = DeepHistone(use_gpu)
print('Begin training model...')
best_model = copy.deepcopy(model)
best_valid_auPRC=0
best_valid_loss = np.float64('Inf')
for epoch in range(50):
    np.random.shuffle(train_index)
    train_loss= model_train(train_index,model,batchsize,dna_dict,lab_dict,)
    valid_loss,valid_lab,valid_pred,valid_truths= model_eval(valid_index, model,batchsize,dna_dict,lab_dict,)
    valid_auPRC,valid_auROC,valid_MCC,valid_Spec,valid_Sen= metrics(valid_lab,valid_pred,valid_truths,'Valid',valid_loss)

    if np.mean(list(valid_auPRC.values())) >best_valid_auPRC:
        best_model = copy.deepcopy(model)

    if valid_loss < best_valid_loss: 
        early_stop_time = 0
        best_valid_loss = valid_loss	
    else:
        model.updateLR(0.1)
        early_stop_time += 1
        if early_stop_time >= 5: break


print('Begin predicting...')
with np.load(test_file) as f:
    indexs2 = f['keys']
    dna_dict2 = dict(zip(f['keys'],f['DNAseq']))
    lab_dict2 = dict(zip(f['keys'],f['labels']))

np.random.shuffle(indexs2)
idx_len2 = len(indexs)


for i in range(5):
    test_index=indexs2[int((i/5)*idx_len2):int(((i+1)/5)*idx_len2)]
    test_lab,test_pred,test_truths = model_predict(test_index,best_model,batchsize,dna_dict2,lab_dict2,)	
    test_auPR,test_roc,test_MCC,test_Spec,test_Sen= metrics(test_lab,test_pred,test_truths,'Test')


print('Begin saving...')
np.savetxt(lab_save_file, test_lab, fmt='%d', delimiter='\t')
np.savetxt(pred_save_file, test_pred, fmt='%.4f', delimiter='\t')
best_model.save_model(model_save_file)
torch.save(model,'model1.pth')

print('Finished.')

```

#### 构建总数据集

20个品种5种组蛋白修饰所有阳性

| histone modifications | nums   |
| --------------------- | ------ |
| H3K4me3（1）          | 256721 |
| H3K27ac（2）          | 227526 |
| H3K4me1（3）          | 152355 |
| H3K27me3（4）         | 136028 |
| H3K9me2（5）          | 118142 |
| total                 | 890772 |
| total（after check）  | 887724 |

```shell
#!/bin/bash

for n in $(cat histone)
do
    for i in $(cat id.txt)
    do
    python3 target_mark5.0.py -f ${i}.fasta.fai -b data/signal_area/sort_${i}.bed -o target_${i}_${n}.bed -s ${i} -m ${n} && paste $[i}.fasta target_${i}_${n}.bed > data/dataset/ex1/${n}.csv && awk '$3 != 0 {print}' data/dataset/ex1/${n}.csv >> dataset_all.csv | awk '{print $3}' | uniq -c  
    done
done

```

```shell
bsub -q gpu -o deep_histone_result.out -e histone.err 'python3 train_dna.py'
```



### **Nt_Transformer**

<img src="https://www.biorxiv.org/content/biorxiv/early/2021/01/29/2021.01.28.428629/F1.large.jpg?width=800&height=600&carousel=1" alt="img" style="zoom: 50%;" />

**参考文献：**

[NUCLEIC TRANSFORMER: DEEP LEARNING ON NUCLEIC ACIDS WITH SELF-ATTENTION AND CONVOLUTIONS](https://www.biorxiv.org/content/10.1101/2021.01.28.428629v1)

github:https://github.com/Shujun-He/Nucleic-Transformer

#### Transformer：Attention is All You Need

**参考文献：**

[Attention Is All You Need](https://arxiv.org/abs/1706.03762)

**论文解析：**

https://blog.csdn.net/weixin_42431920/article/details/110731751

https://zhuanlan.zhihu.com/p/48508221

https://www.bilibili.com/video/BV1Di4y1c7Zm?from=search&seid=15155897634554281203

[**学习笔记**]()



#### **模型架构**

```
/public/home/xwli/xwzhang/deeplearningDATA/rice/Nt_Transformer/

├── data/
├── results/
│   └── model.txt
│   └── label.txt
│   └── pred.txt
├── Dataset.py 
├── evalute_test.py
├── Functions.py
├── Logger.py
├── LrScheduler.py
├── Metrics.py
├── Network.py
├── train.py
├── run.sh
├── test.sh
    
```

**Dataset.py**

```python
import pickle
import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch


nt_int={
"A": 0,
"T": 1,
"G": 2,
"C": 3,}

def nucleatide2int(nt_sequence,target_length=None):
    int_sequence=[]
    for nt in nt_sequence:
        nt=nt.upper()
        if nt in nt_int:
            int_sequence.append(nt_int[nt])
    int_sequence=np.asarray(int_sequence,dtype='int32')
    if target_length:
        int_sequence=np.pad(int_sequence,(0,target_length-len(int_sequence)),constant_values=-1)
    return int_sequence


class ViraminerDataset(torch.utils.data.Dataset):
    def __init__(self,sequences,labels):
        self.data=[]
        for seq in sequences:
            self.data.append(nucleatide2int(seq))

        self.data=np.asarray(self.data,dtype='int')
        self.labels=np.asarray(labels,dtype='int')

        print(self.data.shape)
        print(self.labels.shape)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self,idx):
        return {'data':self.data[idx], 'labels':self.labels[idx]}
```

**evalute_test.py**

```python
import os
import torch
import torch.nn as nn
import time
from Functions import *
from Dataset import *
from Network import *
from LrScheduler import *
import Metrics
from Logger import CSVLogger
import argparse
try:
    #from apex.parallel import DistributedDataParallel as DDP
    from apex.fp16_utils import *
    from apex import amp, optimizers
    from apex.multi_tensor_apply import multi_tensor_applier
except ImportError:
    raise ImportError("Please install apex from https://www.github.com/nvidia/apex to run this example.")
from tqdm import tqdm

def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--gpu_id', type=str, default='0,1',  help='which gpu to use')
    parser.add_argument('--path', type=str, default='../', help='path of csv file with DNA sequences and labels')
    parser.add_argument('--epochs', type=int, default=150, help='number of epochs to train')
    parser.add_argument('--batch_size', type=int, default=24, help='size of each batch during training')
    parser.add_argument('--weight_decay', type=float, default=0, help='weight dacay used in optimizer')
    parser.add_argument('--ntoken', type=int, default=4, help='number of tokens to represent DNA nucleotides (should always be 4)')
    parser.add_argument('--nclass', type=int, default=2, help='number of classes from the linear decoder')
    parser.add_argument('--ninp', type=int, default=512, help='ninp for transformer encoder')
    parser.add_argument('--nhead', type=int, default=8, help='nhead for transformer encoder')
    parser.add_argument('--nhid', type=int, default=2048, help='nhid for transformer encoder')
    parser.add_argument('--nlayers', type=int, default=6, help='nlayers for transformer encoder')
    parser.add_argument('--save_freq', type=int, default=1, help='saving checkpoints per save_freq epochs')
    parser.add_argument('--dropout', type=float, default=.1, help='transformer dropout')
    parser.add_argument('--warmup_steps', type=int, default=3200, help='training schedule warmup steps')
    parser.add_argument('--lr_scale', type=float, default=0.1, help='learning rate scale')
    parser.add_argument('--nmute', type=int, default=18, help='number of mutations during training')
    parser.add_argument('--kmers', type=int, nargs='+', default=[2,3,4,5,6], help='k-mers to be aggregated')
    #parser.add_argument('--kmer_aggregation', type=bool, default=True, help='k-mers to be aggregated')
    parser.add_argument('--kmer_aggregation', dest='kmer_aggregation', action='store_true')
    parser.add_argument('--no_kmer_aggregation', dest='kmer_aggregation', action='store_false')
    parser.set_defaults(kmer_aggregation=True)
    parser.add_argument('--nfolds', type=int, default=5, help='number of cross validation folds')
    parser.add_argument('--fold', type=int, default=0, help='which fold to train')
    parser.add_argument('--val_freq', type=int, default=1, help='which fold to train')
    opts = parser.parse_args()
    return opts


opts=get_args()
#gpu selection
os.environ["CUDA_VISIBLE_DEVICES"] = opts.gpu_id
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#lr=0

#checkpointing
checkpoints_folder='checkpoints_fold{}'.format((opts.fold))
csv_file='log_fold{}.csv'.format((opts.fold))
columns=['epoch','train_loss','train_acc','recon_acc',
         'val_loss','val_auc','val_acc','val_sens','val_spec']
#logger=CSVLogger(columns,csv_file)

#build model and logger
MODELS=[]
for i in range(3):
    model=NucleicTransformer(opts.ntoken, opts.nclass, opts.ninp, opts.nhead, opts.nhid,
                           opts.nlayers, opts.kmer_aggregation, kmers=opts.kmers,
                           dropout=opts.dropout).to(device)
    optimizer=torch.optim.Adam(model.parameters(), weight_decay=opts.weight_decay)
    criterion=nn.CrossEntropyLoss(reduction='none')
    lr_schedule=lr_AIAYN(optimizer,opts.ninp,opts.warmup_steps,opts.lr_scale)
    # Initialization
    opt_level = 'O1'
    model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)
    model = nn.DataParallel(model)


    pytorch_total_params = sum(p.numel() for p in model.parameters())
    print('Total number of paramters: {}'.format(pytorch_total_params))

    model.load_state_dict(torch.load("best_weights/fold0top{}.ckpt".format(i+1)))
    model.eval()
    MODELS.append(model)

dict=MODELS[0].module.state_dict()
for key in dict:
    for i in range(1,len(MODELS)):
        dict[key]=dict[key]+MODELS[i].module.state_dict()[key]

    dict[key]=dict[key]/float(len(MODELS))

MODELS[0].module.load_state_dict(dict)
avg_model=MODELS[0]

def geometric_mean(preds):
    gmean=np.ones(preds.shape[1:])

    for pred in preds:
        gmean=gmean*pred

    gmean=gmean**(1/len(preds))
    return gmean

df=pd.read_csv('../fullset_test.csv',header=None)

seqs=[]
labels=[]

for i in range(len(df)):
    seqs.append(nucleatide2int(df.iloc[i,1]))
    labels.append(df.iloc[i,2])
labels=np.asarray(labels).astype("int")
seqs=np.asarray(seqs).astype("int")


batch_size=128
batches=np.around(len(df)/batch_size+0.5).astype('int')
preds=[]
softmax = nn.Softmax(dim=1)
for i in tqdm(range(batches)):
    with torch.no_grad():
        outputs=[]
        #for model in MODELS:
        x=torch.Tensor(seqs[i*batch_size:(i+1)*batch_size]).to(device).long()
        y=softmax(avg_model(x))
        #outputs.append(softmax(y).cpu().numpy())
        for vec in y:
            preds.append(vec.cpu().numpy())

from sklearn import metrics
preds=np.asarray(preds)
auc=metrics.roc_auc_score(labels,preds[:,1])

with open("test_results.p",'wb+') as f:
    pickle.dump([labels,preds],f)


print(auc)
with open("test_score.txt",'w+') as f:
    f.write("test auc score: {}".format(auc))




# for i in range(3,10):
    # ngrams=np.arange(2,i)
    # print(ngrams)
    # train_fold(0,ngrams)
# # train_fold(0,[2,3,4])

```

**Functions.py**

```python
import torch
import os
from sklearn import metrics
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
from tqdm import tqdm
import Metrics
import numpy as np
import os
import pandas as pd
import random

def seed_everything(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

def get_best_weights_from_fold(fold, record, top=3):
    csv_file='{}log_fold{}.csv'.format(record, fold)

    history=pd.read_csv(csv_file)
    scores=np.asarray(history.val_auc)
    top_epochs=scores.argsort()[-3:][::-1]
    print(scores[top_epochs])
    os.system('mkdir best_weights')

    for i in range(top):
        weights_path='{}checkpoints_fold{}/epoch{}.ckpt'.format(record, fold,history.epoch[top_epochs[i]])
        print(weights_path)
        os.system('cp {} best_weights/fold{}top{}.ckpt'.format(weights_path,fold,i+1))
    os.system('rm -r {}checkpoints_fold{}'.format(record, fold))

def smoothcrossentropyloss(pred,gold,n_class=2,smoothing=0.05):
    gold = gold.contiguous().view(-1)
    one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)
    one_hot = one_hot * (1 - smoothing) + (1 - one_hot) * smoothing / (n_class - 1)
    log_prb = F.log_softmax(pred, dim=1)
    loss = -(one_hot * log_prb)
    #loss=loss.sum(1).mean()
    return loss

def mutate_dna_sequence(sequence,nmute=15):
    mutation=torch.randint(0,4,size=(sequence.shape[0],nmute))
    to_mutate = torch.randperm(sequence.shape[1])[:nmute]
    sequence[:,to_mutate]=mutation
    return sequence

def get_MLM_mask(sequence,nmask=12):
    mask=np.zeros(sequence.shape,dtype='bool')
    to_mask=np.random.choice(len(sequence[0]),size=(nmask),replace=False)
    mask[:,to_mask]=True
    return mask

def get_complementary_sequence(sequence):
    complementary_sequence=sequence.copy()
    complementary_sequence[sequence==0]=1
    complementary_sequence[sequence==1]=0
    complementary_sequence[sequence==2]=3
    complementary_sequence[sequence==3]=2
    complementary_sequence=complementary_sequence[:,::-1]
    return complementary_sequence

def update_lr(optimizer, lr):
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

def save_weights(model,optimizer,epoch,folder):
    if os.path.isdir(folder)==False:
        os.makedirs(folder,exist_ok=True)
    torch.save(model.state_dict(), folder+'/epoch{}.ckpt'.format(epoch+1))



def validate(model,device,dataset,batch_size=64):
    batches=len(dataset)
    model.train(False)
    total=0
    predictions=[]
    outputs=[]
    ground_truths=[]
    loss=0
    criterion=nn.CrossEntropyLoss()
    with torch.no_grad():
        for data in tqdm(dataset):
            X=data['data'].to(device)
            Y=data['labels'].to(device)

            output= model(X)
            del X
            loss+=criterion(output,Y)
            classification_predictions = torch.argmax(output,dim=1).squeeze()
            for pred in classification_predictions:
                predictions.append(pred.cpu().numpy())
            for vector in output:
                outputs.append(vector.cpu().numpy())
            for t in Y:
                ground_truths.append(t.cpu().numpy())
            del output
    torch.cuda.empty_cache()
    val_loss=(loss/batches).cpu()
    ground_truths=np.asarray(ground_truths)
    predictions=np.asarray(predictions)
    outputs=np.asarray(outputs)
    #print(predictions)
    #print(ground_truths)
    #score=metrics.cohen_kappa_score(ground_truths,predictions,weights='quadratic')
    val_acc=Metrics.accuracy(predictions,ground_truths)
    auc=metrics.roc_auc_score(ground_truths,outputs[:,1])
    val_sens=Metrics.sensitivity(predictions,ground_truths)
    val_spec=Metrics.specificity(predictions,ground_truths)
    print('Val accuracy: {}, Val Loss: {}'.format(val_acc,val_loss))
    return val_loss,auc,val_acc,val_sens,val_spec


def predict(model,device,dataset,batch_size=64):
    batches=int(len(dataset.val_indices)/batch_size)+1
    model.train(False)
    total=0
    ground_truths=dataset.labels[dataset.val_indices]
    predictions=[]
    attention_weights=[]
    loss=0
    criterion=nn.CrossEntropyLoss()
    dataset.switch_mode(training=False)
    dataset.update_batchsize(batch_size)
    with torch.no_grad():
        for i in tqdm(range(len(dataset))):
            data=dataset[i]
            X=torch.Tensor(data['data']).to(device,).long()
            Y=torch.Tensor(data['labels']).to(device,dtype=torch.int64)
            directions=data['directions']
            directions=directions.reshape(len(directions),1)*np.ones(X.shape)
            directions=torch.Tensor(directions).to(device).long()
            output,_,_,aw= model(X,directions,None)
            del X
            loss+=criterion(output,Y)
            classification_predictions = torch.argmax(output,dim=1).squeeze()
            for pred in output:
                predictions.append(pred.cpu().numpy())
            for weight in aw:
                attention_weights.append(weight.cpu().numpy())

            del output
    torch.cuda.empty_cache()
    val_loss=(loss/batches).cpu()
    predictions=np.asarray(predictions)
    attention_weights=np.asarray(attention_weights)
    binary_predictions=predictions.copy()
    binary_predictions[binary_predictions==2]=1
    binary_ground_truths=ground_truths.copy()
    binary_ground_truths[binary_ground_truths==2]=1
    return predictions,attention_weights,np.asarray(dataset.data[dataset.val_indices])
```

**Logger.py**

```python
import csv
from os import path


class CSVLogger:
    def __init__(self,columns,file):
        self.columns=columns
        self.file=file
        if not self.check_header():
            self._write_header()


    def check_header(self):
        if path.exists(self.file):
            header=True
        else:
            header=False
        return header


    def _write_header(self):
        with open(self.file,"a") as f:
            string=""
            for attrib in self.columns:
                string+="{},".format(attrib)
            string=string[:len(string)-1]
            string+="\n"
            f.write(string)
        return self

    def log(self,row):
        if len(row)!=len(self.columns):
            raise Exception("Mismatch between row vector and number of columns in logger")
        with open(self.file,"a") as f:
            string=""
            for attrib in row:
                string+="{},".format(attrib)
            string=string[:len(string)-1]
            string+="\n"
            f.write(string)
        return self

```

**LrScheduler.py**

```python
import csv
from os import path


class CSVLogger:
    def __init__(self,columns,file):
        self.columns=columns
        self.file=file
        if not self.check_header():
            self._write_header()


    def check_header(self):
        if path.exists(self.file):
            header=True
        else:
            header=False
        return header


    def _write_header(self):
        with open(self.file,"a") as f:
            string=""
            for attrib in self.columns:
                string+="{},".format(attrib)
            string=string[:len(string)-1]
            string+="\n"
            f.write(string)
        return self

    def log(self,row):
        if len(row)!=len(self.columns):
            raise Exception("Mismatch between row vector and number of columns in logger")
        with open(self.file,"a") as f:
            string=""
            for attrib in row:
                string+="{},".format(attrib)
            string=string[:len(string)-1]
            string+="\n"
            f.write(string)
        return self

```

**Metrics.py**

```python
import numpy as np


def accuracy(predictions,ground_truths):
    return np.sum(predictions==ground_truths)/len(ground_truths)
    
    
def sensitivity(predictions,ground_truths):
    '''
    Here it is assumed:
    0=negative
    1=positive
    '''
    return 1-len(predictions[(predictions==0)*(ground_truths==1)])/len(ground_truths[ground_truths==1])



def specificity(predictions,ground_truths):
    '''
    Here it is assumed:
    0=negative
    1=positive
    '''
    return 1-len(predictions[(predictions==1)*(ground_truths==0)])/len(ground_truths[ground_truths==0])
   
def MCC(predictions,ground_truths):
    '''
    Here it is assumed:
    0=negative
    1=positive
    '''
    N1=len(predictions[(predictions==0)&(ground_truths==1)])
    N2=len(predictions[(predictions==1)&(ground_truths==0)])
    N3=len(ground_truths[ground_truths==1])
    N4=len(ground_truths[ground_truths==0])
    sens=1-N1/N3
    spec=1-N2/N4
    denom=np.sqrt((1+(N2-N1)/N3)*(1+(N1-N2)/N4))
    return (1-sens-spec)/denom
    
```

**Network.py**

```python
import math
import torch
import torch.nn as nn
import torch.nn.functional as F


#mish activation
class Mish(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x):
        #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)
        return x *( torch.tanh(F.softplus(x)))


from torch.nn.parameter import Parameter
def gem(x, p=3, eps=1e-6):
    return F.avg_pool1d(x.clamp(min=eps).pow(p), (x.size(-1))).pow(1./p)
class GeM(nn.Module):
    def __init__(self, p=3, eps=1e-6):
        super(GeM,self).__init__()
        self.p = Parameter(torch.ones(1)*p)
        self.eps = eps
    def forward(self, x):
        return gem(x, p=self.p, eps=self.eps)
    def __repr__(self):
        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'


class TransformerEncoderLayer(nn.Module):
    r"""TransformerEncoderLayer is made up of self-attn and feedforward network.
    This standard encoder layer is based on the paper "Attention Is All You Need".
    Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
    Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
    Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
    in a different way during application.

    Args:
        d_model: the number of expected features in the input (required).
        nhead: the number of heads in the multiheadattention models (required).
        dim_feedforward: the dimension of the feedforward network model (default=2048).
        dropout: the dropout value (default=0.1).
        activation: the activation function of intermediate layer, relu or gelu (default=relu).

    Examples::
        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)
        >>> src = torch.rand(10, 32, 512)
        >>> out = encoder_layer(src)
    """

    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation="relu"):
        super(TransformerEncoderLayer, self).__init__()
        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)
        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.dropout = nn.Dropout(dropout)
        self.linear2 = nn.Linear(dim_feedforward, d_model)

        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)

        self.activation = Mish()


    def forward(self, src , src_mask = None, src_key_padding_mask = None):
        src2,attention_weights = self.self_attn(src, src, src, attn_mask=src_mask,
                              key_padding_mask=src_key_padding_mask)
        src = src + self.dropout1(src2)
        src = self.norm1(src)
        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))
        src = src + self.dropout2(src2)
        src = self.norm2(src)
        return src,attention_weights


class LinearDecoder(nn.Module):
    def __init__(self,num_classes,ninp,dropout,pool=True,):
        super(LinearDecoder, self).__init__()
        # if pool:
            # self.pool_layer=GeM()
        if pool:
            self.classifier=nn.Linear(ninp,num_classes)
        else:
            self.classifier=nn.Linear(ninp,num_classes)
        self.pool=pool
        self.pool_layer=GeM()

    def forward(self,x):
        if self.pool:
            # max_x,_=torch.max(x,dim=1)
            # x=torch.cat([torch.mean(x,dim=1),max_x],dim=-1)
            #print(x.shape)
            x=self.pool_layer(x.permute(0,2,1)).permute(0,2,1).squeeze()
            #print(x.shape)
        x=self.classifier(x)
        return x


class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)


class K_mer_aggregate(nn.Module):
    def __init__(self,kmers,in_dim,out_dim,dropout=0.1):
        super(K_mer_aggregate, self).__init__()
        #self.dropout=nn.Dropout(dropout)
        self.convs=[]
        for i in kmers:
            print(i)
            self.convs.append(nn.Conv1d(in_dim,out_dim,i,padding=0))
        self.convs=nn.ModuleList(self.convs)
        self.norm=nn.LayerNorm(out_dim)
        #self.activation=nn.ReLU(inplace=True)
        #self.activation=Mish()

    def forward(self,x):
        outputs=[]
        for conv in self.convs:
            outputs.append(conv(x))
        outputs=torch.cat(outputs,dim=2)
        return self.norm(outputs.permute(2,0,1))


class NucleicTransformer(nn.Module):

    def __init__(self, ntoken, nclass, ninp, nhead, nhid, nlayers, kmer_aggregation, kmers, dropout=0.5,return_aw=False):
        super(NucleicTransformer, self).__init__()
        self.model_type = 'Transformer'
        self.src_mask = None
        self.pos_encoder = PositionalEncoding(ninp, dropout)
        self.kmers=kmers
        #if self.ngrams!=None:
        self.kmer_aggregation=kmer_aggregation
        if self.kmer_aggregation:
            self.k_mer_aggregate=K_mer_aggregate(kmers,ninp,ninp)
        else:
            print("No kmer aggregation is chosen")
        self.transformer_encoder = []
        for i in range(nlayers):
            self.transformer_encoder.append(TransformerEncoderLayer(ninp, nhead, nhid, dropout))
        self.transformer_encoder= nn.ModuleList(self.transformer_encoder)
        self.encoder = nn.Embedding(ntoken, ninp)
        #self.directional_encoder = nn.Embedding(3, ninp//8)
        self.ninp = ninp
        self.decoder = LinearDecoder(nclass,ninp,dropout)
        self.return_aw=False


    def forward(self, src):
        src = src.permute(1,0)
        #dir = dir.permute(1,0)
        src = self.encoder(src) #* math.sqrt(self.ninp)
        #dir = self.directional_encoder(dir)
        #src = torch.cat([src,dir],dim=-1)
        src = self.pos_encoder(src)
        #if self.ngrams!=None:
        if self.kmer_aggregation:
            kmer_output = self.k_mer_aggregate(src.permute(1,2,0))
            #src = torch.cat([src,kmer_output],dim=0)
            src = kmer_output
        attention_weights=[]
        for layer in self.transformer_encoder:
            src,attention_weights_layer=layer(src)
            attention_weights.append(attention_weights_layer)

        encoder_output = src.permute(1,0,2)
        #print(encoder_output.shape)
        output = self.decoder(encoder_output)
        if self.return_aw:
            attention_weights=torch.stack(attention_weights).permute(1,0,2,3)
            return output, attention_weights
        else:
            return output
```

**train.py**

```python
import os
import torch
import torch.nn as nn
import time
from Functions import *
from Dataset import *
from Network import *
from LrScheduler import *
import Metrics
from Logger import CSVLogger
import argparse
from tensorboardX import SummaryWriter
from torch.cuda.amp import autocast as autocast
from torch.cuda.amp import GradScaler as GradScaler



def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--gpu_id', type=str, default='0',  help='which gpu to use')
    parser.add_argument('--path', type=str, default='../', help='path of csv file with DNA sequences and labels')
    parser.add_argument('--epochs', type=int, default=150, help='number of epochs to train')
    parser.add_argument('--batch_size', type=int, default=24, help='size of each batch during training')
    parser.add_argument('--weight_decay', type=float, default=0, help='weight dacay used in optimizer')
    parser.add_argument('--ntoken', type=int, default=4, help='number of tokens to represent DNA nucleotides (should always be 4)')
    parser.add_argument('--nclass', type=int, default=2, help='number of classes from the linear decoder')
    parser.add_argument('--ninp', type=int, default=512, help='ninp for transformer encoder')
    parser.add_argument('--nhead', type=int, default=8, help='nhead for transformer encoder')
    parser.add_argument('--nhid', type=int, default=2048, help='nhid for transformer encoder')
    parser.add_argument('--nlayers', type=int, default=6, help='nlayers for transformer encoder')
    parser.add_argument('--save_freq', type=int, default=1, help='saving checkpoints per save_freq epochs')
    parser.add_argument('--dropout', type=float, default=.1, help='transformer dropout')
    parser.add_argument('--warmup_steps', type=int, default=3200, help='training schedule warmup steps')
    parser.add_argument('--lr_scale', type=float, default=0.1, help='learning rate scale')
    parser.add_argument('--kmers', type=int, nargs='+', default=[2,3,4,5,6], help='k-mers to be aggregated')
    #parser.add_argument('--kmer_aggregation', type=bool, default=True, help='k-mers to be aggregated')
    parser.add_argument('--kmer_aggregation', dest='kmer_aggregation', action='store_true')
    parser.add_argument('--no_kmer_aggregation', dest='kmer_aggregation', action='store_false')
    parser.set_defaults(kmer_aggregation=True)
    parser.add_argument('--nfolds', type=int, default=5, help='number of cross validation folds')
    parser.add_argument('--fold', type=int, default=0, help='which fold to train')
    parser.add_argument('--val_freq', type=int, default=1, help='which fold to train')
    parser.add_argument('--num_workers', type=int, default=1, help='num_workers')
    parser.add_argument('--record',  type=str, default=' ', help='train or test record')
    opts = parser.parse_args()
    return opts

tb = SummaryWriter('/root/my_train/tblogdir/H3K27me3')

def train_fold():

    opts = get_args()
    seed_everything(2020)
    #gpu selection
    os.environ["CUDA_VISIBLE_DEVICES"] = opts.gpu_id
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    data = pd.read_csv('/root/my_train/dataset_all/H3K27me3_train_24w.txt', header=None,  sep='\t')

    dataset = ViraminerDataset(data.iloc[:220000,0],data.iloc[:220000,1])
    dataloader = torch.utils.data.DataLoader(dataset,batch_size=opts.batch_size,shuffle=True,num_workers=opts.num_workers)
    val_dataset = ViraminerDataset(data.iloc[220000:,0],data.iloc[220000:,1])
    val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=opts.batch_size,shuffle=False)

    #exit()
    #lr=0

    #checkpointing
    checkpoints_folder = '{}checkpoints_fold{}'.format(opts.record, opts.fold)
    csv_file = '{}log_fold{}.csv'.format(opts.record, opts.fold)
    columns = ['epoch','train_loss',
             'val_loss','val_auc','val_acc','val_sens','val_spec']
    logger = CSVLogger(columns,csv_file)

    #build model and logger
    model = NucleicTransformer(opts.ntoken, opts.nclass, opts.ninp, opts.nhead, opts.nhid,
                           opts.nlayers, opts.kmer_aggregation, kmers=opts.kmers,
                           dropout=opts.dropout).to(device)
    optimizer = torch.optim.Adam(model.parameters(), weight_decay=opts.weight_decay)
    criterion = nn.CrossEntropyLoss(reduction='none')
    lr_schedule = lr_AIAYN(optimizer,opts.ninp,opts.warmup_steps,opts.lr_scale)
    
    softmax = nn.Softmax(dim=1)
    
    pytorch_total_params = sum(p.numel() for p in model.parameters())
    print('Total number of paramters: {}'.format(pytorch_total_params))

    print("Starting training for fold {}/{}".format(opts.fold,opts.nfolds))
    #training loop
    scaler = GradScaler()
    for epoch in range(opts.epochs):
        model.train(True)
        t = time.time()
        total_loss = 0
        total_steps = len(dataloader)
        for step, data in enumerate(dataloader):
        #for step in range(1):
            lr = lr_schedule.step()
            src = data['data'].to(device)
            labels = data['labels'].to(device)
            optimizer.zero_grad()

            with autocast():
            	output = model(src)
            	loss = torch.mean(criterion(output,labels))
            
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(),1)
            scaler.step(optimizer)
            scaler.update()
            
            total_loss += loss

            print ("Epoch [{}/{}], Step [{}/{}] Loss: {:.3f} Lr:{:.6f} Time: {:.1f}"
                           .format(epoch+1, opts.epochs, step+1, total_steps, total_loss/(step+1) , lr,time.time()-t),end='\r',flush=True) #total_loss/(step+1)
            #break
        print('')

        train_loss = total_loss/(step+1)        

        if (epoch+1)%opts.val_freq == 0:
            val_loss,auc,val_acc,val_sens,val_spec=validate(model,device,val_dataloader,batch_size=opts.batch_size*2)
            print("Epoch {} train loss: {}".format(epoch+1,train_loss))
            tb.add_scalars('train/val/loss', {'train':train_loss, 'val':val_loss}, epoch+1)
            tb.add_scalar('val_acc', val_acc, epoch+1)
            tb.add_scalar('auc', auc, epoch+1)
            tb.add_scalar('val_sens', val_sens, epoch+1)
            tb.add_scalar('val_spec', val_spec, epoch+1)

            to_log = [epoch+1,train_loss,val_loss,auc,val_acc,val_sens,val_spec]
            logger.log(to_log)
            

        if (epoch+1)%opts.save_freq == 0:
            save_weights(model,optimizer,epoch,checkpoints_folder)
    
    tb.close()
    get_best_weights_from_fold(opts.record, opts.fold)
    
train_fold()

```

**run.sh**

```shell
#!/bin/bash
python train.py --gpu_id 0 --kmer_aggregation  --epochs 12 --nlayers 6 \
 --batch_size 64 --kmers 20 --lr_scale 0.1 --ninp 512  --nhid 2048 --num_workers 8 --nhead 8 --record 0504_train1

```

**test.sh**

```shell
#!/bin/bash
python evaluate_test.py --gpu_id 0,1 --kmer_aggregation --nmute 20 --epochs 100 --nlayers 6 \
--batch_size 128 --kmers 13 --lr_scale 0.1 --ninp 512 --nhid 2048

```



## 