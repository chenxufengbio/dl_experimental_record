
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>构建模型 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="模型评估.html" />
    
    
    <link rel="prev" href="数据获取与预处理.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="./">
            
                <a href="./">
            
                    
                    实验流程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="实验流程概述.html">
            
                <a href="实验流程概述.html">
            
                    
                    实验流程概述
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="数据获取与预处理.html">
            
                <a href="数据获取与预处理.html">
            
                    
                    数据获取与预处理
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.3" data-path="构建模型.html">
            
                <a href="构建模型.html">
            
                    
                    构建模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="模型评估.html">
            
                <a href="模型评估.html">
            
                    
                    模型评估
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="特征提取.html">
            
                <a href="特征提取.html">
            
                    
                    特征提取
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../结果分析.html">
            
                <a href="../结果分析.html">
            
                    
                    结果分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../训练日志.html">
            
                <a href="../训练日志.html">
            
                    
                    训练日志
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../背景知识/READ.html">
            
                <a href="../背景知识/READ.html">
            
                    
                    背景知识
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../背景知识/生物.html">
            
                <a href="../背景知识/生物.html">
            
                    
                    生物学
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../背景知识/深度学习.html">
            
                <a href="../背景知识/深度学习.html">
            
                    
                    深度学习
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >构建模型</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id="&#x6784;&#x5EFA;&#x6A21;&#x578B;">&#x6784;&#x5EFA;&#x6A21;&#x578B;</h2>
<h3 id="&#x6784;&#x5EFA;&#x57FA;&#x672C;&#x6A21;&#x578B;&#xFF08;pytorch&#xFF09;">&#x6784;&#x5EFA;&#x57FA;&#x672C;&#x6A21;&#x578B;&#xFF08;pytorch&#xFF09;</h3>
<p>&#x521D;&#x6B65;&#x5B9E;&#x9A8C;&#x5728;&#x6052;&#x6E90;&#x4E91;&#x670D;&#x52A1;&#x5668;&#x4E0A;&#x8FDB;&#x884C;</p>
<h4 id="&#x5BFC;&#x5165;&#x6A21;&#x5757;"><strong>&#x5BFC;&#x5165;&#x6A21;&#x5757;</strong></h4>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, optim
<span class="hljs-keyword">import</span> sys
</code></pre>
<h4 id="&#x8BBE;&#x7F6E;gpu"><strong>&#x8BBE;&#x7F6E;GPU</strong></h4>
<pre><code class="lang-python">device = torch.device(<span class="hljs-string">&apos;cuda&apos;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&apos;cpu&apos;</span>)
</code></pre>
<h4 id="&#x6570;&#x636E;&#x5BFC;&#x5165;&#x53CA;&#x683C;&#x5F0F;&#x8F6C;&#x6362;"><strong>&#x6570;&#x636E;&#x5BFC;&#x5165;&#x53CA;&#x683C;&#x5F0F;&#x8F6C;&#x6362;</strong></h4>
<pre><code class="lang-python">data_np = np.load(<span class="hljs-string">&apos;./one_hot.npy&apos;</span>)
target_pd =pd.read_csv(<span class="hljs-string">&apos;./target6.txt&apos;</span>,sep = <span class="hljs-string">&apos;\n&apos;</span>)
<span class="hljs-comment">#&#x8F6C;&#x6362;&#x6210;tensor</span>
data_tensor = torch.from_numpy(data_np)
target_array = np.array(target_pd)
target_tensor = torch.tensor(target_array)
<span class="hljs-comment">#&#x8F6C;&#x7F6E;&#x6210;(4&#xFF0C;500)</span>
data_tensor = data_tensor.reshape(<span class="hljs-number">10000</span>,<span class="hljs-number">4</span>,<span class="hljs-number">500</span>)
<span class="hljs-comment">#&#x8F6C;&#x6362;&#x6210;float&#xFF08;&#x540E;&#x7EED;&#x6A21;&#x578B;&#x8F93;&#x5165;&#x9700;&#x8981;&#xFF09;</span>
data_tensor = data_tensor.float()
target_tenor = target_tensor.float()
</code></pre>
<h4 id="&#x6784;&#x5EFA;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;&#xFF08;tensordataset&#x7C7B;&#x548C;dataloader&#x7C7B;&#xFF09;"><strong>&#x6784;&#x5EFA;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;</strong>&#xFF08;TensorDataset&#x7C7B;&#x548C;DataLoader&#x7C7B;&#xFF09;</h4>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TensorDataset</span><span class="hljs-params">(data.Dataset)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;Dataset wrapping data and target tensors.
    Each sample will be retrieved by indexing both tensors along the first
    dimension.
    Arguments:
        data_tensor (Tensor): contains sample data.
        target_tensor (Tensor): contains sample targets (labels).
    &quot;&quot;&quot;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, data_tensor, target_tensor)</span>:</span>
        <span class="hljs-keyword">assert</span> data_tensor.size(<span class="hljs-number">0</span>) == target_tensor.size(<span class="hljs-number">0</span>)
        self.data_tensor = data_tensor
        self.target_tensor = target_tensor

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, index)</span>:</span>
        <span class="hljs-keyword">return</span> self.data_tensor[index], self.target_tensor[index]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> len(self.data_tensor)
</code></pre>
<pre><code class="lang-python">train_data = TensorDataset(data_tensor[<span class="hljs-number">0</span>:<span class="hljs-number">9000</span>], target_tensor[<span class="hljs-number">0</span>:<span class="hljs-number">9000</span>])
val_data = TensorDataset(data_tensor[<span class="hljs-number">9000</span>:<span class="hljs-number">10000</span>], target_tensor[<span class="hljs-number">9000</span>:<span class="hljs-number">10000</span>])
train_dataloader = data.DataLoader(train_data,batch_size = <span class="hljs-number">200</span>,
                        shuffle=<span class="hljs-keyword">True</span>,num_workers=<span class="hljs-number">0</span>)
val_dataloader = data.DataLoader(val_data,batch_size = <span class="hljs-number">200</span>,
                        shuffle=<span class="hljs-keyword">False</span>,num_workers=<span class="hljs-number">0</span>)
</code></pre>
<h3 id="deepsea">DeepSEA</h3>
<p>&#x4E3A;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#x589E;&#x5927;&#x6CDB;&#x5316;&#x80FD;&#x529B;&#xFF0C;&#x5728;&#x5377;&#x79EF;&#x5C42;&#x540E;&#x52A0;&#x5165;BN&#x5C42;&#xFF08;&#x5F52;&#x4E00;&#x5316;&#xFF09;</p>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DeepSEA</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, sequence_length=<span class="hljs-number">500</span>, n_genomic_features=<span class="hljs-number">2</span>)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        Parameters
        ----------
        sequence_length : int
        n_genomic_features : int
        &quot;&quot;&quot;</span>
        super(DeepSEA, self).__init__()
        conv_kernel_size = <span class="hljs-number">8</span>
        pool_kernel_size = <span class="hljs-number">4</span>

        self.conv_net = nn.Sequential(
            nn.Conv1d(<span class="hljs-number">4</span>, <span class="hljs-number">320</span>, kernel_size=conv_kernel_size),
            nn.BatchNorm1d(<span class="hljs-number">320</span>),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=<span class="hljs-number">0.2</span>),

            nn.Conv1d(<span class="hljs-number">320</span>, <span class="hljs-number">480</span>, kernel_size=conv_kernel_size),
            nn.BatchNorm1d(<span class="hljs-number">480</span>),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=<span class="hljs-number">0.2</span>),

            nn.Conv1d(<span class="hljs-number">480</span>, <span class="hljs-number">960</span>, kernel_size=conv_kernel_size),
            nn.BatchNorm1d(<span class="hljs-number">960</span>),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.Dropout(p=<span class="hljs-number">0.5</span>))

        reduce_by = conv_kernel_size - <span class="hljs-number">1</span>

        self.n_channels = int(
            np.floor(
                (np.floor(
                    (sequence_length - reduce_by) / pool_kernel_size)
                 - reduce_by) / pool_kernel_size)
            - reduce_by)
        self.classifier = nn.Sequential(
            nn.Linear(<span class="hljs-number">960</span> * self.n_channels, n_genomic_features),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.Linear(n_genomic_features, n_genomic_features),
            nn.Sigmoid())

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;Forward propagation of a batch.
        &quot;&quot;&quot;</span>
        out = self.conv_net(x)
        reshape_out = out.view(out.size(<span class="hljs-number">0</span>), <span class="hljs-number">960</span> * self.n_channels)
        predict = self.classifier(reshape_out)
        <span class="hljs-keyword">return</span> predict
</code></pre>
<p><strong>&#x521B;&#x5EFA;&#x8BAD;&#x7EC3;&#x51FD;&#x6570;</strong></p>
<p>&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF1A;CrossEntropyLoss</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span>:</span>
    net = net.to(device)
    print(<span class="hljs-string">&quot;training on &quot;</span>, device)
    loss = torch.nn.CrossEntropyLoss()
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(num_epochs):
        train_l_sum, train_acc_sum, n, batch_count, start = <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, time.time()
        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:
            X = X.to(device)
            y = y.to(device)
            y_hat = net(X)
            y = y.squeeze()
            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.cpu().item()
            train_acc_sum += (y_hat.argmax(dim=<span class="hljs-number">1</span>) == y).sum().cpu().item()
            n += y.shape[<span class="hljs-number">0</span>]
            batch_count += <span class="hljs-number">1</span>
        test_acc = evaluate_accuracy(test_iter, net)
        print(<span class="hljs-string">&apos;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&apos;</span>
              % (epoch + <span class="hljs-number">1</span>, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))
</code></pre>
<p><strong>&#x521B;&#x5EFA;&#x51C6;&#x786E;&#x7387;&#x8BA1;&#x7B97;&#x51FD;&#x6570;</strong></p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluate_accuracy</span><span class="hljs-params">(data_iter, net, device=None)</span>:</span>
    <span class="hljs-keyword">if</span> device <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span> <span class="hljs-keyword">and</span> isinstance(net, torch.nn.Module):
        device = list(net.parameters())[<span class="hljs-number">0</span>].device
    acc_sum, n = <span class="hljs-number">0.0</span>, <span class="hljs-number">0</span>
    <span class="hljs-keyword">with</span> torch.no_grad():
        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:
            <span class="hljs-keyword">if</span> isinstance(net, torch.nn.Module):
                net.eval() <span class="hljs-comment"># &#x8BC4;&#x4F30;&#x6A21;&#x5F0F;, &#x8FD9;&#x4F1A;&#x5173;&#x95ED;dropout</span>
                acc_sum += (net(X.to(device)).argmax(dim=<span class="hljs-number">1</span>)==y.to(device).squeeze()).float().sum().cpu().item()
                net.train() <span class="hljs-comment"># &#x6539;&#x56DE;&#x8BAD;&#x7EC3;&#x6A21;&#x5F0F;</span>
            <span class="hljs-keyword">else</span>: 
                <span class="hljs-keyword">if</span>(<span class="hljs-string">&apos;is_training&apos;</span> <span class="hljs-keyword">in</span> net.__code__.co_varnames): <span class="hljs-comment"># &#x5982;&#x679C;&#x6709;is_training&#x8FD9;&#x4E2A;&#x53C2;&#x6570;</span>
                    <span class="hljs-comment"># &#x5C06;is_training&#x8BBE;&#x7F6E;&#x6210;False</span>
                    acc_sum += (net(X, is_training=<span class="hljs-keyword">False</span>).argmax(dim=<span class="hljs-number">1</span>) == y).float().sum().item() 
                <span class="hljs-keyword">else</span>:
                    acc_sum += (net(X).argmax(dim=<span class="hljs-number">1</span>) == y).float().sum().item() 
            n += y.shape[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">return</span> acc_sum / n
</code></pre>
<p><strong>&#x5F00;&#x542F;&#x8BAD;&#x7EC3;</strong></p>
<table>
<thead>
<tr>
<th>&#x8D85;&#x53C2;&#x6570;</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>lr</td>
<td>&#x5B66;&#x4E60;&#x7387;</td>
</tr>
<tr>
<td>num_epochs</td>
<td>&#x8BAD;&#x7EC3;&#x6279;&#x6B21;</td>
</tr>
</tbody>
</table>
<p>&#x4F18;&#x5316;&#x5668;&#xFF1A;Adam</p>
<p>&#x4F18;&#x5316;&#x5668;&#xFF1A;SGD</p>
<pre><code class="lang-python">lr, num_epochs = <span class="hljs-number">0.001</span>, <span class="hljs-number">10</span>
optimizer = torch.optim.SGD(net.parameters(), lr=lr)
train(net, train_dataloader, val_dataloader, <span class="hljs-number">256</span>, optimizer, device, num_epochs)
</code></pre>
<p><strong>&#x8BAD;&#x7EC3;&#x7ED3;&#x679C;&#x53EF;&#x89C6;&#x5316;</strong></p>
<p>&#x66F4;&#x65B0;train&#x51FD;&#x6570;</p>
<p>&#x6052;&#x6E90;&#x4E91;</p>
<pre><code class="lang-python">logger.log_value(<span class="hljs-string">&apos;loss&apos;</span>, train_l_sum/batch_count,  epoch*len(train_iter) + batch_count)
logger.log_value(<span class="hljs-string">&apos;train_acc&apos;</span>, <span class="hljs-number">100.</span> *train_acc_sum / n, epoch*len(train_iter) + batch_count)
logger.log_value(<span class="hljs-string">&apos;val_acc&apos;</span>,test_acc,epoch)
</code></pre>
<p><strong>TensorBoard_logger</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> tensorboard_logger <span class="hljs-keyword">import</span> Logger
logger = Logger(logdir=<span class="hljs-string">&quot;./tb_logs&quot;</span>, flush_secs=<span class="hljs-number">10</span>)<span class="hljs-comment">#&#x8BBE;&#x7F6E;&#x8F93;&#x51FA;&#x7684;log&#x6587;&#x4EF6;&#x4F4D;&#x7F6E;</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)</span>:</span>
    net = net.to(device)
    print(<span class="hljs-string">&quot;training on &quot;</span>, device)
    loss = torch.nn.CrossEntropyLoss()
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(num_epochs):
        train_l_sum, train_acc_sum, n, batch_count, start = <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, time.time()
        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:
            X = X.to(device)
            y = y.to(device)
            y_hat = net(X)
            y = y.squeeze()

            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.cpu().item()
            train_acc_sum += (y_hat.argmax(dim=<span class="hljs-number">1</span>) == y).sum().cpu().item()
            n += y.shape[<span class="hljs-number">0</span>]
            batch_count += <span class="hljs-number">1</span>


        test_acc = evaluate_accuracy(test_iter, net)
        logger.log_value(<span class="hljs-string">&apos;loss&apos;</span>, train_l_sum/batch_count,  epoch*len(train_iter) + batch_count)
        logger.log_value(<span class="hljs-string">&apos;train_acc&apos;</span>, <span class="hljs-number">100.</span> *train_acc_sum / n, epoch*len(train_iter) + batch_count)
        logger.log_value(<span class="hljs-string">&apos;val_acc&apos;</span>,test_acc,epoch)
        print(<span class="hljs-string">&apos;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&apos;</span>
              % (epoch + <span class="hljs-number">1</span>, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))
</code></pre>
<h4 id="&#x7EC4;&#x7EC7;&#x4EE3;&#x7801;&#x6846;&#x67B6;"><strong>&#x7EC4;&#x7EC7;&#x4EE3;&#x7801;&#x6846;&#x67B6;</strong></h4>
<p>/public/home/xwli/xwzhang/deeplearningDATA/pytorch_deepsea</p>
<p><strong>&#x6587;&#x4EF6;&#x7EC4;&#x7EC7;&#x67B6;&#x6784;</strong></p>
<pre><code class="lang-text">&#x251C;&#x2500;&#x2500; checkpoints/
&#x251C;&#x2500;&#x2500; data/
&#x2502;   &#x251C;&#x2500;&#x2500; __init__.py
&#x2502;   &#x251C;&#x2500;&#x2500; dataset.py
&#x2502;  
&#x251C;&#x2500;&#x2500; models/
&#x2502;   &#x251C;&#x2500;&#x2500; __init__.py
&#x2502;   &#x251C;&#x2500;&#x2500; DeepSEA.py
&#x2502;   
&#x2502;  
&#x2514;&#x2500;&#x2500; utils/
&#x2502;   &#x251C;&#x2500;&#x2500; __init__.py
&#x2502;   &#x2514;&#x2500;&#x2500; visualize.py
&#x251C;&#x2500;&#x2500; config.py
&#x251C;&#x2500;&#x2500; main.py
&#x251C;&#x2500;&#x2500; README.md
</code></pre>
<p><strong>&#x6570;&#x636E;&#x52A0;&#x8F7D;&#x6A21;&#x5757;</strong></p>
<pre><code class="lang-python"><span class="hljs-comment">#dataset.py</span>
<span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data 

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TensorDataset</span><span class="hljs-params">(data.Dataset)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;Dataset wrapping data and target tensors.
    Each sample will be retrieved by indexing both tensors along the first
    dimension.
    Arguments:
        data_tensor (Tensor): contains sample data.
        target_tensor (Tensor): contains sample targets (labels).
    &quot;&quot;&quot;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, data_tensor, target_tensor)</span>:</span>
        <span class="hljs-keyword">assert</span> data_tensor.size(<span class="hljs-number">0</span>) == target_tensor.size(<span class="hljs-number">0</span>)
        self.data_tensor = data_tensor
        self.target_tensor = target_tensor

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, index)</span>:</span>
        <span class="hljs-keyword">return</span> self.data_tensor[index], self.target_tensor[index]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> len(self.data_tensor)
</code></pre>
<p><strong>&#x6A21;&#x578B;&#x5B9A;&#x4E49;&#x6A21;&#x5757;</strong></p>
<pre><code class="lang-python"><span class="hljs-comment"># coding: utf-8</span>


<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> time


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BasicModule</span><span class="hljs-params">(torch.nn.Module)</span>:</span>
    <span class="hljs-string">&apos;&apos;&apos;
    &#x5C01;&#x88C5;&#x4E86;nn.Module&#xFF0C;&#x4E3B;&#x8981;&#x63D0;&#x4F9B;save&#x548C;load&#x4E24;&#x4E2A;&#x65B9;&#x6CD5;
    &apos;&apos;&apos;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,opt=None)</span>:</span>
        super(BasicModule,self).__init__()
        self.model_name = str(type(self)) <span class="hljs-comment"># &#x6A21;&#x578B;&#x7684;&#x9ED8;&#x8BA4;&#x540D;&#x5B57;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load</span><span class="hljs-params">(self, path)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x53EF;&#x52A0;&#x8F7D;&#x6307;&#x5B9A;&#x8DEF;&#x5F84;&#x7684;&#x6A21;&#x578B;
        &apos;&apos;&apos;</span>
        self.load_state_dict(torch.load(path))

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span><span class="hljs-params">(self, name=None)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4FDD;&#x5B58;&#x6A21;&#x578B;&#xFF0C;&#x9ED8;&#x8BA4;&#x4F7F;&#x7528;&#x201C;&#x6A21;&#x578B;&#x540D;&#x5B57;+&#x65F6;&#x95F4;&#x201D;&#x4F5C;&#x4E3A;&#x6587;&#x4EF6;&#x540D;&#xFF0C;
        &#x5982;AlexNet_0710_23:57:29.pth
        &apos;&apos;&apos;</span>
        <span class="hljs-keyword">if</span> name <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span>:
            prefix = <span class="hljs-string">&apos;checkpoints/&apos;</span> + self.model_name + <span class="hljs-string">&apos;_&apos;</span>
            name = time.strftime(prefix + <span class="hljs-string">&apos;%m%d_%H:%M:%S.pth&apos;</span>)
        torch.save(self.state_dict(), name)
        <span class="hljs-keyword">return</span> name
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment">#__init__.py</span>
<span class="hljs-keyword">from</span> .DeepSEA <span class="hljs-keyword">import</span> DeepSEA
<span class="hljs-comment">#from .new_module import NewModule</span>
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># coding: utf-8</span>

<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> .BasicModule <span class="hljs-keyword">import</span> BasicModule

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DeepSEA</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, sequence_length=<span class="hljs-number">500</span>, n_genomic_features=<span class="hljs-number">2</span>)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        Parameters
        ----------
        sequence_length : int
        n_genomic_features : int
        &quot;&quot;&quot;</span>
        super(DeepSEA, self).__init__()
        conv_kernel_size = <span class="hljs-number">8</span>
        pool_kernel_size = <span class="hljs-number">4</span>

        self.conv_net = nn.Sequential(
            nn.Conv1d(<span class="hljs-number">4</span>, <span class="hljs-number">320</span>, kernel_size=conv_kernel_size),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=<span class="hljs-number">0.2</span>),

            nn.Conv1d(<span class="hljs-number">320</span>, <span class="hljs-number">480</span>, kernel_size=conv_kernel_size),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.MaxPool1d(
                kernel_size=pool_kernel_size, stride=pool_kernel_size),
            nn.Dropout(p=<span class="hljs-number">0.2</span>),

            nn.Conv1d(<span class="hljs-number">480</span>, <span class="hljs-number">960</span>, kernel_size=conv_kernel_size),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.Dropout(p=<span class="hljs-number">0.5</span>))

        reduce_by = conv_kernel_size - <span class="hljs-number">1</span>

        self.n_channels = int(
            np.floor(
                (np.floor(
                    (sequence_length - reduce_by) / pool_kernel_size)
                 - reduce_by) / pool_kernel_size)
            - reduce_by)
        self.classifier = nn.Sequential(
            nn.Linear(<span class="hljs-number">960</span> * self.n_channels, n_genomic_features),
            nn.ReLU(inplace=<span class="hljs-keyword">True</span>),
            nn.Linear(n_genomic_features, n_genomic_features),
            nn.Sigmoid()
        )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;Forward propagation of a batch.
        &quot;&quot;&quot;</span>
        out = self.conv_net(x)
        reshape_out = out.view(out.size(<span class="hljs-number">0</span>), <span class="hljs-number">960</span> * self.n_channels)
        predict = self.classifier(reshape_out)
        <span class="hljs-keyword">return</span> predict
</code></pre>
<p><strong>&#x5DE5;&#x5177;&#x51FD;&#x6570;</strong></p>
<pre><code class="lang-python"><span class="hljs-comment">#coding:utf8</span>
<span class="hljs-comment">#visualize.py</span>
<span class="hljs-keyword">import</span> visdom
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Visualizer</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-string">&apos;&apos;&apos;
    &#x5C01;&#x88C5;&#x4E86;visdom&#x7684;&#x57FA;&#x672C;&#x64CD;&#x4F5C;&#xFF0C;&#x4F46;&#x662F;&#x4F60;&#x4ECD;&#x7136;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;`self.vis.function`
    &#x6216;&#x8005;`self.function`&#x8C03;&#x7528;&#x539F;&#x751F;&#x7684;visdom&#x63A5;&#x53E3;
    &#x6BD4;&#x5982; 
    self.text(&apos;hello visdom&apos;)
    self.histogram(t.randn(1000))
    self.line(t.arange(0, 10),t.arange(1, 11))
    &apos;&apos;&apos;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, env=<span class="hljs-string">&apos;default&apos;</span>, **kwargs)</span>:</span>
        self.vis = visdom.Visdom(env=env, **kwargs)

       <span class="hljs-comment"># &#x753B;&#x7684;&#x7B2C;&#x51E0;&#x4E2A;&#x6570;&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x6A2A;&#x5750;&#x6807;</span>
       <span class="hljs-comment"># &#x6BD4;&#x5982;&#xFF08;&#x2019;loss&apos;,23&#xFF09; &#x5373;loss&#x7684;&#x7B2C;23&#x4E2A;&#x70B9;</span>
        self.index = {}
        self.log_text = <span class="hljs-string">&apos;&apos;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reinit</span><span class="hljs-params">(self, env=<span class="hljs-string">&apos;default&apos;</span>, **kwargs)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4FEE;&#x6539;visdom&#x7684;&#x914D;&#x7F6E;
        &apos;&apos;&apos;</span>
        self.vis = visdom.Visdom(env=env, **kwargs)
        <span class="hljs-keyword">return</span> self

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_many</span><span class="hljs-params">(self, d)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4E00;&#x6B21;plot&#x591A;&#x4E2A;
        @params d: dict (name, value) i.e. (&apos;loss&apos;, 0.11)
        &apos;&apos;&apos;</span>
        <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> d.iteritems():
            self.plot(k, v)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img_many</span><span class="hljs-params">(self, d)</span>:</span>
        <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> d.iteritems():
            self.img(k, v)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot</span><span class="hljs-params">(self, name, y, **kwargs)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        self.plot(&apos;loss&apos;, 1.00)
        &apos;&apos;&apos;</span>
        x = self.index.get(name, <span class="hljs-number">0</span>)
        self.vis.line(Y=np.array([y]), X=np.array([x]),
                     win=unicode(name),
                     opts=dict(title=name),
                     update=<span class="hljs-keyword">None</span> <span class="hljs-keyword">if</span> x == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&apos;append&apos;</span>,
                     **kwargs
                     )
        self.index[name] = x + <span class="hljs-number">1</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img</span><span class="hljs-params">(self, name, img_, **kwargs)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        self.img(&apos;input_img&apos;, t.Tensor(64, 64))
        self.img(&apos;input_imgs&apos;, t.Tensor(3, 64, 64))
        self.img(&apos;input_imgs&apos;, t.Tensor(100, 1, 64, 64))
        self.img(&apos;input_imgs&apos;, t.Tensor(100, 3, 64, 64), nrows=10)
        &apos;&apos;&apos;</span>
        self.vis.images(img_.cpu().numpy(),
                      win=unicode(name),
                      opts=dict(title=name),
                      **kwargs
                      )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log</span><span class="hljs-params">(self, info, win=<span class="hljs-string">&apos;log_text&apos;</span>)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        self.log({&apos;loss&apos;:1, &apos;lr&apos;:0.0001})
        &apos;&apos;&apos;</span>

        self.log_text += (<span class="hljs-string">&apos;[{time}] {info} &lt;br&gt;&apos;</span>.format(
                           time=time.strftime(<span class="hljs-string">&apos;%m%d_%H%M%S&apos;</span>),\
                           info=info))
        self.vis.text(self.log_text, win)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getattr__</span><span class="hljs-params">(self, name)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        self.function &#x7B49;&#x4EF7;&#x4E8E;self.vis.function
        &#x81EA;&#x5B9A;&#x4E49;&#x7684;plot,image,log,plot_many&#x7B49;&#x9664;&#x5916;
        &apos;&apos;&apos;</span>
        <span class="hljs-keyword">return</span> getattr(self.vis, name)
</code></pre>
<p><strong>&#x914D;&#x7F6E;&#x6587;&#x4EF6;</strong></p>
<pre><code class="lang-python"><span class="hljs-comment">#config.py</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DefaultConfig</span><span class="hljs-params">(object)</span>:</span>
    env = <span class="hljs-string">&apos;default&apos;</span> <span class="hljs-comment"># visdom &#x73AF;&#x5883;</span>
    model = <span class="hljs-string">&apos;DeepSEA&apos;</span> <span class="hljs-comment"># &#x4F7F;&#x7528;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x540D;&#x5B57;&#x5FC5;&#x987B;&#x4E0E;models/__init__.py&#x4E2D;&#x7684;&#x540D;&#x5B57;&#x4E00;&#x81F4;</span>

    train_data_root = <span class="hljs-string">&apos;./data/one_hot_10w_sh.npy&apos;</span> <span class="hljs-comment"># &#x8BAD;&#x7EC3;&#x96C6;&#x5B58;&#x653E;&#x8DEF;&#x5F84;</span>
    test_data_root = <span class="hljs-string">&apos;./data/test1&apos;</span> <span class="hljs-comment"># &#x6D4B;&#x8BD5;&#x96C6;&#x5B58;&#x653E;&#x8DEF;&#x5F84;</span>
    target_data_root = <span class="hljs-string">&apos;./data/target_10w_sh.txt&apos;</span>
    load_model_path = <span class="hljs-string">&apos;checkpoints/model.pth&apos;</span> <span class="hljs-comment"># &#x52A0;&#x8F7D;&#x9884;&#x8BAD;&#x7EC3;&#x7684;&#x6A21;&#x578B;&#x7684;&#x8DEF;&#x5F84;&#xFF0C;&#x4E3A;None&#x4EE3;&#x8868;&#x4E0D;&#x52A0;&#x8F7D;</span>

    batch_size = <span class="hljs-number">256</span> <span class="hljs-comment"># batch size</span>
    use_gpu = <span class="hljs-keyword">True</span> <span class="hljs-comment"># use GPU or not</span>
    num_workers = <span class="hljs-number">2</span> <span class="hljs-comment"># how many workers for loading data</span>
    print_freq = <span class="hljs-number">20</span> <span class="hljs-comment"># print info every N batch</span>
    <span class="hljs-comment">#debug_file = &apos;/tmp/debug&apos; # if os.path.exists(debug_file): enter ipdb</span>
    result_file = <span class="hljs-string">&apos;result.csv&apos;</span>

    num_epochs = <span class="hljs-number">10</span>
    lr = <span class="hljs-number">0.01</span> <span class="hljs-comment"># initial learning rate</span>
    lr_decay = <span class="hljs-number">0.95</span> <span class="hljs-comment"># when val_loss increase, lr = lr*lr_decay</span>
    weight_decay = <span class="hljs-number">1e-4</span> <span class="hljs-comment"># &#x635F;&#x5931;&#x51FD;&#x6570;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, kwargs)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x6839;&#x636E;&#x5B57;&#x5178;kwargs &#x66F4;&#x65B0; config&#x53C2;&#x6570;
        &apos;&apos;&apos;</span>
        <span class="hljs-comment"># &#x66F4;&#x65B0;&#x914D;&#x7F6E;&#x53C2;&#x6570;</span>
        <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> kwargs.items():
            <span class="hljs-string">&apos;&apos;&apos;
            if not hasattr(self, k):
                # &#x8B66;&#x544A;&#x8FD8;&#x662F;&#x62A5;&#x9519;&#xFF0C;&#x53D6;&#x51B3;&#x4E8E;&#x4F60;&#x4E2A;&#x4EBA;&#x7684;&#x559C;&#x597D;

                warnings.warn(&quot;Warning: opt has not attribut %s&quot; %k)
            &apos;&apos;&apos;</span>
            setattr(self, k, v)

        <span class="hljs-comment"># &#x6253;&#x5370;&#x914D;&#x7F6E;&#x4FE1;&#x606F;  </span>
        print(<span class="hljs-string">&apos;user config:&apos;</span>)
        <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.__class__.__dict__.items():
            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> k.startswith(<span class="hljs-string">&apos;__&apos;</span>):
                print(k, getattr(self, k))

DefaultConfig.parse = parse
opt =DefaultConfig()
</code></pre>
<p><strong>&#x4E3B;&#x51FD;&#x6570;</strong></p>
<pre><code class="lang-python"><span class="hljs-comment">#main.py</span>
<span class="hljs-keyword">from</span> config <span class="hljs-keyword">import</span> opt
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data
<span class="hljs-keyword">import</span> models
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> data.dataset <span class="hljs-keyword">import</span> TensorDataset
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-comment">#from torch.autograd import Variable</span>
<span class="hljs-comment">#from torchnet import meter</span>
<span class="hljs-comment">#from utils.visualize import Visualizer</span>
<span class="hljs-comment">#from tqdm import tqdm</span>
<span class="hljs-keyword">import</span> time




<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluate_accuracy</span><span class="hljs-params">(data_iter, net, device=None)</span>:</span>
    <span class="hljs-keyword">if</span> device <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span> <span class="hljs-keyword">and</span> isinstance(net, torch.nn.Module):
        <span class="hljs-comment"># &#x5982;&#x679C;&#x6CA1;&#x6307;&#x5B9A;device&#x5C31;&#x4F7F;&#x7528;net&#x7684;device</span>
        device = list(net.parameters())[<span class="hljs-number">0</span>].device
    acc_sum, n = <span class="hljs-number">0.0</span>, <span class="hljs-number">0</span>
    <span class="hljs-keyword">with</span> torch.no_grad():
        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:
            <span class="hljs-string">&apos;&apos;&apos;
            if isinstance(net, torch.nn.Module):
                net.eval() # &#x8BC4;&#x4F30;&#x6A21;&#x5F0F;, &#x8FD9;&#x4F1A;&#x5173;&#x95ED;dropout
                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()
                net.train() # &#x6539;&#x56DE;&#x8BAD;&#x7EC3;&#x6A21;&#x5F0F;
            else: 
                if(&apos;is_training&apos; in net.__code__.co_varnames): # &#x5982;&#x679C;&#x6709;is_training&#x8FD9;&#x4E2A;&#x53C2;&#x6570;
                    # &#x5C06;is_training&#x8BBE;&#x7F6E;&#x6210;False
                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() 
                else:
                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()
            &apos;&apos;&apos;</span>
            acc_sum += (net(X.to(device)).argmax(dim=<span class="hljs-number">1</span>) == (y.to(device).squeeze())).float().sum().cpu().item()
            n += y.shape[<span class="hljs-number">0</span>]

    <span class="hljs-keyword">return</span> acc_sum / n



<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(**kwargs)</span>:</span>
    opt.parse(kwargs)
    <span class="hljs-comment">#vis = Visualizer(opt.env)</span>

    model = getattr(models, opt.model)()

    <span class="hljs-string">&apos;&apos;&apos;
    if opt.load_model_path:
        model.load(opt.load_model_path)
    if opt.use_gpu: model.cuda()
    &apos;&apos;&apos;</span>
    device = torch.device(<span class="hljs-string">&apos;cuda&apos;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&apos;cpu&apos;</span>)
    print(<span class="hljs-string">&quot;training on &quot;</span>, device)

    data_np = np.load(opt.train_data_root)
    data_tensor = torch.from_numpy(data_np)

    target_pd =pd.read_csv(opt.target_data_root,sep = <span class="hljs-string">&apos;\n&apos;</span>,header = <span class="hljs-keyword">None</span>)
    target_array = np.array(target_pd)
    target_tensor = torch.tensor(target_array)

    data_tensor = data_tensor.reshape(<span class="hljs-number">100000</span>,<span class="hljs-number">4</span>,<span class="hljs-number">500</span>)
    data_tensor = data_tensor.float()
    target_tenor = target_tensor.float()

    train_data = TensorDataset(data_tensor[<span class="hljs-number">0</span>:<span class="hljs-number">99000</span>], target_tensor[<span class="hljs-number">0</span>:<span class="hljs-number">99000</span>])
    val_data = TensorDataset(data_tensor[<span class="hljs-number">99000</span>:<span class="hljs-number">100000</span>], target_tensor[<span class="hljs-number">99000</span>:<span class="hljs-number">100000</span>])
    train_dataloader = data.DataLoader(train_data,batch_size = <span class="hljs-number">200</span>,
                        shuffle=<span class="hljs-keyword">True</span>,num_workers=<span class="hljs-number">0</span>)
    val_dataloader = data.DataLoader(val_data,batch_size = <span class="hljs-number">200</span>,
                        shuffle=<span class="hljs-keyword">False</span>,num_workers=<span class="hljs-number">0</span>)

    loss = torch.nn.CrossEntropyLoss()
    lr = opt.lr
    optimizer = torch.optim.SGD(model.parameters(),
                                lr=lr,
                                weight_decay = opt.weight_decay)




    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(opt.num_epochs):
        model = model.to(device)
        train_l_sum, train_acc_sum, n, batch_count, start = <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, time.time()
        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_dataloader:
            X = X.to(device)
            y = y.to(device)
            y_hat = model(X)
            y = y.squeeze()
            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.cpu().item()
            train_acc_sum += (y_hat.argmax(dim=<span class="hljs-number">1</span>) == y).sum().cpu().item()
            n += y.shape[<span class="hljs-number">0</span>]
            batch_count += <span class="hljs-number">1</span>
        test_acc = evaluate_accuracy(val_dataloader, model)
        print(<span class="hljs-string">&apos;epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec&apos;</span>
              % (epoch + <span class="hljs-number">1</span>, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))


        <span class="hljs-comment">#model.save()</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">val</span><span class="hljs-params">(model, dataloader)</span>:</span>
    <span class="hljs-string">&apos;&apos;&apos;
    &#x8BA1;&#x7B97;&#x6A21;&#x578B;&#x5728;&#x9A8C;&#x8BC1;&#x96C6;&#x4E0A;&#x7684;&#x51C6;&#x786E;&#x7387;&#x7B49;&#x4FE1;&#x606F;&#xFF0C;&#x7528;&#x4EE5;&#x8F85;&#x52A9;&#x8BAD;&#x7EC3;
    &apos;&apos;&apos;</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span><span class="hljs-params">(**kwargs)</span>:</span>
    <span class="hljs-string">&apos;&apos;&apos;
    &#x6D4B;&#x8BD5;&#xFF08;inference&#xFF09;
    &apos;&apos;&apos;</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">help</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-string">&apos;&apos;&apos;
    &#x6253;&#x5370;&#x5E2E;&#x52A9;&#x7684;&#x4FE1;&#x606F; 
    &apos;&apos;&apos;</span>
    print(<span class="hljs-string">&apos;help&apos;</span>)

<span class="hljs-keyword">if</span> __name__==<span class="hljs-string">&apos;__main__&apos;</span>:
    <span class="hljs-keyword">import</span> fire
    fire.Fire()
</code></pre>
<p>&#x5355;&#x4E2A;&#x7EC4;&#x86CB;&#x767D;&#x4FEE;&#x9970;&#x6570;&#x636E;&#x96C6;&#x6784;&#x5EFA;</p>
<p>&#x7EC4;&#x86CB;&#x767D;&#x4FEE;&#x9970;&#x6587;&#x732E;&#x9605;&#x8BFB;</p>
<h3 id="deephistone">DeepHistone</h3>
<p><a href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-5489-4#Sec9" target="_blank">https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-5489-4#Sec9</a></p>
<p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12864-019-5489-4/MediaObjects/12864_2019_5489_Fig1_HTML.png" alt="Fig. 1"></p>
<p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12864-019-5489-4/MediaObjects/12864_2019_5489_Fig2_HTML.png" alt="Fig. 2" style="zoom:50%;"></p>
<p>DenseNet</p>
<p>labels onehot encoder</p>
<p>&#x53EF;&#x4EE5;&#x5C06;&#x6B64;&#x51FD;&#x6570;&#x52A0;&#x5165;OneHotEncoder</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dense_to_one_hot</span><span class="hljs-params">(labels_dense, num_classes)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;Convert class labels from scalars to one-hot vectors.&quot;&quot;&quot;</span>
    num_labels = labels_dense.shape[<span class="hljs-number">0</span>]
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset+labels_dense.ravel()] = <span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> labels_one_hot

labels_dense = np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]) 
num_classes  = <span class="hljs-number">5</span>
dense_to_one_hot(labels_dense,num_classes)
</code></pre>
<p>&#x7EE7;&#x7EED;&#x6539;&#x8FDB;target_mark : &#x5C06;&#x7EC4;&#x86CB;&#x767D;&#x4FEE;&#x9970;&#xFF08;m&#xFF09;&#x4E0E;&#x6570;&#x5B57;&#x6807;&#x7B7E;&#x5BF9;&#x5E94;&#xFF0C;&#x540C;&#x65F6;<strong>&#x6539;&#x826F;&#x6BCF;&#x79CD;&#x7EC4;&#x86CB;&#x767D;&#x7684;&#x6807;&#x8BB0;&#x65B9;&#x6CD5;</strong></p>
<p>npz&#x5C01;&#x88C5;&#xFF1A;&#x5C06;npz&#x5C01;&#x88C5;&#x4E5F;&#x52A0;&#x5165;OneHotEncoder&#xFF0C;&#x52A0;&#x5165;&#x5230;make</p>
<pre><code class="lang-python">np.savez(<span class="hljs-string">&apos;C:/Users/12394/PycharmProjects/Spyder/data.npz&apos;</span>,a = a, b = b)
</code></pre>
<p>bash&#x811A;&#x672C;</p>
<p>1.&#x5C06;5&#x79CD;&#x7EC4;&#x86CB;&#x767D;&#x4FEE;&#x9970;&#x9633;&#x6027;&#x6837;&#x672C;&#x96C6;&#x4E2D;&#x5728;&#x4E00;&#x4E2A;&#x6570;&#x636E;&#x96C6;</p>
<p>2.reshape(len(data),1,4,500)</p>
<p>3.&#x5148;&#x62FF;&#x4E00;&#x4E2A;&#x54C1;&#x79CD;&#x5236;&#x4F5C;&#x6570;&#x636E;&#x96C6;</p>
<p>labels_make.sh</p>
<p>OneHotEncoder3.0.py&#x5B8C;&#x6210;</p>
<p>&#x52A0;&#x5165;&#x5220;&#x9664;&#xFF08;n,1,6)&#x4E2D;&#x7684;&#x7B2C;&#x4E00;&#x5217;&#xFF0C;&#x53D8;&#x4E3A;&#xFF08;n,1,5)</p>
<pre><code class="lang-shell">bsub -q high -e 12.err -o 12.out &apos;python3 scripts/py_scripts/OneHotEncoder3.0.py -i dataset_ex1_10w.txt -c make -m ex1 -n 10w&apos;
</code></pre>
<table>
<thead>
<tr>
<th>Keys</th>
<th>DNA seq</th>
<th>labels</th>
</tr>
</thead>
<tbody>
<tr>
<td>(nums,)</td>
<td>(nums, 1 , 4 , 500 )</td>
<td>(nums ,1, 5)</td>
</tr>
<tr>
<td>species_histone_chr_start_end</td>
<td>onehot</td>
<td>onehot</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="dna-only"><strong>DNA-only</strong></h4>
<pre><code>

</code></pre><p>geno_sub3.0.py(&#x52A0;&#x4E0A;keys)</p>
<p>.npz ([&apos;keys&apos;, &apos;dna&apos;, &apos;labels&apos;])</p>
<p><strong>DNase</strong>&#xFF08;openness score&#xFF09;</p>
<p><img src="C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20210331205505975.png" alt="image-20210331205505975"></p>
<p><strong>model_dna.py</strong></p>
<p><a href="https://ieeexplore.ieee.org/document/8099726" target="_blank">https://ieeexplore.ieee.org/document/8099726</a></p>
<p>&#x4E09;&#x4E2A;&#x6A21;&#x5757;&#xFF1A;DNA module &#xFF0C;DNase module&#xFF0C; joint module</p>
<p>DNA and DNase module&#xFF1A; <strong>densely connected</strong> convolutional neural network</p>
<p>joint module&#xFF1A; distinguish histone modification sites of a marker from those of other markers</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics
<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span>  Optimizer
<span class="hljs-keyword">import</span> math 
<span class="hljs-keyword">from</span> torch.nn.parameter <span class="hljs-keyword">import</span> Parameter

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BasicBlock</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, in_planes, grow_rate,)</span>:</span>
        super(BasicBlock, self).__init__()
        self.block = nn.Sequential(
            nn.BatchNorm2d(in_planes),
            nn.ReLU(),
            nn.Conv2d(in_planes, grow_rate, (<span class="hljs-number">1</span>,<span class="hljs-number">9</span>), <span class="hljs-number">1</span>, (<span class="hljs-number">0</span>,<span class="hljs-number">4</span>)),
            <span class="hljs-comment">#nn.Dropout2d(0.2)</span>
        )
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        out = self.block(x)
        <span class="hljs-keyword">return</span> torch.cat([x, out],<span class="hljs-number">1</span>)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DenseBlock</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, nb_layers, in_planes, grow_rate,)</span>:</span>
        super(DenseBlock, self).__init__()
        layers = []
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(nb_layers):
            layers.append(BasicBlock(in_planes + i*grow_rate, grow_rate,))
        self.layer = nn.Sequential(*layers)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-keyword">return</span> self.layer(x)


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ModuleDense</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(ModuleDense, self).__init__()


        self.conv1 = nn.Sequential(
            nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">128</span>,(<span class="hljs-number">4</span>,<span class="hljs-number">9</span>),<span class="hljs-number">1</span>,(<span class="hljs-number">0</span>,<span class="hljs-number">4</span>)),
            <span class="hljs-comment">#nn.Dropout2d(0.2),</span>
            )

        self.block1 = DenseBlock(<span class="hljs-number">3</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>)    
        self.trans1 = nn.Sequential(
            nn.BatchNorm2d(<span class="hljs-number">128</span>+<span class="hljs-number">3</span>*<span class="hljs-number">128</span>),
            nn.ReLU(),
            nn.Conv2d(<span class="hljs-number">128</span>+<span class="hljs-number">3</span>*<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),<span class="hljs-number">1</span>),
            <span class="hljs-comment">#nn.Dropout2d(0.2),</span>
            nn.MaxPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">4</span>)),
        )
        self.block2 = DenseBlock(<span class="hljs-number">3</span>,<span class="hljs-number">256</span>,<span class="hljs-number">256</span>)
        self.trans2 = nn.Sequential(
            nn.BatchNorm2d(<span class="hljs-number">256</span>+<span class="hljs-number">3</span>*<span class="hljs-number">256</span>),
            nn.ReLU(),
            nn.Conv2d(<span class="hljs-number">256</span>+<span class="hljs-number">3</span>*<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),<span class="hljs-number">1</span>),
            <span class="hljs-comment">#nn.Dropout2d(0.2),</span>
            nn.MaxPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">4</span>)),
        )
        self.out_size = <span class="hljs-number">500</span> // <span class="hljs-number">4</span> // <span class="hljs-number">4</span>  * <span class="hljs-number">512</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, seq)</span>:</span>
        n, h, w = seq.size()

        seq = seq.view(n,<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,w)

        out = self.conv1(seq)
        out = self.block1(out)
        out = self.trans1(out)
        out = self.block2(out)
        out = self.trans2(out)
        n, c, h, w = out.size()
        out = out.view(n,c*h*w) 
        <span class="hljs-keyword">return</span> out


<span class="hljs-comment">#NetDeepHistone&#x7C7B;&#x624D;&#x662F;model</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NetDeepHistone</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(NetDeepHistone, self).__init__()
        print(<span class="hljs-string">&apos;DeepHistone(Dense) is used.&apos;</span>)
        self.seq_map = ModuleDense()
        self.seq_len = self.seq_map.out_size
        seq_len = self.seq_len

        self.linear_map = nn.Sequential(
            nn.Dropout(<span class="hljs-number">0.5</span>),
            nn.Linear(int(seq_len),<span class="hljs-number">925</span>),
            nn.BatchNorm1d(<span class="hljs-number">925</span>),
            nn.ReLU(),
            <span class="hljs-comment">#nn.Dropout(0.1),</span>
            nn.Linear(<span class="hljs-number">925</span>,<span class="hljs-number">5</span>),
            nn.Sigmoid(),
        )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, seq)</span>:</span>
        flat_seq = self.seq_map(seq)    
        out = self.linear_map(flat_seq)
        <span class="hljs-keyword">return</span> out

<span class="hljs-comment">#&#x5C01;&#x88C5;&#x4E86;&#x8BAD;&#x7EC3;&#x9A8C;&#x8BC1;&#x548C;&#x6D4B;&#x8BD5;&#xFF0C;&#x4FDD;&#x5B58;&#x52A0;&#x8F7D;&#x6A21;&#x578B;&#x7684;&#x51FD;&#x6570;</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DeepHistone</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,use_gpu,learning_rate=<span class="hljs-number">0.001</span>)</span>:</span>
        self.forward_fn = NetDeepHistone()
        self.criterion  = nn.BCELoss()
        self.optimizer  = optim.Adam(self.forward_fn.parameters(), lr=learning_rate, weight_decay = <span class="hljs-number">0</span>)
        self.use_gpu    = use_gpu
        <span class="hljs-keyword">if</span> self.use_gpu : self.criterion,self.forward_fn = self.criterion.cuda(), self.forward_fn.cuda()

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateLR</span><span class="hljs-params">(self, fold)</span>:</span>
        <span class="hljs-keyword">for</span> param_group <span class="hljs-keyword">in</span> self.optimizer.param_groups:
            param_group[<span class="hljs-string">&apos;lr&apos;</span>] *= fold

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_on_batch</span><span class="hljs-params">(self,seq_batch,lab_batch,)</span>:</span> 
        self.forward_fn.train()
        seq_batch  = Variable(torch.Tensor(seq_batch))
        lab_batch  = Variable(torch.Tensor(lab_batch))
        <span class="hljs-keyword">if</span> self.use_gpu: seq_batch, lab_batch = seq_batch.cuda(), lab_batch.cuda()
        output = self.forward_fn(seq_batch)
        loss = self.criterion(output,lab_batch)
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        <span class="hljs-keyword">return</span> loss.cpu().data

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">eval_on_batch</span><span class="hljs-params">(self,seq_batch,lab_batch,)</span>:</span>
        self.forward_fn.eval()
        seq_batch  = Variable(torch.Tensor(seq_batch))
        lab_batch  = Variable(torch.Tensor(lab_batch))
        <span class="hljs-keyword">if</span> self.use_gpu: seq_batch,  lab_batch = seq_batch.cuda(), lab_batch.cuda()
        output = self.forward_fn(seq_batch)
        loss = self.criterion(output,lab_batch)
        <span class="hljs-keyword">return</span> loss.cpu().data,output.cpu().data.numpy()

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_on_batch</span><span class="hljs-params">(self, seq_batch)</span>:</span>
        self.forward_fn.eval()
        seq_batch  = Variable(torch.Tensor(seq_batch))
        <span class="hljs-keyword">if</span> self.use_gpu: seq_batch = seq_batch.cuda()
        output = self.forward_fn(seq_batch)
        pred = output.cpu().data.numpy()
        <span class="hljs-keyword">return</span> pred

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_model</span><span class="hljs-params">(self, path)</span>:</span>
        torch.save(self.forward_fn.state_dict(), path)


    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_model</span><span class="hljs-params">(self, path)</span>:</span>
        self.forward_fn.load_state_dict(torch.load(path))
</code></pre>
<p><strong>untils_dna.py</strong></p>
<p>&#x5728;&#x539F;&#x51FD;&#x6570;&#x7684;&#x57FA;&#x7840;&#x4E0A;&#x589E;&#x52A0;&#x4E86;MCC&#xFF0C;Specificity&#x548C;Sensitivity&#x7684;&#x8BA1;&#x7B97;&#x51FD;&#x6570;&#xFF0C;&#x73B0;&#x5728;&#x6709;&#x4E09;&#x4E2A;&#x5177;&#x4F53;&#x8BC4;&#x4F30;&#x6307;&#x6807;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> auc,roc_auc_score,precision_recall_curve
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
histones=[<span class="hljs-string">&apos;H3K4me3&apos;</span>,<span class="hljs-string">&apos;H3K27ac&apos;</span>,<span class="hljs-string">&apos;H3K4me1&apos;</span>,<span class="hljs-string">&apos;H3K27me3&apos;</span>,<span class="hljs-string">&apos;H3K9me2&apos;</span>]

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loadRegions</span><span class="hljs-params">(regions_indexs,dna_dict,label_dict,)</span>:</span>
    <span class="hljs-keyword">if</span> dna_dict <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        dna_regions = np.concatenate([dna_dict[meta]  <span class="hljs-keyword">for</span> meta <span class="hljs-keyword">in</span> regions_indexs],axis=<span class="hljs-number">0</span>)
    <span class="hljs-keyword">else</span>: dna_regions =[]

    label_regions = np.concatenate([label_dict[meta] <span class="hljs-keyword">for</span> meta <span class="hljs-keyword">in</span> regions_indexs],axis=<span class="hljs-number">0</span>).astype(int)
    <span class="hljs-keyword">return</span> dna_regions,label_regions

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_train</span><span class="hljs-params">(regions,model,batchsize,dna_dict,label_dict,)</span>:</span>
    train_loss = []
    regions_len = len(regions)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, regions_len , batchsize):
        regions_batch = [regions[i+j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(batchsize) <span class="hljs-keyword">if</span> (i+j) &lt; regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _loss= model.train_on_batch(seq_batch, lab_batch)
        train_loss.append(_loss)
    <span class="hljs-keyword">return</span> np.mean(train_loss) 

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_eval</span><span class="hljs-params">(regions,model,batchsize,dna_dict,label_dict,)</span>:</span>
    loss = []
    pred =[]
    lab =[]
    regions_len = len(regions)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, regions_len , batchsize):
        regions_batch = [regions[i+j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(batchsize) <span class="hljs-keyword">if</span> (i+j) &lt; regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _loss,_pred = model.eval_on_batch(seq_batch, lab_batch)
        loss.append(_loss)
        lab.extend(lab_batch)
        pred.extend(_pred)
    <span class="hljs-keyword">return</span> np.mean(loss), np.array(lab),np.array(pred)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_predict</span><span class="hljs-params">(regions,model,batchsize,dna_dict,label_dict,)</span>:</span>
    lab  = []
    pred = []
    regions_len = len(regions)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(regions), batchsize):
        regions_batch = [regions[i+j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(batchsize) <span class="hljs-keyword">if</span> (i+j) &lt; regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _pred = model.test_on_batch(seq_batch)
        lab.extend(lab_batch)
        pred.extend(_pred)        
    <span class="hljs-keyword">return</span> np.array(lab), np.array(pred) 


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">ROC</span><span class="hljs-params">(label,pred)</span>:</span>
    <span class="hljs-keyword">if</span> len(np.unique(np.array(label).reshape(<span class="hljs-number">-1</span>)))  == <span class="hljs-number">1</span>:
        print(<span class="hljs-string">&quot;all the labels are the same !&quot;</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
    <span class="hljs-keyword">else</span>:
        label = np.array(label).reshape(<span class="hljs-number">-1</span>)
        pred = np.array(pred).reshape(<span class="hljs-number">-1</span>)
        <span class="hljs-keyword">return</span> roc_auc_score(label,pred)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">auPR</span><span class="hljs-params">(label,pred)</span>:</span>
    <span class="hljs-keyword">if</span> len(np.unique(np.array(label).reshape(<span class="hljs-number">-1</span>)))  == <span class="hljs-number">1</span>:
        print(<span class="hljs-string">&quot;all the labels are the same !&quot;</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
    <span class="hljs-keyword">else</span>:
        label = np.array(label).reshape(<span class="hljs-number">-1</span>)
        pred = np.array(pred).reshape(<span class="hljs-number">-1</span>)
        precision, recall, thresholds = precision_recall_curve(label,pred)
        <span class="hljs-keyword">return</span> auc(recall,precision)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">metrics</span><span class="hljs-params">(lab,pred,Type=<span class="hljs-string">&apos;test&apos;</span>,loss=None)</span>:</span>
        <span class="hljs-keyword">if</span> Type == <span class="hljs-string">&apos;Valid&apos;</span>:
            training_color = <span class="hljs-string">&apos;\033[0;34m&apos;</span>
        <span class="hljs-keyword">elif</span> Type == <span class="hljs-string">&apos;Test&apos;</span>:
            training_color = <span class="hljs-string">&apos;\033[0;35m&apos;</span>
        <span class="hljs-keyword">else</span>:
            training_color = <span class="hljs-string">&apos;\033[0;36m&apos;</span>

        auPRC_dict={}
        auROC_dict ={}
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(histones)):
            auPRC_dict[histones[i]] = auPR(lab[:,i],pred[:,i])
            auROC_dict[histones[i]] = ROC(lab[:,i],pred[:,i])

        print_str = training_color + <span class="hljs-string">&apos;\t%s\t%s\tauROC : %.4f,auPRC : %.4f\033[0m&apos;</span>
        print(<span class="hljs-string">&apos;-&apos;</span>*<span class="hljs-number">25</span>+Type+<span class="hljs-string">&apos;-&apos;</span>*<span class="hljs-number">25</span>)
        <span class="hljs-keyword">if</span> loss <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>: loss_str = <span class="hljs-string">&apos;,Loss : %.4f&apos;</span>%loss
        <span class="hljs-keyword">else</span> :loss_str =<span class="hljs-string">&apos;&apos;</span>
        print(<span class="hljs-string">&apos;\033[0;36m%s\tTotalMean\tauROC : %.4f,auPRC : %.4f%s\033[0m&apos;</span>%(Type,np.mean(list(auROC_dict.values())),np.mean(list(auPRC_dict.values())),loss_str) )
        <span class="hljs-keyword">for</span> histone <span class="hljs-keyword">in</span> histones:
                print(print_str%(Type,histone.ljust(<span class="hljs-number">10</span>),auROC_dict[histone],auPRC_dict[histone]))
        <span class="hljs-keyword">return</span> auPRC_dict,auROC_dict
[xwli@mn02 deepHistone]$ cat utils_dna.py 
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> auc,roc_auc_score,precision_recall_curve
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
histones=[<span class="hljs-string">&apos;H3K4me3&apos;</span>,<span class="hljs-string">&apos;H3K27ac&apos;</span>,<span class="hljs-string">&apos;H3K4me1&apos;</span>,<span class="hljs-string">&apos;H3K27me3&apos;</span>,<span class="hljs-string">&apos;H3K9me2&apos;</span>]

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loadRegions</span><span class="hljs-params">(regions_indexs,dna_dict,label_dict,)</span>:</span>
    <span class="hljs-keyword">if</span> dna_dict <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        dna_regions = np.concatenate([dna_dict[meta]  <span class="hljs-keyword">for</span> meta <span class="hljs-keyword">in</span> regions_indexs],axis=<span class="hljs-number">0</span>)
    <span class="hljs-keyword">else</span>: dna_regions =[]

    label_regions = np.concatenate([label_dict[meta] <span class="hljs-keyword">for</span> meta <span class="hljs-keyword">in</span> regions_indexs],axis=<span class="hljs-number">0</span>).astype(int)
    <span class="hljs-keyword">return</span> dna_regions,label_regions

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_train</span><span class="hljs-params">(regions,model,batchsize,dna_dict,label_dict,)</span>:</span>
    train_loss = []
    regions_len = len(regions)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, regions_len , batchsize):
        regions_batch = [regions[i+j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(batchsize) <span class="hljs-keyword">if</span> (i+j) &lt; regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _loss= model.train_on_batch(seq_batch, lab_batch)
        train_loss.append(_loss)
    <span class="hljs-keyword">return</span> np.mean(train_loss) 

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_eval</span><span class="hljs-params">(regions,model,batchsize,dna_dict,label_dict,)</span>:</span>
    loss = []
    pred =[]
    lab =[]
    regions_len = len(regions)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, regions_len , batchsize):
        regions_batch = [regions[i+j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(batchsize) <span class="hljs-keyword">if</span> (i+j) &lt; regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _loss,_pred = model.eval_on_batch(seq_batch, lab_batch)
        loss.append(_loss)
        lab.extend(lab_batch)
        pred.extend(_pred)
    <span class="hljs-keyword">return</span> np.mean(loss), np.array(lab),np.array(pred)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_predict</span><span class="hljs-params">(regions,model,batchsize,dna_dict,label_dict,)</span>:</span>
    lab  = []
    pred = []
    regions_len = len(regions)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(regions), batchsize):
        regions_batch = [regions[i+j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(batchsize) <span class="hljs-keyword">if</span> (i+j) &lt; regions_len]
        seq_batch ,lab_batch = loadRegions(regions_batch,dna_dict,label_dict)
        _pred = model.test_on_batch(seq_batch)
        lab.extend(lab_batch)
        pred.extend(_pred)        
    <span class="hljs-keyword">return</span> np.array(lab), np.array(pred) 


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">ROC</span><span class="hljs-params">(label,pred)</span>:</span>
    <span class="hljs-keyword">if</span> len(np.unique(np.array(label).reshape(<span class="hljs-number">-1</span>)))  == <span class="hljs-number">1</span>:
        print(<span class="hljs-string">&quot;all the labels are the same !&quot;</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
    <span class="hljs-keyword">else</span>:
        label = np.array(label).reshape(<span class="hljs-number">-1</span>)
        pred = np.array(pred).reshape(<span class="hljs-number">-1</span>)
        <span class="hljs-keyword">return</span> roc_auc_score(label,pred)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">auPR</span><span class="hljs-params">(label,pred)</span>:</span>
    <span class="hljs-keyword">if</span> len(np.unique(np.array(label).reshape(<span class="hljs-number">-1</span>)))  == <span class="hljs-number">1</span>:
        print(<span class="hljs-string">&quot;all the labels are the same !&quot;</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
    <span class="hljs-keyword">else</span>:
        label = np.array(label).reshape(<span class="hljs-number">-1</span>)
        pred = np.array(pred).reshape(<span class="hljs-number">-1</span>)
        precision, recall, thresholds = precision_recall_curve(label,pred)
        <span class="hljs-keyword">return</span> auc(recall,precision)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">metrics</span><span class="hljs-params">(lab,pred,Type=<span class="hljs-string">&apos;test&apos;</span>,loss=None)</span>:</span>
        <span class="hljs-keyword">if</span> Type == <span class="hljs-string">&apos;Valid&apos;</span>:
            training_color = <span class="hljs-string">&apos;\033[0;34m&apos;</span>
        <span class="hljs-keyword">elif</span> Type == <span class="hljs-string">&apos;Test&apos;</span>:
            training_color = <span class="hljs-string">&apos;\033[0;35m&apos;</span>
        <span class="hljs-keyword">else</span>:
            training_color = <span class="hljs-string">&apos;\033[0;36m&apos;</span>

        auPRC_dict={}
        auROC_dict ={}
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(histones)):
            auPRC_dict[histones[i]] = auPR(lab[:,i],pred[:,i])
            auROC_dict[histones[i]] = ROC(lab[:,i],pred[:,i])

        print_str = training_color + <span class="hljs-string">&apos;\t%s\t%s\tauROC : %.4f,auPRC : %.4f\033[0m&apos;</span>
        print(<span class="hljs-string">&apos;-&apos;</span>*<span class="hljs-number">25</span>+Type+<span class="hljs-string">&apos;-&apos;</span>*<span class="hljs-number">25</span>)
        <span class="hljs-keyword">if</span> loss <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>: loss_str = <span class="hljs-string">&apos;,Loss : %.4f&apos;</span>%loss
        <span class="hljs-keyword">else</span> :loss_str =<span class="hljs-string">&apos;&apos;</span>
        print(<span class="hljs-string">&apos;\033[0;36m%s\tTotalMean\tauROC : %.4f,auPRC : %.4f%s\033[0m&apos;</span>%(Type,np.mean(list(auROC_dict.values())),np.mean(list(auPRC_dict.values())),loss_str) )
        <span class="hljs-keyword">for</span> histone <span class="hljs-keyword">in</span> histones:
                print(print_str%(Type,histone.ljust(<span class="hljs-number">10</span>),auROC_dict[histone],auPRC_dict[histone]))
        <span class="hljs-keyword">return</span> auPRC_dict,auROC_dict
</code></pre>
<p><strong>train_dna.py</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> model_dna <span class="hljs-keyword">import</span> DeepHistone
<span class="hljs-keyword">import</span> copy
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> utils_dna <span class="hljs-keyword">import</span> metrics,model_train,model_eval,model_predict
<span class="hljs-keyword">import</span> torch
<span class="hljs-comment">#setting </span>
batchsize=<span class="hljs-number">20</span>
data_file = <span class="hljs-string">&apos;data/onehot_all_100w.npz&apos;</span>

model_save_file = <span class="hljs-string">&apos;results/model.txt&apos;</span>
lab_save_file =<span class="hljs-string">&apos;results/label.txt&apos;</span>
pred_save_file =<span class="hljs-string">&apos;results/pred.txt&apos;</span>

print(<span class="hljs-string">&apos;Begin loading data...&apos;</span>)
<span class="hljs-keyword">with</span> np.load(data_file) <span class="hljs-keyword">as</span> f:
    indexs = f[<span class="hljs-string">&apos;keys&apos;</span>]
    dna_dict = dict(zip(f[<span class="hljs-string">&apos;keys&apos;</span>],f[<span class="hljs-string">&apos;DNAseq&apos;</span>]))
    lab_dict = dict(zip(f[<span class="hljs-string">&apos;keys&apos;</span>],f[<span class="hljs-string">&apos;labels&apos;</span>]))
np.random.shuffle(indexs)
idx_len = len(indexs)
train_index=indexs[:int(idx_len*<span class="hljs-number">3</span>/<span class="hljs-number">5</span>)]
valid_index=indexs[int(idx_len*<span class="hljs-number">3</span>/<span class="hljs-number">5</span>):int(idx_len*<span class="hljs-number">4</span>/<span class="hljs-number">5</span>)]
test_index=indexs[int(idx_len*<span class="hljs-number">4</span>/<span class="hljs-number">5</span>):]


use_gpu = torch.cuda.is_available()
model = DeepHistone(use_gpu)
print(<span class="hljs-string">&apos;Begin training model...&apos;</span>)
best_model = copy.deepcopy(model)
best_valid_auPRC=<span class="hljs-number">0</span>
best_valid_loss = np.float(<span class="hljs-string">&apos;Inf&apos;</span>)
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">50</span>):
    np.random.shuffle(train_index)
    train_loss= model_train(train_index,model,batchsize,dna_dict,lab_dict,)
    valid_loss,valid_lab,valid_pred= model_eval(valid_index, model,batchsize,dna_dict,lab_dict,)
    valid_auPRC,valid_auROC= metrics(valid_lab,valid_pred,<span class="hljs-string">&apos;Valid&apos;</span>,valid_loss)

    <span class="hljs-keyword">if</span> np.mean(list(valid_auPRC.values())) &gt;best_valid_auPRC:
        best_model = copy.deepcopy(model)

    <span class="hljs-keyword">if</span> valid_loss &lt; best_valid_loss: 
        early_stop_time = <span class="hljs-number">0</span>
        best_valid_loss = valid_loss    
    <span class="hljs-keyword">else</span>:
        model.updateLR(<span class="hljs-number">0.1</span>)
        early_stop_time += <span class="hljs-number">1</span>
        <span class="hljs-keyword">if</span> early_stop_time &gt;= <span class="hljs-number">5</span>: <span class="hljs-keyword">break</span>


print(<span class="hljs-string">&apos;Begin predicting...&apos;</span>)
test_lab,test_pred = model_predict(test_index,best_model,batchsize,dna_dict,lab_dict,)    
test_auPR,test_roc= metrics(test_lab,test_pred,<span class="hljs-string">&apos;Test&apos;</span>)


print(<span class="hljs-string">&apos;Begin saving...&apos;</span>)
np.savetxt(lab_save_file, test_lab, fmt=<span class="hljs-string">&apos;%d&apos;</span>, delimiter=<span class="hljs-string">&apos;\t&apos;</span>)
np.savetxt(pred_save_file, test_pred, fmt=<span class="hljs-string">&apos;%.4f&apos;</span>, delimiter=<span class="hljs-string">&apos;\t&apos;</span>)
best_model.save_model(model_save_file)
torch.save(model,<span class="hljs-string">&apos;model1.pth&apos;</span>)

print(<span class="hljs-string">&apos;Finished.&apos;</span>)
</code></pre>
<h4 id="&#x786E;&#x5B9A;&#x4E0A;&#x6807;&#x7B7E;&#x65B9;&#x6CD5;">&#x786E;&#x5B9A;&#x4E0A;&#x6807;&#x7B7E;&#x65B9;&#x6CD5;</h4>
<p>&#x5C06;H3K4me3&#x548C;H3K27ac&#x6309;&#x7167;&#x540C;&#x4E00;&#x79CD;&#x6807;&#x7B7E;&#x8BA1;&#x7B97;</p>
<p>&#x5C06;H3K4me1&#x548C;H3K9me2&#x6309;&#x7167;&#x540C;&#x4E00;&#x79CD;&#x6807;&#x7B7E;&#x8BA1;&#x7B97;</p>
<p>&#x8BA1;&#x7B97;&#x6BCF;&#x79CD;&#x7EC4;&#x86CB;&#x767D;&#x4FEE;&#x9970;peak&#x7684;&#x4E2D;&#x4F4D;&#x6570;&#xFF0C;&#x5E73;&#x5747;&#x6570;</p>
<table>
<thead>
<tr>
<th>histone modifications</th>
<th>mid</th>
<th>average</th>
</tr>
</thead>
<tbody>
<tr>
<td>H3K4me3&#xFF08;1&#xFF09;</td>
<td>880</td>
<td>950.52</td>
</tr>
<tr>
<td>H3K27ac&#xFF08;2&#xFF09;</td>
<td>799</td>
<td>854.329</td>
</tr>
<tr>
<td>H3K4me1&#xFF08;3&#xFF09;</td>
<td>2694</td>
<td>3446.12</td>
</tr>
<tr>
<td>H3K27me3&#xFF08;4&#xFF09;</td>
<td>1586</td>
<td>3149.9</td>
</tr>
<tr>
<td>H3K9me2&#xFF08;5&#xFF09;</td>
<td>2158</td>
<td>4094.97</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>histone modifications</th>
<th>function</th>
</tr>
</thead>
<tbody>
<tr>
<td>H3K4me3&#xFF08;1&#xFF09;</td>
<td>&#x53D6;peak&#x4E2D;&#x592E;<strong>250bp</strong>&#x4F5C;&#x4E3A;&#x6807;&#x51C6;&#xFF0C;win&#x5728;&#x5176;&#x4E2D;&#x7684;&#x6BD4;&#x4F8B;&#x5360;&#x5230;<strong>10%</strong>&#x5219;&#x6807;&#x8BB0;&#x4E3A;&#x9633;&#x6027;</td>
</tr>
<tr>
<td>H3K27ac&#xFF08;2&#xFF09;</td>
<td>250</td>
</tr>
<tr>
<td>H3K4me1&#xFF08;3&#xFF09;</td>
<td>750</td>
</tr>
<tr>
<td>H3K27me3&#xFF08;4&#xFF09;</td>
<td>750</td>
</tr>
<tr>
<td>H3K9me2&#xFF08;5&#xFF09;</td>
<td>1000</td>
</tr>
</tbody>
</table>
<p>target_mark5.0.py</p>
<p><img src="C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20210406221649915.png" alt="image-20210406221649915"></p>
<h4 id="&#x6784;&#x5EFA;&#x603B;&#x6570;&#x636E;&#x96C6;">&#x6784;&#x5EFA;&#x603B;&#x6570;&#x636E;&#x96C6;</h4>
<p>20&#x4E2A;&#x54C1;&#x79CD;5&#x79CD;&#x7EC4;&#x86CB;&#x767D;&#x4FEE;&#x9970;&#x6240;&#x6709;&#x9633;&#x6027;</p>
<table>
<thead>
<tr>
<th>histone modifications</th>
<th>nums</th>
</tr>
</thead>
<tbody>
<tr>
<td>H3K4me3&#xFF08;1&#xFF09;</td>
<td>256721</td>
</tr>
<tr>
<td>H3K27ac&#xFF08;2&#xFF09;</td>
<td>227526</td>
</tr>
<tr>
<td>H3K4me1&#xFF08;3&#xFF09;</td>
<td>152355</td>
</tr>
<tr>
<td>H3K27me3&#xFF08;4&#xFF09;</td>
<td>136028</td>
</tr>
<tr>
<td>H3K9me2&#xFF08;5&#xFF09;</td>
<td>118142</td>
</tr>
<tr>
<td>total</td>
<td>890772</td>
</tr>
<tr>
<td>total&#xFF08;after check&#xFF09;</td>
<td>887724</td>
</tr>
</tbody>
</table>
<pre><code class="lang-shell">#!/bin/bash

for n in $(cat histone)
do
    for i in $(cat id.txt)
    do
    python3 target_mark5.0.py -f ${i}.fasta.fai -b data/signal_area/sort_${i}.bed -o target_${i}_${n}.bed -s ${i} -m ${n} &amp;&amp; paste $[i}.fasta target_${i}_${n}.bed &gt; data/dataset/ex1/${n}.csv &amp;&amp; awk &apos;$3 != 0 {print}&apos; data/dataset/ex1/${n}.csv &gt;&gt; dataset_all.csv | awk &apos;{print $3}&apos; | uniq -c  
    done
done
</code></pre>
<pre><code>#!/bin/bash
</code></pre><pre><code class="lang-shell">bsub -q gpu -o result1.out -e 14.err &apos;python3 train_dna.py&apos;
</code></pre>
<p>&#x7ED3;&#x679C;&#x5C55;&#x793A;</p>
<p>&#x7BB1;&#x7EBF;&#x56FE;</p>
<pre><code>

</code></pre><p><img src="C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20210415140355121.png" alt="image-20210415140355121"></p>
<h3 id="transformer">Transformer</h3>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="数据获取与预处理.html" class="navigation navigation-prev " aria-label="Previous page: 数据获取与预处理">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="模型评估.html" class="navigation navigation-next " aria-label="Next page: 模型评估">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"构建模型","level":"1.2.3","depth":2,"next":{"title":"模型评估","level":"1.2.4","depth":2,"path":"实验流程/模型评估.md","ref":"实验流程/模型评估.md","articles":[]},"previous":{"title":"数据获取与预处理","level":"1.2.2","depth":2,"path":"实验流程/数据获取与预处理.md","ref":"实验流程/数据获取与预处理.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"实验流程/构建模型.md","mtime":"2021-05-05T08:35:23.775Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2021-05-05T08:36:40.018Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

